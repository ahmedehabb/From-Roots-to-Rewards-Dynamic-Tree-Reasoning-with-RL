{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Tree generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the together service and make sure you can prompt the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProviderReq:\n",
    "    def __init__(self, url, cache_path=\"./cache.jsonl\", model=None):\n",
    "        self.url = url\n",
    "        self.cache = {}\n",
    "        self.cache_path = cache_path\n",
    "        self.model = model  # Default model is set to None, but can be overridden in child classes\n",
    "        if os.path.exists(self.cache_path):\n",
    "            with open(self.cache_path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    datum = json.loads(line.strip())\n",
    "                    self.cache[tuple(datum[\"input\"])] = datum[\"response\"]\n",
    "\n",
    "    def req2provider(self, prompt, temperature=0, max_tokens=None, stop=None, logprobs=1, use_cache=True):\n",
    "        assert isinstance(prompt, str)\n",
    "        input = (prompt, self.model, max_tokens, stop, logprobs)\n",
    "        if use_cache and temperature == 0 and input in self.cache:\n",
    "            return self.cache[input], True\n",
    "\n",
    "        # Retry logic\n",
    "        for i in range(3):\n",
    "            try:\n",
    "                response = self.make_request(prompt, self.model, temperature, max_tokens, stop, logprobs)\n",
    "                if response.status_code != 200:\n",
    "                    raise Exception(response.text)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                err_msg = str(e)\n",
    "                print(e)\n",
    "                if \"reduce your prompt\" in err_msg:  # this is because the input string is too long\n",
    "                    return ['too long'], False\n",
    "\n",
    "        try:\n",
    "            response_json = response.json()\n",
    "            response = self.parse_response(response_json)\n",
    "        except:\n",
    "            return ['error'], False\n",
    "\n",
    "        # Cache the result if temperature is 0\n",
    "        if temperature == 0:\n",
    "            self.cache_result(input, response)\n",
    "\n",
    "        return response, True\n",
    "\n",
    "    def make_request(self, prompt, model, temperature, max_tokens, stop, logprobs):\n",
    "        \"\"\"To be implemented in the subclass\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def parse_response(self, response_json):\n",
    "        \"\"\"To be implemented in the subclass\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
    "\n",
    "    def cache_result(self, input, response):\n",
    "        \"\"\"Cache the result if it's not already cached\"\"\"\n",
    "        if input not in self.cache:\n",
    "            self.cache[input] = response\n",
    "            with open(self.cache_path, \"a\") as f:\n",
    "                f.write(\"%s\\n\" % json.dumps({\"input\": input, \"response\": response}))\n",
    "\n",
    "class TogetherReq(ProviderReq):\n",
    "    # meta-llama/Llama-Vision-Free is free but doesnt support log_probs which are necessary for probtree\n",
    "    # meta-llama/Meta-Llama-3-8B-Instruct-Turbo : bad answers but provide log_prob\n",
    "    # meta-llama/Llama-3.2-3B-Instruct-Turbo ? bad answers tpp\n",
    "    # meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo ? very nice but no log_prob !! \n",
    "    # meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo ? niceeee and log probs !! :) \n",
    "    # meta-llama/Meta-Llama-3-70B-Instruct-Lite ?\n",
    "    def __init__(self, cache_path=\"./cache.jsonl\", model=\"meta-llama/Meta-Llama-3-70B-Instruct-Lite\"):\n",
    "        super().__init__(url=\"http://127.0.0.1:10001/api/together/completion\", cache_path=cache_path, model=model)\n",
    "\n",
    "    def make_request(self, prompt, model, temperature, max_tokens, stop, logprobs):\n",
    "        return requests.post(self.url, json={\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"stop\": stop,\n",
    "            \"logprobs\": logprobs,\n",
    "        })\n",
    "\n",
    "    def parse_response(self, response_json):\n",
    "        return response_json['choices']\n",
    "\n",
    "def bm25_search(question, k, use_serpapi=False):\n",
    "    web = \"http://localhost:1439\"\n",
    "    data = {\n",
    "        \"query\": question,\n",
    "        \"k\": k\n",
    "    }\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            r = requests.get(web, json=data)\n",
    "            if r.status_code != 200:\n",
    "                raise Exception(r.text)\n",
    "            contexts = r.json()\n",
    "            # if use_serpapi:\n",
    "            #     context = get_question_wiki_snippet(question, cache=True)\n",
    "            #     title = context.split(': ')[0]\n",
    "            #     text = ' '.join(context.split(': ')[1:])\n",
    "            #     contexts.append({\"title\": title, \"text\": text})\n",
    "            return contexts\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'finish_reason': 'eos', 'index': 0, 'logprobs': {'token_ids': [3923, 264, 27387, 8815, 2268, 81122, 1131, 13126, 499, 2351, 505, 15212, 11, 358, 3358, 1935, 264, 8545, 8101, 2195, 11787, 499, 8530, 7086, 330, 83705, 3690, 1, 477, 330, 6219, 81, 44969, 4314, 527, 1633, 4279, 5144, 304, 15212, 11, 719, 358, 1436, 387, 12756, 1022, 2268, 5618, 3041, 757, 264, 13310, 477, 3371, 757, 422, 358, 2846, 12660, 3345, 0, 128009], 'token_logprobs': [-0.1640625, -0.0024719238, -0.18945312, -0.46289062, -0.00074768066, -1.171875, -0.0017089844, -0.5546875, -0.21679688, -0.006713867, 0, -2.3841858e-07, -4.720688e-05, -0.0006942749, -0.47460938, -7.5101852e-06, -0.00033569336, -0.18554688, -0.011108398, -0.45117188, -0.640625, -0.00012302399, -0.578125, -0.19921875, -0.8515625, -0.49804688, -0.12695312, -0.1171875, -0.0007171631, -0.1171875, -0.875, -0.099609375, -0.11328125, -0.765625, -0.25195312, -0.76953125, -0.029785156, -0.12890625, 0, -1.0251999e-05, -0.026855469, -0.31445312, -0.005432129, -0.671875, -3.33786e-06, -0.90625, -0.029785156, -0.3984375, -0.80078125, -0.5546875, 0, -0.038330078, -2.861023e-05, -0.022705078, -0.07519531, 0, -0.103027344, -7.6293945e-06, -4.7683716e-06, -0.83984375, -0.0024719238, -0.171875, -0.0009422302], 'tokens': ['What', ' a', ' fascinating', ' challenge', '!\\n\\n', 'Hmm', '...', ' considering', ' you', \"'re\", ' from', ' Egypt', ',', ' I', \"'ll\", ' take', ' a', ' wild', ' guess', '...\\n\\n', 'Are', ' you', ' perhaps', ' named', ' \"', 'Moh', 'amed', '\"', ' or', ' \"', 'Am', 'r', '\"?', ' These', ' are', ' very', ' common', ' names', ' in', ' Egypt', ',', ' but', ' I', ' could', ' be', ' totally', ' off', '!\\n\\n', 'Please', ' give', ' me', ' a', ' hint', ' or', ' tell', ' me', ' if', ' I', \"'m\", ' anywhere', ' close', '!', '<|eot_id|>']}, 'message': {'content': 'What a fascinating challenge!\\n\\nHmm... considering you\\'re from Egypt, I\\'ll take a wild guess...\\n\\nAre you perhaps named \"Mohamed\" or \"Amr\"? These are very common names in Egypt, but I could be totally off!\\n\\nPlease give me a hint or tell me if I\\'m anywhere close!', 'role': 'assistant', 'tool_calls': []}, 'seed': 12760961252387523000}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "key_pool = os.getenv('TOGETHER_API_KEY').split(',')\n",
    "NUM_WORKERS = len(key_pool)  # Match the number of workers to the number of clients\n",
    "\n",
    "reqor = TogetherReq()\n",
    "result, tag = reqor.req2provider(\"Hello, I am from Egypt. Guess my name ??\", max_tokens = None, stop = None)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the children decomposition mechanism to only expand/decompose one node at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the prompt\n",
    "\n",
    "# ***Carefully review the existing children and the current node. If they already provide a comprehensive decomposition of the current node and no further meaningful steps are needed, respond with \"Done\".***\n",
    "\n",
    "# ***Only suggest a new child node if it directly contributes to solving the main question. The child node should be a specific, actionable step that helps answer the original question.***\n",
    "\n",
    "# ***Important Rules:***\n",
    "# 1. **Do not repeat subquestions**: Ensure the new child node does not repeat any of the existing children or restate information already present in the original question.\n",
    "# 2. **Use placeholders correctly**: If the new child node depends on the answer of a previous subquestion, use placeholders like `<1>` to refer to it. For example:\n",
    "# - If the first child is \"What is the capital of France?\", and the second child depends on its answer, write: \"What is the population of <1>?\"\n",
    "# 3. **Avoid irrelevant subquestions**: Ensure the new child node directly contributes to solving the main question. Do not suggest subquestions that are unrelated or tangential.\n",
    "# 4. **Keep subquestions simple and specific**: Avoid overly complex or redundant subquestions.\n",
    "\n",
    "# ***Return only the new child node or \"Done\".***\n",
    "\n",
    "\n",
    "def create_decompose_prompt(question, children):\n",
    "    return f\"\"\"\n",
    "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
    "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
    "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
    "\n",
    "    ### Task:\n",
    "\n",
    "    1. **Carefully analyze the reasoning tree**:\n",
    "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
    "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
    "\n",
    "    2. **Follow these rules for decomposition**:\n",
    "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
    "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
    "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
    "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
    "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
    "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
    "\n",
    "    3. **Define stopping criteria**:\n",
    "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
    "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
    "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
    "\n",
    "    4. **Output Format**:\n",
    "        - Return either the new child node or \"Done\" without any additional context.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Examples for Guidance\n",
    "\n",
    "    #### Example 1:\n",
    "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "    - Existing Children: []\n",
    "    - Response: \"How many members does The Border Surrender have?\"\n",
    "\n",
    "    #### Example 2:\n",
    "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
    "    - Response: \"How many members does Unsane have?\"\n",
    "\n",
    "    #### Example 3:\n",
    "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
    "    - Response: \"Which is larger, <1> or <2>?\"\n",
    "\n",
    "    #### Example 4:\n",
    "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
    "    - Response: \"Done\"\n",
    "\n",
    "    ---\n",
    "\n",
    "    - Current Node: {question}\n",
    "    - Existing Children: {children}\n",
    "    - Response:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Function to query the LLM\n",
    "def query_llm(prompt):\n",
    "    result, tag = reqor.req2provider(prompt, max_tokens=None, stop=None)\n",
    "    response = result[0][\"message\"][\"content\"].strip()\n",
    "    log_probs = result[0].get(\"logprobs\", [])  # Assuming logprobs is returned by the LLM\n",
    "    if log_probs:\n",
    "        log_probs = log_probs[\"token_logprobs\"]\n",
    "    return response, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: []\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What fiction magazine did Robert E. Howard write for in the 1930s?\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What was the typical page count of <1>?\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: Is <1> a pulp magazine?\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?']\n",
      "Final Tree: {'node': 'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?', 'children': ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?']}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the question and children\n",
    "question = \"Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\"\n",
    "children = []\n",
    "\n",
    "# Iterative decomposition loop until \"Done\" is returned\n",
    "count = 0\n",
    "while count < 3:  # Limiting the number of iterations for demonstration purposes\n",
    "    # Create the prompt\n",
    "    prompt = create_decompose_prompt(question, children)\n",
    "    print(\"Prompt for expansion:\", prompt)\n",
    "    \n",
    "    # Query the LLM\n",
    "    response, log_probs = query_llm(prompt)\n",
    "    print(\"LLM Response:\", response)\n",
    "    \n",
    "    # Check if the response is \"Done\"\n",
    "    if response.lower() == \"done\":\n",
    "        print(\"Decomposition complete.\")\n",
    "        break\n",
    "    \n",
    "    # Add the new child node to the children list\n",
    "    children.append(response)\n",
    "    print(\"Updated Children:\", children)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# Final tree structure\n",
    "tree = {\n",
    "    \"node\": question,\n",
    "    \"children\": children\n",
    "}\n",
    "print(\"Final Tree:\", tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: []\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What fiction magazine did Robert E. Howard write for in the 1930s?\n",
      "log_probs for the response: [-0.0066833496, -0.25976562, -0.038085938, -0.07128906, -3.5762787e-07, 0, -1.3113022e-06, -5.4836273e-06, -0.11425781, -0.12695312, -0.0007019043, -2.7537346e-05, 0, -1.1920929e-07, 0, -1.1920929e-07, -2.5629997e-05, -3.5762787e-06]\n",
      "Score for the response: -0.61780093649765\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What was the typical page count of <1>?\n",
      "log_probs for the response: [-0.23144531, -0.026855469, -0.0032806396, -0.013549805, -0.011779785, -0.00040626526, -0.10058594, -0.19433594, -1.1920929e-07, -0.4296875, -6.0796738e-06]\n",
      "Score for the response: -1.01193285274309\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: Is <1> a pulp magazine?\n",
      "log_probs for the response: [-0.06933594, -0.53125, -0.3125, -0.0019378662, -0.028076172, -0.012268066, -0.00044822693, -0.006713867, -1.5854836e-05]\n",
      "Score for the response: -0.962545992966\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?\n",
      "log_probs for the response: [-0.4140625, -0.71484375, -0.17382812, -5.531311e-05, -2.6226044e-06, -0.0027618408, -0.4921875, -2.18153e-05, -0.00010967255, -1.0078125, -0.010559082, -0.24121094, -0.19042969, -0.9375, -0.6953125, -1.1920929e-07, -1.1920929e-07, -0.005584717, -0.69921875, -0.578125, -0.33984375, -0.00028038025]\n",
      "Score for the response: -6.5037506820329805\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\n",
      "log_probs for the response: [-1.3359375, -1.484375, -0.018920898, -0.984375, -1.2636185e-05, -0.2109375, -0.38085938, -7.4863434e-05, 0, -0.4921875, -0.17773438, -8.225441e-06, -0.0009841919, -0.296875, -0.765625, -0.034423828, -1.9073486e-06, -0.22558594, -1.1920929e-07, -7.2717667e-06, -3.695488e-06, -6.4373016e-06, -0.203125, -0.27539062, -0.00031661987, -7.5101852e-06, 0, 0, -4.7683716e-07, -0.014160156, -1.0728836e-05]\n",
      "Score for the response: -6.90194738580255\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\"]\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\"]\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: Is the typical page count of <1> a standard or varied across different issues?\n",
      "log_probs for the response: [-1.65625, -0.045166016, -0.48046875, -0.0004272461, 0, -0.0035552979, -0.15136719, -3.2901764e-05, -0.00014019012, -1.3515625, -0.6875, -0.4609375, -1.375, -0.55078125, -0.35546875, -0.0002593994, -0.10205078, -4.887581e-06]\n",
      "Score for the response: -7.220972658865\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?\n",
      "log_probs for the response: [-0.3984375, -0.77734375, -1.765625, -0.0023498535, -0.22949219, -0.72265625, -0.20800781, 0, -1.1205673e-05, -3.33786e-06, -0.34960938, -0.0004711151, -0.21191406, -0.0011444092, -1.1920929e-07, -0.38671875, -0.06347656, -1.7881393e-06, -2.3841858e-07, 0, 0, -3.5762787e-07, -0.033203125, -6.4373016e-06]\n",
      "Score for the response: -5.15047323702964\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?\n",
      "log_probs for the response: [-0.63671875, -0.6875, -1.078125, -0.41992188, -0.8828125, -0.921875, -0.44140625, -1.1920929e-07, -0.16796875, -0.44140625, -0.012878418, -2.1457672e-06, -1.0078125, -4.2676926e-05, -0.0002632141, -0.0031738281, 0, -0.00041770935, -4.1246414e-05, -1.5497208e-06, -0.038085938, -6.67572e-06]\n",
      "Score for the response: -6.74046040130729\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?\n",
      "log_probs for the response: [-0.8046875, -0.9453125, -0.22949219, -0.012817383, -0.041503906, -0.06347656, -0.4140625, -1.1920929e-07, -0.59765625, -0.578125, -0.009033203, -0.0047302246, -0.8671875, -0.0003452301, -0.05883789, -0.0064697266, -0.0001206398, -0.0016708374, -0.57421875, -0.00010061264, -0.46875, -0.08154297]\n",
      "Score for the response: -5.76014149234929\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?\n",
      "log_probs for the response: [-0.42578125, -0.984375, -0.18457031, -0.10107422, -0.16699219, -0.08300781, -0.765625, 0, -4.863739e-05, -0.0052490234, 0, -1.7881393e-06, -0.0039978027, 0, -1.1920929e-07, -1.1920929e-07, 0, -2.3841858e-07, -1.9550323e-05, 0, -0.0005645752, -5.197525e-05]\n",
      "Score for the response: -2.72135960923946\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?\n",
      "log_probs for the response: [-0.45898438, -0.94140625, -0.20996094, -0.025390625, -0.20605469, -0.0015640259, -0.23632812, -7.1525574e-07, -0.21972656, -0.43945312, -8.225441e-06, -0.048828125, -0.94140625, -0.00032806396, -0.028686523, -0.0018386841, -3.9339066e-06, -0.00075912476, -0.004425049, -3.2186508e-06, -0.66796875, -0.53125]\n",
      "Score for the response: -4.96437537397414\n",
      "Updated Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?']\n",
      "Prompt for expansion: \n",
      "    You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "    - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "    - Existing Children: A list of subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "    ### Task:\n",
      "\n",
      "    1. **Carefully analyze the reasoning tree**:\n",
      "        - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "        - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "    2. **Follow these rules for decomposition**:\n",
      "        - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "        - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "        - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "        - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "            - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "            - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "\n",
      "    3. **Define stopping criteria**:\n",
      "        - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "        - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "        - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "    4. **Output Format**:\n",
      "        - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "    ---\n",
      "\n",
      "    ### Examples for Guidance\n",
      "\n",
      "    #### Example 1:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: []\n",
      "    - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "    #### Example 2:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "    - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "    #### Example 3:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "    - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "    #### Example 4:\n",
      "    - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "    - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "    - Response: \"Done\"\n",
      "\n",
      "    ---\n",
      "\n",
      "    - Current Node: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "    - Existing Children: ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?']\n",
      "    - Response:\n",
      "    \n",
      "LLM Response: Done\n",
      "Decomposition complete.\n",
      "Decomposition complete at depth 0.\n",
      "Final Tree Structure: {'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'children': ['What fiction magazine did Robert E. Howard write for in the 1930s?', 'What was the typical page count of <1>?', 'Is <1> a pulp magazine?', 'Is the typical page count of <1> relevant to understanding the typical number of pages in the magazine?', \"What is the significance of the typical page count of <1> in the context of Robert E. Howard's writing in the 1930s?\", 'Is the typical page count of <1> a standard or varied across different issues?', 'What specific type of fiction did Robert E. Howard typically write for <1> in the 1930s?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, such as size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?', 'What specific pulp magazine characteristics, other than size or format, influenced the typical page count of <1>?'], 'children_sum_scores': [-0.61780093649765, -1.01193285274309, -0.962545992966, -6.5037506820329805, -6.90194738580255, -7.220972658865, -5.15047323702964, -6.74046040130729, -5.76014149234929, -2.72135960923946, -4.96437537397414], 'children_log_probs_lengths': [18, 11, 9, 22, 31, 18, 24, 22, 22, 22, 22]}}\n"
     ]
    }
   ],
   "source": [
    "def get_all_children_of_certain_node(question, existing_children=[], max_children=3):\n",
    "    # Iterative decomposition loop untill Done is got\n",
    "    num_children = len(existing_children)\n",
    "    while num_children <= max_children:\n",
    "        # Create the prompt\n",
    "        prompt = create_decompose_prompt(question, [child[\"text\"] for child in existing_children])\n",
    "        print(\"Prompt for expansion:\", prompt)\n",
    "        \n",
    "        # Query the LLM\n",
    "        response, log_probs = query_llm(prompt)\n",
    "        print(\"LLM Response:\", response)\n",
    "        \n",
    "        # Check if the response is \"Done\"\n",
    "        if response.lower() == \"done\":\n",
    "            print(\"Decomposition complete.\")\n",
    "            break\n",
    "        \n",
    "        # Calculate the score using log probabilities\n",
    "        score = sum(log_probs) if log_probs else -100\n",
    "        print(\"log_probs for the response:\", log_probs)\n",
    "        print(\"Score for the response:\", score)\n",
    "\n",
    "        # Add the new child node to the existing_children list\n",
    "        existing_children.append({\n",
    "            \"text\": response,\n",
    "            \"score\": score,  # Keeping the original score for reference\n",
    "            \"log_probs_length\": len(log_probs) if log_probs else -1,\n",
    "        })\n",
    "        print(\"Updated Children:\", [child[\"text\"] for child in existing_children])\n",
    "\n",
    "    return existing_children\n",
    "\n",
    "# Function to recursively decompose a node\n",
    "def decompose_node(node, tree_structure={}, depth=0, max_depth=2):\n",
    "    if depth >= max_depth:\n",
    "        return tree_structure\n",
    "    \n",
    "    # Avoid re-decomposing the same node\n",
    "    if node in tree_structure:\n",
    "        return tree_structure\n",
    "\n",
    "    children_with_scores = get_all_children_of_certain_node(node, [])\n",
    "    print(f\"Decomposition complete at depth {depth}.\")\n",
    "\n",
    "    # Add the new child node to the tree structure\n",
    "    # TODO:: in original probtree code, score at parent was calculated based on response of one shot tree generation.\n",
    "    # Here i added children sum scores, and lengths as lists since we generate each child now separately.\n",
    "    tree_structure[node] = {\n",
    "        \"children\": [child[\"text\"] for child in children_with_scores],\n",
    "        \"children_sum_scores\": [child[\"score\"] for child in children_with_scores],\n",
    "        \"children_log_probs_lengths\": [child[\"log_probs_length\"] for child in children_with_scores],\n",
    "    }\n",
    "    assert len(tree_structure[node][\"children\"]) == len(tree_structure[node][\"children_sum_scores\"]) == len(tree_structure[node][\"children_log_probs_lengths\"]), \"Length mismatch in children data.\"\n",
    "\n",
    "    #TODO:: maybe can be removed since later we may need to decompose step by step or based on an action.\n",
    "    # Recursively decompose the new child node\n",
    "    for child in children_with_scores:\n",
    "        tree_structure = decompose_node(child[\"text\"], tree_structure, depth + 1, max_depth)\n",
    "\n",
    "    return tree_structure\n",
    "\n",
    "# Initialize the question and children\n",
    "question = \"Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\"\n",
    "\n",
    "# Build the tree structure\n",
    "tree_structure = {}\n",
    "tree_structure = decompose_node(question, max_depth=1)\n",
    "\n",
    "# Final tree structure\n",
    "print(\"Final Tree Structure:\", tree_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning Action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pruning_prompt(main_question, node, siblings):\n",
    "    return f\"\"\"\n",
    "    You are helping to prune a reasoning tree. Here is the current state of the tree:\n",
    "    - Main Question: The root question that the reasoning tree is trying to answer.\n",
    "    - Current Node: A subquestion or step in the reasoning process.\n",
    "    - Siblings: Other subquestions or steps at the same level in the tree.\n",
    "\n",
    "    ### Task:\n",
    "\n",
    "    1. **Carefully analyze the reasoning tree**:\n",
    "        - Evaluate whether the current node is relevant to solving the main question.\n",
    "        - If the current node is irrelevant, redundant, or does not contribute meaningfully to solving the main question, respond with \"Prune\".\n",
    "        - If the current node is relevant and necessary, respond with \"Keep\".\n",
    "\n",
    "    2. **Follow these rules for pruning**:\n",
    "        - **Focus on relevance**: A node should be pruned if it does not directly contribute to solving the main question.\n",
    "        - **Avoid redundancy**: Prune nodes that repeat or rephrase existing information from siblings without adding new insights.\n",
    "        - **Simplify complexity**: Prune nodes that introduce unnecessary complexity or depth without advancing the reasoning process.\n",
    "\n",
    "    3. **Output Format**:\n",
    "        - Return either \"Prune\" or \"Keep\" without any additional context.\n",
    "\n",
    "    ---\n",
    "\n",
    "    ### Examples for Guidance\n",
    "\n",
    "    #### Example 1:\n",
    "    - Main Question: \"What is the capital of France?\"\n",
    "    - Current Node: \"What is the population of Paris?\"\n",
    "    - Siblings: [\"What is the name of the capital city of France?\"]\n",
    "    - Response: \"Prune\"  # Not directly relevant to the main question\n",
    "\n",
    "    #### Example 2:\n",
    "    - Main Question: \"What is the capital of France?\"\n",
    "    - Current Node: \"What is the name of the capital city of France?\"\n",
    "    - Siblings: [\"What is the population of Paris?\"]\n",
    "    - Response: \"Keep\"  # Directly relevant to the main question\n",
    "\n",
    "    #### Example 3:\n",
    "    - Main Question: \"What is the capital of France?\"\n",
    "    - Current Node: \"What is the population of France?\"\n",
    "    - Siblings: [\"What is the name of the capital city of France?\"]\n",
    "    - Response: \"Prune\"  # Not directly relevant to the main question\n",
    "\n",
    "    #### Example 4:\n",
    "    - Main Question: \"What is the capital of France?\"\n",
    "    - Current Node: \"What is the name of the capital city of France?\"\n",
    "    - Siblings: [\"What is the population of France?\"]\n",
    "    - Response: \"Keep\"  # Directly relevant to the main question\n",
    "\n",
    "    #### Example 5:\n",
    "    - Main Question: \"What is the capital of France?\"\n",
    "    - Current Node: \"What is the population of Paris?\"\n",
    "    - Siblings: [\"What is the name of the capital city of France?\", \"What is the population of France?\"]\n",
    "    - Response: \"Prune\"  # Redundant with siblings and not directly relevant\n",
    "\n",
    "    ---\n",
    "\n",
    "    - Main Question: {main_question}\n",
    "    - Current Node: {node}\n",
    "    - Siblings: {siblings}\n",
    "    - Response:\n",
    "    \"\"\"\n",
    "\n",
    "def should_prune_node(main_question, node, siblings):\n",
    "    \"\"\"\n",
    "    Asks the LLM whether a node should be pruned.\n",
    "    \n",
    "    Args:\n",
    "        main_question (str): The main question (root node).\n",
    "        node (str): The node to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the node should be pruned, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if siblings contain the node, we should remove it but dont change the original list\n",
    "    siblings = siblings.copy()\n",
    "    if node in siblings:\n",
    "        # print(f\"Node '{node}' found in siblings. Removing it.\")\n",
    "        siblings.remove(node)\n",
    "\n",
    "    # Create the pruning prompt\n",
    "    prompt = create_pruning_prompt(main_question, node, siblings)\n",
    "    # print(\"Prompt for pruning:\", prompt)\n",
    "    \n",
    "    # Query the LLM\n",
    "    response, _ = query_llm(prompt)\n",
    "    \n",
    "    # Parse the response\n",
    "    return response.strip().lower() == \"prune\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned node: If the fiction magazine in which Robert E. Howard wrote in 1930s was primarily Weird Tales magazine, did he write in other magazines during that period as well?\n",
      "Pruned node: If the fiction magazine in which Robert E. Howard wrote in 1930s was not primarily Weird Tales magazine, what was the typical page count of that magazine during the 1930s?\n",
      "Pruned node: What was the typical page count of other fiction magazines that Robert E. Howard wrote for during the 1930s?\n",
      "Updated tree structure: {'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'children': ['What was the typical page count of Weird Tales magazine during the 1930s?', 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'], 'children_sum_scores': [-2.04336368615382, -0.7338265208047, -5.4407544111175], 'children_log_probs_lengths': [18, 20, 22]}}\n"
     ]
    }
   ],
   "source": [
    "def prune_nodes_with_llm(question, tree_structure):\n",
    "    # Extract the children, scores, and log probabilities from the tree structure\n",
    "    children = tree_structure[question]['children']\n",
    "    children_sum_scores = tree_structure[question]['children_sum_scores']\n",
    "    children_log_probs_lengths = tree_structure[question]['children_log_probs_lengths']\n",
    "    updated_children = children.copy()\n",
    "    pruned_children = []\n",
    "\n",
    "    # Create a mapping of child to its score and log probability length\n",
    "    child_to_score = {child: score for child, score in zip(children, children_sum_scores)}\n",
    "    child_to_log_prob = {child: log_prob for child, log_prob in zip(children, children_log_probs_lengths)}\n",
    "\n",
    "    # Iterate through the children nodes and prune based on criteria\n",
    "    for child in children:\n",
    "        # Pass the score and log probability length indirectly via the updated_children list\n",
    "        if should_prune_node(question, child, updated_children):\n",
    "            pruned_children.append(child)\n",
    "            updated_children.remove(child)\n",
    "            print(f\"Pruned node: {child}\")\n",
    "\n",
    "    updated_scores = [child_to_score[child] for child in updated_children]\n",
    "    updated_log_probs = [child_to_log_prob[child] for child in updated_children]\n",
    "\n",
    "    # Update the tree structure with the pruned results\n",
    "    tree_structure[question]['children'] = updated_children\n",
    "    tree_structure[question]['children_sum_scores'] = updated_scores\n",
    "    tree_structure[question]['children_log_probs_lengths'] = updated_log_probs\n",
    "\n",
    "    #TODO:: If the parent score depends on them, we must update the parent score as well. (Parent score based on children bot implemented yet)\n",
    "\n",
    "    return tree_structure\n",
    "\n",
    "# Example usage:\n",
    "question = 'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?'\n",
    "tree_structure = {\n",
    "    question: {\n",
    "        'children': [\n",
    "            'What was the typical page count of Weird Tales magazine during the 1930s?', \n",
    "            'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', \n",
    "            'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?', \n",
    "            'If the fiction magazine in which Robert E. Howard wrote in 1930s was primarily Weird Tales magazine, did he write in other magazines during that period as well?', \n",
    "            'If the fiction magazine in which Robert E. Howard wrote in 1930s was not primarily Weird Tales magazine, what was the typical page count of that magazine during the 1930s?', \n",
    "            'What was the typical page count of other fiction magazines that Robert E. Howard wrote for during the 1930s?'\n",
    "        ], \n",
    "        'children_sum_scores': [-2.04336368615382, -0.7338265208047, -5.4407544111175, -6.85595369407406, -0.95331907415425, -4.1018621915672], \n",
    "        'children_log_probs_lengths': [18, 20, 22, 35, 40, 25]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prune nodes\n",
    "updated_tree_structure = prune_nodes_with_llm(question, tree_structure)\n",
    "\n",
    "print(\"Updated tree structure:\", updated_tree_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'children': ['What was the typical page count of Weird Tales magazine during the 1930s?',\n",
       "   'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?',\n",
       "   'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'],\n",
       "  'children_sum_scores': [-2.04336368615382,\n",
       "   -0.7338265208047,\n",
       "   -5.4407544111175],\n",
       "  'children_log_probs_lengths': [18, 20, 22]}}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_tree_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving leaf nodes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOP Version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, question, decomposition_log_probs=None, parent=None, placeholder=None):\n",
    "        self.question = question  # The question or reasoning step\n",
    "        self.placeholder = placeholder  # Placeholder for the answer\n",
    "        self.children = []  # Child nodes (for decomposition)\n",
    "        self.parent = parent  # Parent node\n",
    "        self.decomposition_log_probs = decomposition_log_probs  # Confidence scores for decomposition, log probabilities\n",
    "        self.solved = False  # Flag to indicate if the node has been solved\n",
    "        self.cb_answer = None  # Answer from the closed-book model\n",
    "        self.cb_log_probs = None  # Log probability from the closed-book model\n",
    "        self.ob_answer = None  # Answer from the open-book model\n",
    "        self.ob_log_probs = None  # Log probability from the open-book model\n",
    "        self.child_aggregation_answer = None  # Aggregated answer from the children nodes\n",
    "        self.child_aggregation_log_probs = None  # Aggregated log probabilities from the children nodes\n",
    "        self.solver_results = []  # Store results from all solvers\n",
    "\n",
    "\n",
    "    def add_child(self, child):\n",
    "        \"\"\"Add a child node.\"\"\"\n",
    "        if child.parent is not None and child.parent is not self:\n",
    "            raise ValueError(\"The child node should not have a parent or should be the parent itself.\")\n",
    "        child.parent = self\n",
    "        self.children.append(child)\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"String representation of the node.\"\"\"\n",
    "        return f\"Node(question={self.question}, children={[child.question for child in self.children]}, decomposition_log_probs={self.decomposition_log_probs})\"\n",
    "\n",
    "    def print_tree(self, level=0):\n",
    "        \"\"\"Print the tree structure.\"\"\"\n",
    "        print(\"  \" * level + str(self))\n",
    "        for child in self.children:\n",
    "            child.print_tree(level + 1)\n",
    "    \n",
    "    def calculate_avg_log_probs(self, log_probs):\n",
    "        if not log_probs:\n",
    "            return -1000\n",
    "        return sum(log_probs) / len(log_probs)\n",
    "    \n",
    "    def get_confident_children_sorted(self):\n",
    "        return sorted(self.children, key=lambda child: child.calculate_avg_log_probs(child.decomposition_log_probs), reverse=True)\n",
    "    \n",
    "    def get_most_confident_child(self):\n",
    "        return self.get_confident_children_sorted()[0]\n",
    "    \n",
    "    def is_parent_solved(self):\n",
    "        \"\"\"\n",
    "        Check if the child node's answer resolves the parent node's question.\n",
    "        \"\"\"\n",
    "        return self.parent.solved\n",
    "    \n",
    "    def return_best_answer(self):\n",
    "        \"\"\"\n",
    "        Return the best answer for my node based on the confidence scores.\n",
    "        \"\"\"\n",
    "        ob_score = self.calculate_avg_log_probs(self.ob_log_probs)\n",
    "        cb_score = self.calculate_avg_log_probs(self.cb_log_probs)\n",
    "        #TODO:: Child aggregation score is implemented differently in the original probtree code, they use scores from children nodes as well.\n",
    "        child_aggreg_score = self.calculate_avg_log_probs(self.child_aggregation_log_probs)\n",
    "        if ob_score >= cb_score and ob_score >= child_aggreg_score:\n",
    "            return self.ob_answer\n",
    "        elif cb_score >= ob_score and cb_score >= child_aggreg_score:\n",
    "            return self.cb_answer\n",
    "        else:\n",
    "            return self.child_aggregation_answer\n",
    "        \n",
    "    def return_best_answer_score(self):\n",
    "        \"\"\"\n",
    "        Return the best answer's score for my node based on the confidence scores.\n",
    "        \"\"\"\n",
    "        ob_score = self.calculate_avg_log_probs(self.ob_log_probs)\n",
    "        cb_score = self.calculate_avg_log_probs(self.cb_log_probs)\n",
    "        child_aggreg_score = self.calculate_avg_log_probs(self.child_aggregation_log_probs)\n",
    "        return max(ob_score, cb_score, child_aggreg_score)\n",
    "    \n",
    "    def get_solved_nodes_in_my_subtree(self):\n",
    "        \"\"\"\n",
    "        Return a list of all nodes in the subtree rooted at the current node that are solved.\n",
    "        \"\"\"\n",
    "        solved_nodes = []\n",
    "        if self.solved:\n",
    "            solved_nodes.append(self)\n",
    "        for child in self.children:\n",
    "            solved_nodes.extend(child.get_solved_nodes_in_my_subtree())\n",
    "        return solved_nodes\n",
    "    \n",
    "    def add_solver_result(self, solver_name, answer, log_probs):\n",
    "        \"\"\"Store the result from a solver.\"\"\"\n",
    "        self.solver_results.append({\n",
    "            \"solver\": solver_name,\n",
    "            \"answer\": answer,\n",
    "            \"log_probs\": log_probs,\n",
    "        })\n",
    "\n",
    "    def plot_confidence_heatmap(self, log_probs_list):\n",
    "        def pad_arrays(log_probs_list, pad_value=np.nan):\n",
    "            \"\"\"Pad arrays in log_probs_list to make them the same length.\"\"\"\n",
    "            max_length = max(len(log_probs) for log_probs in log_probs_list)\n",
    "            padded_list = [\n",
    "                log_probs + [pad_value] * (max_length - len(log_probs))\n",
    "                for log_probs in log_probs_list\n",
    "            ]\n",
    "            return np.array(padded_list)\n",
    "        log_probs_list_padded = pad_arrays(log_probs_list)\n",
    "        plt.imshow(log_probs_list_padded, cmap=\"viridis\", aspect=\"auto\")\n",
    "        plt.colorbar(label=\"Log Probability\")\n",
    "        plt.xlabel(\"Token Position\")\n",
    "        plt.ylabel(\"Index\")\n",
    "        plt.title(\"Confidence Heatmap\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confidence_bars(self, log_probs_list):\n",
    "        avg_confidences = [np.mean(log_probs) for log_probs in log_probs_list]\n",
    "        plt.bar(range(len(avg_confidences)), avg_confidences)\n",
    "        plt.xlabel(\"Index\")\n",
    "        plt.ylabel(\"Average Confidence\")\n",
    "        plt.title(\"Confidence Scores\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confidence_bars_for_children(self):\n",
    "        log_probs_list = [child.decomposition_log_probs for child in self.children]\n",
    "        self.plot_confidence_bars(log_probs_list)\n",
    "\n",
    "    def plot_confidence_heatmap_for_children(self):\n",
    "        log_probs_list = [child.decomposition_log_probs for child in self.children]\n",
    "        self.plot_confidence_heatmap(log_probs_list)\n",
    "\n",
    "    def plot_confidence_bars_for_my_solvers(self):\n",
    "        # get all log probs for all solvers if they exists and call plot_confidence_bars\n",
    "        ob_log_probs = self.ob_log_probs\n",
    "        cb_log_probs = self.cb_log_probs\n",
    "        child_aggreg_log_probs = self.child_aggregation_log_probs\n",
    "        log_probs_list = [log_probs for log_probs in [ob_log_probs, cb_log_probs, child_aggreg_log_probs] if log_probs and log_probs != [-1000]]\n",
    "        self.plot_confidence_bars(log_probs_list)\n",
    "\n",
    "    def plot_confidence_heatmap_for_my_solvers(self):\n",
    "        # get all log probs for all solvers if they exists and call plot_confidence_heatmap\n",
    "        ob_log_probs = self.ob_log_probs\n",
    "        cb_log_probs = self.cb_log_probs\n",
    "        child_aggreg_log_probs = self.child_aggregation_log_probs\n",
    "        log_probs_list = [log_probs for log_probs in [ob_log_probs, cb_log_probs, child_aggreg_log_probs] if log_probs and log_probs != [-1000]]\n",
    "        self.plot_confidence_heatmap(log_probs_list)\n",
    "\n",
    "    def calculate_uncertainty(self, log_probs):\n",
    "        # Use the variance of log probabilities across tokens to estimate uncertainty.\n",
    "        # High variance indicates inconsistent confidence, which might signal a problematic node.\n",
    "        return np.var(log_probs)\n",
    "\n",
    "    def identify_low_confidence_tokens(self, log_probs, threshold=-0.1):\n",
    "        return [i for i, log_prob in enumerate(log_probs) if log_prob < threshold]\n",
    "\n",
    "class Action:\n",
    "    def execute(self, node):\n",
    "        \"\"\"Execute the action on the node.\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposeAction(Action):\n",
    "    def __init__(self, llm_query_function=query_llm):\n",
    "        self.llm_query_function = llm_query_function  # Function to query the LLM\n",
    "\n",
    "    def execute(self, node):\n",
    "        \"\"\"Decompose the node into one more child node.\"\"\"\n",
    "        prompt = self._create_decompose_prompt(node)\n",
    "        print(\"Prompt for expansion:\", prompt)\n",
    "        response, log_probs = self.llm_query_function(prompt)\n",
    "        print(\"LLM Response:\", response)\n",
    "        if response.lower() != \"done\":\n",
    "            # score = sum(log_probs) if log_probs else -100\n",
    "            child = Node(response, log_probs, node)\n",
    "            node.add_child(child)\n",
    "            return child\n",
    "        return None\n",
    "    \n",
    "    def execute_all(self, node, max_children=2):\n",
    "        \"\"\"Decompose the node into multiple child nodes.\"\"\"\n",
    "        children = []\n",
    "        while len(node.children) < max_children:\n",
    "            child = self.execute(node)\n",
    "            if child is None:\n",
    "                break\n",
    "            children.append(child)\n",
    "        return children\n",
    "\n",
    "    def _create_decompose_prompt(self, node: Node):\n",
    "        return f\"\"\"\n",
    "        You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
    "        - Current Node: The main question that needs to be broken down into smaller steps.\n",
    "        - Existing Children: A list of atomic subquestions (thoughts) already generated to help answer the main question.\n",
    "\n",
    "        ### Task:\n",
    "\n",
    "        1. **Carefully analyze the reasoning tree**:\n",
    "            - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
    "            - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
    "\n",
    "        2. **Follow these rules for decomposition**:\n",
    "            - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
    "            - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
    "            - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
    "            - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
    "                - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
    "                - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
    "            - **Atomic questions**: Each new child node must ask **one and only one question**. Do not combine multiple questions into a single node.\n",
    "\n",
    "        3. **Define stopping criteria**:\n",
    "            - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
    "            - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
    "            - Respond with \"Done\" in that case when no further decomposition is needed.\n",
    "\n",
    "        4. **Output Format**:\n",
    "            - Return either the new child node or \"Done\" without any additional context.\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Examples for Guidance\n",
    "\n",
    "        #### Example 1:\n",
    "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "        - Existing Children: []\n",
    "        - Response: \"How many members does The Border Surrender have?\"\n",
    "\n",
    "        #### Example 2:\n",
    "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "        - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
    "        - Response: \"How many members does Unsane have?\"\n",
    "\n",
    "        #### Example 3:\n",
    "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
    "        - Response: \"Which is larger, <1> or <2>?\"\n",
    "\n",
    "        #### Example 4:\n",
    "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
    "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
    "        - Response: \"Done\"\n",
    "\n",
    "        #### Example 5:\n",
    "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
    "        - Existing Children: []\n",
    "        - Response: \"Which city was Lake Wales Medical Center located in?\"\n",
    "\n",
    "        #### Example 6:\n",
    "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
    "        - Existing Children: [\"Which city was Lake Wales Medical Center located in?\"]\n",
    "        - Response: \"What was the 2014 population of <1>?\"\n",
    "\n",
    "        #### Example 7:\n",
    "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
    "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \\\"Power\\\"?\"]\n",
    "        - Response: \"<1> played a character on \\\"Entourage\\\" that has what last name?\"\n",
    "        \n",
    "        #### Example 8:\n",
    "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
    "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \\\"Power\\\"?\", \"<1> played a character on \\\"Entourage\\\" that has what last name?\"]\n",
    "        - Response: \"Done\"\n",
    "\n",
    "        #### Example 9:\n",
    "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
    "        - Existing Children: []\n",
    "        - Response: \"Who is Edburga of Minster-in-Thanet's father?\"\n",
    "\n",
    "        #### Example 10:\n",
    "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
    "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\"]\n",
    "        - Response: \"What year did <1> die?\"\n",
    "\n",
    "        #### Example 11:\n",
    "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
    "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\", \"What year did <1> die?\"]\n",
    "        - Response: \"Done\"\n",
    "\n",
    "        ---\n",
    "\n",
    "        - Current Node: {node.question}\n",
    "        - Existing Children: {[child.question for child in node.children]}\n",
    "        - Response:\n",
    "        \"\"\"\n",
    "    \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMBasedPruneAction(Action):\n",
    "    def __init__(self, llm_query_function=query_llm):\n",
    "        self.llm_query_function = llm_query_function  # Function to query the LLM\n",
    "\n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Prune irrelevant or redundant child nodes.\"\"\"\n",
    "        # Create a copy of the children list to avoid modifying it while iterating\n",
    "        updated_children = node.children.copy()\n",
    "\n",
    "        for child in node.children:\n",
    "            if self._should_prune(node, child, updated_children):\n",
    "                updated_children.remove(child)\n",
    "                print(f\"Pruned node: {child}\")\n",
    "\n",
    "        # Update the node's children with the pruned list\n",
    "        node.children = updated_children\n",
    "\n",
    "    def _should_prune(self, parent, child, updated_children):\n",
    "        \"\"\"Determine whether a child node should be pruned.\"\"\"\n",
    "        prompt = self._create_pruning_prompt(parent, child, updated_children)\n",
    "        print(\"Prompt for pruning:\", prompt)\n",
    "        response, _ = self.llm_query_function(prompt)\n",
    "        print(f\"Pruning response for '{child.question}': {response}\")\n",
    "        return response.strip().lower() == \"prune\"\n",
    "\n",
    "    def _create_pruning_prompt(self, parent, child, siblings):\n",
    "        \"\"\"Create a prompt for pruning a child node.\"\"\"\n",
    "        return f\"\"\"\n",
    "        You are helping to prune a reasoning tree. Here is the current state of the tree:\n",
    "        - Main Question: The root question that the reasoning tree is trying to answer.\n",
    "        - Current Node: A subquestion or step in the reasoning process.\n",
    "        - Siblings: Other subquestions or steps at the same level in the tree.\n",
    "\n",
    "        ### Task:\n",
    "\n",
    "        1. **Carefully analyze the reasoning tree**:\n",
    "            - Evaluate whether the current node is relevant to solving the main question.\n",
    "            - If the current node is irrelevant, redundant, or does not contribute meaningfully to solving the main question, respond with \"Prune\".\n",
    "            - If the current node is relevant and necessary, respond with \"Keep\".\n",
    "\n",
    "        2. **Follow these rules for pruning**:\n",
    "            - **Focus on relevance**: A node should be pruned if it does not directly contribute to solving the main question.\n",
    "            - **Avoid redundancy**: Prune nodes that repeat or rephrase existing information from siblings without adding new insights.\n",
    "            - **Simplify complexity**: Prune nodes that introduce unnecessary complexity or depth without advancing the reasoning process.\n",
    "            - **Handle references**: If the current node references answers from previous nodes (e.g., using placeholders like `<1>`, `<2>`, etc.), ensure that the referenced nodes are relevant and necessary. If the referenced nodes are pruned, the current node may also need to be pruned.\n",
    "\n",
    "        3. **Output Format**:\n",
    "            - Return either \"Prune\" or \"Keep\" without any additional context.\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Examples for Guidance\n",
    "\n",
    "        #### Example 1:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Current Node: \"What is the population of Paris?\"\n",
    "        - Siblings: [\"What is the name of the capital city of France?\"]\n",
    "        - Response: \"Prune\"  # Not directly relevant to the main question\n",
    "\n",
    "        #### Example 2:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Current Node: \"What is the name of the capital city of France?\"\n",
    "        - Siblings: [\"What is the population of Paris?\"]\n",
    "        - Response: \"Keep\"  # Directly relevant to the main question\n",
    "\n",
    "        #### Example 3:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Current Node: \"What is the population of France?\"\n",
    "        - Siblings: [\"What is the name of the capital city of France?\"]\n",
    "        - Response: \"Prune\"  # Not directly relevant to the main question\n",
    "\n",
    "        #### Example 4:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Current Node: \"What is the name of the capital city of France?\"\n",
    "        - Siblings: [\"What is the population of France?\"]\n",
    "        - Response: \"Keep\"  # Directly relevant to the main question\n",
    "\n",
    "        #### Example 5:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Current Node: \"What is the population of Paris?\"\n",
    "        - Siblings: [\"What is the name of the capital city of France?\", \"What is the population of France?\"]\n",
    "        - Response: \"Prune\"  # Redundant with siblings and not directly relevant\n",
    "\n",
    "        #### Example 6:\n",
    "        - Main Question: \"Does The Border Surrender or Unsane have more members?\"\n",
    "        - Current Node: \"Which is larger, <1> or <2>?\"\n",
    "        - Siblings: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
    "        - Response: \"Keep\"  # Directly relevant and references necessary information\n",
    "\n",
    "        ---\n",
    "\n",
    "        - Main Question: {parent.question}\n",
    "        - Current Node: {child.question}\n",
    "        - Siblings: {[sibling.question for sibling in siblings if sibling.question != child.question]}\n",
    "        - Response:\n",
    "        \"\"\"\n",
    "    \n",
    "\n",
    "class ConfidenceBasedPruneAction(Action):\n",
    "    def __init__(self, uncertainty_threshold=0.05, len_low_confidence_tokens_threshold=5, avg_log_prob_threshold=-0.1):\n",
    "        self.uncertainty_threshold = uncertainty_threshold  # Prune if uncertainty > threshold\n",
    "        self.len_low_confidence_tokens_threshold = len_low_confidence_tokens_threshold  # Prune if len(low-confidence tokens) > threshold\n",
    "        self.avg_log_prob_threshold = avg_log_prob_threshold  # Prune if avg log probs < threshold\n",
    "        pass\n",
    "\n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Prune irrelevant or redundant child nodes.\"\"\"\n",
    "        # Create a copy of the children list to avoid modifying it while iterating\n",
    "        updated_children = node.children.copy()\n",
    "\n",
    "        for child in node.children:\n",
    "            if self._should_prune(child):\n",
    "                updated_children.remove(child)\n",
    "                print(f\"Pruned node: {child}\")\n",
    "\n",
    "        # Update the node's children with the pruned list\n",
    "        node.children = updated_children\n",
    "\n",
    "    def _should_prune(self, child):\n",
    "        \"\"\"Determine whether a child node should be pruned based on the confidence score.\"\"\"\n",
    "        print(f\"Checking if node '{child.question}' should be pruned.\")\n",
    "        # Use the variance of log probabilities across tokens to estimate uncertainty. High variance indicates inconsistent confidence, which might signal a problematic node.\n",
    "        uncertainty = child.calculate_uncertainty(child.decomposition_log_probs)\n",
    "        # return list of the tokens with low confidence, so we may use the length of this list as a metric.\n",
    "        low_confidence_tokens = child.identify_low_confidence_tokens(child.decomposition_log_probs)\n",
    "        # Average log probs of the child node to use as a metric.\n",
    "        avg_log_probs = child.calculate_avg_log_probs(child.decomposition_log_probs)\n",
    "\n",
    "        # Prune if uncertainty is too high\n",
    "        if uncertainty > self.uncertainty_threshold:\n",
    "            print(f\"Pruning due to high uncertainty: {uncertainty}\")\n",
    "            return True\n",
    "\n",
    "        # Prune if there are too many low-confidence tokens\n",
    "        if len(low_confidence_tokens) > self.len_low_confidence_tokens_threshold:\n",
    "            print(f\"Pruning due to low-confidence tokens: {len(low_confidence_tokens)}\")\n",
    "            return True\n",
    "\n",
    "        # Prune if average log probabilities are too low\n",
    "        if avg_log_probs < self.avg_log_prob_threshold:\n",
    "            print(f\"Pruning due to low average log probs: {avg_log_probs}\")\n",
    "            return True\n",
    "\n",
    "        print(\"Node passed all pruning criteria.\")\n",
    "        # Otherwise, keep the node\n",
    "        return False\n",
    "        \n",
    "\n",
    "# print(\"first child, second child (second one was so bad)\")\n",
    "# print(\"calculate_uncertainty:\", root_node.children[0].calculate_uncertainty(root_node.children[0].decomposition_log_probs), root_node.children[1].calculate_uncertainty(root_node.children[1].decomposition_log_probs))\n",
    "# print(\"low conf tokens:\", root_node.children[0].identify_low_confidence_tokens(root_node.children[0].decomposition_log_probs), root_node.children[1].identify_low_confidence_tokens(root_node.children[1].decomposition_log_probs))\n",
    "# print(\"avg log probs:\", root_node.children[0].calculate_avg_log_probs(root_node.children[0].decomposition_log_probs), root_node.children[1].calculate_avg_log_probs(root_node.children[1].decomposition_log_probs))\n",
    "\n",
    "# calculate_uncertainty: 0.027343752204908728 0.08293155082718029\n",
    "# low conf tokens: [0, 3, 7] [0, 1, 2, 4, 8, 13, 15, 16, 19]\n",
    "# avg log probs: -0.0604590557338379 -0.2261969573251304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/97g04f6j0xbd6n9kfwf97fs00000gn/T/ipykernel_84644/1306752305.py:10: DeprecationWarning: The StanfordParser will be deprecated\n",
      "Please use \u001b[91mnltk.parse.corenlp.CoreNLPParser\u001b[0m instead.\n",
      "  parser = stanford.StanfordParser(model_path=\"./stanford-parser-full-2020-11-17/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.parse import stanford\n",
    "from POSTree import POSTree\n",
    "\n",
    "# Set the path to the Stanford Parser JAR files\n",
    "os.environ['STANFORD_PARSER'] = './stanford-parser-full-2020-11-17/stanford-parser.jar'\n",
    "os.environ['STANFORD_MODELS'] = './stanford-parser-full-2020-11-17/stanford-parser-4.2.0-models.jar'\n",
    "\n",
    "# Initialize the Stanford Parser\n",
    "parser = stanford.StanfordParser(model_path=\"./stanford-parser-full-2020-11-17/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n",
    "\n",
    "class SimulateAnswerAction(Action):\n",
    "    def __init__(self, parser, llm_query_function=query_llm):\n",
    "        self.llm_query_function = llm_query_function  # Function to query the LLM\n",
    "        self.parser = parser  # Stanford Parser instance\n",
    "\n",
    "    def execute(self, node):\n",
    "        \"\"\"Simulate answers for child nodes and evaluate if they solve the original problem.\"\"\"\n",
    "        simulated_answers = []\n",
    "        i = 1\n",
    "        for child in node.children:\n",
    "            # TODO:: Should we just include the answered ones, like to know given those answered ones, are they enough to solve the main question ?\n",
    "            # But thats different, because original purpose is to know given all children, are they enough to solve parent node. so take care.\n",
    "            # if child.solved == False:\n",
    "            #     continue\n",
    "            # Parse the child question into an answer-like format\n",
    "            answer_format = self._parse_question_to_answer(child, i)\n",
    "            simulated_answers.append(answer_format)\n",
    "            i += 1\n",
    "\n",
    "        print(f\"Simulated answers for '{node.question}': {simulated_answers}\")\n",
    "        # Ask the LLM if the simulated answers solve the original problem\n",
    "        prompt = self._create_evaluation_prompt(node.question, simulated_answers)\n",
    "        response, _ = self.llm_query_function(prompt)\n",
    "        print(f\"Evaluation response for '{node.question}': {response}\")\n",
    "        if response.strip().lower() == \"solved\":\n",
    "            # may need to mark that the node can be solved with these set of children.\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    #TODO:: We need to take care of the references correctly !!!\n",
    "    # Forexample if you have <1> in your question we should replace it with [ANSWER_1] in the answer.\n",
    "    def _parse_question_to_answer(self, node: Node, i):\n",
    "        \"\"\"Convert a question into an answer-like format using the parser.\"\"\"\n",
    "        parse_trees = self.parser.raw_parse(node.question)\n",
    "        # Use a try catch block to handle parsing errors\n",
    "        try:\n",
    "            for tree in parse_trees:\n",
    "                tree = POSTree(str(tree))\n",
    "                tree = tree.adjust_order()\n",
    "                # replace **blank** substring with [ANSWER_1], [ANSWER_2], etc.\n",
    "                placeholder = f\"[ANSWER_{i}]\"\n",
    "                tree = tree.replace(\"**blank**\", placeholder)                \n",
    "                return tree\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing question: {question}\")\n",
    "            return question\n",
    "    \n",
    "    def _create_evaluation_prompt(self, main_question, simulated_answers):\n",
    "        \"\"\"Create a prompt to evaluate if the simulated answers solve the main question.\"\"\"\n",
    "        return f\"\"\"\n",
    "        You are helping to evaluate whether a set of simulated answers would solve a main question. Here is the current state of the problem:\n",
    "        - Main Question: {main_question}\n",
    "        - Simulated Answers: {simulated_answers}\n",
    "\n",
    "        ### Important Notes:\n",
    "        - The answers provided are **simulated** and contain placeholders (e.g., `[ANSWER_1]`, `[ANSWER_2]`) instead of actual facts.\n",
    "        - Each placeholder (e.g., `[ANSWER_1]`, `[ANSWER_2]`) represents a **distinct piece of information**.\n",
    "        - Your task is to evaluate whether the **structure** and **content** of these simulated answers would be sufficient to solve the main question if the placeholders were filled with accurate information.\n",
    "\n",
    "        ### Task:\n",
    "\n",
    "        1. **Carefully analyze the main question and the simulated answers**:\n",
    "            - Evaluate whether the simulated answers collectively provide enough **structure** and **coverage** to answer the main question.\n",
    "            - If the answers are sufficient, respond with \"Solved\".\n",
    "            - If the answers are insufficient or missing critical information, respond with \"Unsolved\".\n",
    "\n",
    "        2. **Follow these rules for evaluation**:\n",
    "            - **Focus on completeness**: Ensure that all aspects of the main question are addressed by the simulated answers.\n",
    "            - **Check for relevance**: Ensure that the simulated answers are directly related to the main question.\n",
    "            - **Identify gaps**: If any part of the main question is not addressed, note it in your response.\n",
    "\n",
    "        3. **Output Format**:\n",
    "            - Return either \"Solved\" or \"Unsolved\" without any additional context.\n",
    "\n",
    "        ---\n",
    "\n",
    "        ### Examples for Guidance\n",
    "\n",
    "        #### Example 1:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Simulated Answers: [\"The capital of France is [ANSWER_1].\"]\n",
    "        - Response: \"Solved\"  # The structure is sufficient to answer the question.\n",
    "\n",
    "        #### Example 2:\n",
    "        - Main Question: \"What is the capital of France?\"\n",
    "        - Simulated Answers: [\"The population of Paris is [ANSWER_1].\"]\n",
    "        - Response: \"Unsolved\"  # The answer is not relevant to the main question.\n",
    "\n",
    "        #### Example 3:\n",
    "        - Main Question: \"What is the population of the land of a thousand lakes?\"\n",
    "        - Simulated Answers: [\"The land of a thousand lakes is [ANSWER_1].\", \"The population of [ANSWER_1] is [ANSWER_2].\"]\n",
    "        - Response: \"Solved\"  # Both answers are needed to solve the question.\n",
    "\n",
    "        ---\n",
    "\n",
    "        - Main Question: {main_question}\n",
    "        - Simulated Answers: {simulated_answers}\n",
    "        - Response:\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ahmed is [ANSWER_1] a software engineer'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _parse_question_to_answer(node: Node, i):\n",
    "        \"\"\"Convert a question into an answer-like format using the parser.\"\"\"\n",
    "        parse_trees = parser.raw_parse(node.question)\n",
    "        # Use a try catch block to handle parsing errors\n",
    "        try:\n",
    "            for tree in parse_trees:\n",
    "                tree = POSTree(str(tree))\n",
    "                tree = tree.adjust_order()\n",
    "                # replace **blank** substring with [ANSWER_1], [ANSWER_2], etc.\n",
    "                placeholder = f\"[ANSWER_{i}]\"\n",
    "                tree = tree.replace(\"**blank**\", placeholder)                \n",
    "                return tree\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing question: {question}\")\n",
    "            return question\n",
    "        \n",
    "\n",
    "_parse_question_to_answer(Node(\"Is ahmed a software engineer?\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosedBookSolving(Action):\n",
    "    def __init__(self, llm_query_function=query_llm):\n",
    "        self.llm_query_function = llm_query_function\n",
    "\n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Solve the node by querying the LLM.\"\"\"\n",
    "        print(f\"Solving node '{node.question}' using the Closed-Book model.\")\n",
    "        # if node.solved:\n",
    "        if node.solved and node.cb_answer:\n",
    "            print(f\"Node '{node.question}' is already solved using the Closed-Book model : {node.return_best_answer()}\")\n",
    "            return node.return_best_answer()\n",
    "        \n",
    "        question = node.question # dont change the original question, we may need it later.\n",
    "\n",
    "        # if you have dependencies as <1> in your question that are not solved, solve them first and then solve this node.\n",
    "        ref_tokens = re.findall(r\"<\\d+>\", question)\n",
    "        if len(ref_tokens):\n",
    "            children_indices = [int(token[1:-1]) for token in ref_tokens]\n",
    "            print(f\"Node '{question}' has dependencies on children: {children_indices}. Solving them first.\")\n",
    "            for i in children_indices:\n",
    "                print(f\"Solving child of <{i}> of node '{question}'\")\n",
    "                # i-1 because children are 0 indexed while in question they are 1 indexed.\n",
    "                child = node.parent.children[i-1] # .parent.children because he is my sibling and i want to solve him.\n",
    "                # Its better to get the best answer from the child instead of using the same solver again.\n",
    "                # answer = self.execute(child)\n",
    "                answer = child.return_best_answer()\n",
    "                # replace the placeholder with the answer in the question.\n",
    "                question = question.replace(f\"<{i}>\", answer)\n",
    "\n",
    "        prompt = self._create_solving_prompt(question)\n",
    "        print(\"Prompt for solving:\", prompt)\n",
    "        response, log_probs = self.llm_query_function(prompt)\n",
    "        print(f\"LLM Response for '{question}': {response}\")\n",
    "        \n",
    "        if response:\n",
    "            # Extract the answer from the response\n",
    "            answer = self._extract_answer(response)\n",
    "            if answer:\n",
    "                node.solved = True\n",
    "                node.cb_answer = answer\n",
    "                node.cb_log_probs = log_probs\n",
    "                print(f\"Extracted answer: {answer}\")\n",
    "                return answer\n",
    "            else:\n",
    "                # TODO:: we should handle this case better, maybe reask the question or something else.\n",
    "                print(\"Failed to extract answer from the response.\")\n",
    "        return None\n",
    "\n",
    "    def _extract_answer(self, response):\n",
    "        \"\"\"Extract the answer from the LLM's response.\"\"\"\n",
    "        # Look for the phrase \"So the answer is:\" and extract the text after it\n",
    "        answer_prefix = \"So the answer is:\"\n",
    "        if answer_prefix in response:\n",
    "            # Split the response at the prefix and take the part after it\n",
    "            answer = response.split(answer_prefix)[-1].strip()\n",
    "            # Remove any trailing punctuation or extra spaces\n",
    "            answer = answer.rstrip(\".\").strip()\n",
    "            return answer\n",
    "        return None\n",
    "\n",
    "    def _create_solving_prompt(self, question):\n",
    "        return f\"\"\"\n",
    "        Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
    "        The exact format should be:\n",
    "        [Explanation]. So the answer is: [Answer]\n",
    "\n",
    "        Example Format:\n",
    "\n",
    "        Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
    "        A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
    "\n",
    "        Q: How many episodes were in the South Korean television series in which Ryu Hye-young played Bo-ra?\n",
    "        A: The South Korean television series in which Ryu Hye-young played Bo-ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
    "\n",
    "        Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
    "        A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
    "\n",
    "        Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
    "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
    "\n",
    "        Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
    "        A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
    "\n",
    "        Q: In what country was Lost Gravity manufactured?\n",
    "        A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
    "\n",
    "        Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
    "        A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
    "\n",
    "        Q: Was Lonny (magazine) was founded in 2009?\n",
    "        A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
    "\n",
    "        Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para-military training?\n",
    "        A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para-military training in Afghanistan. So the answer is: Afghanistan.\n",
    "\n",
    "        Q: Does The Border Surrender or Unsane have more members?\n",
    "        A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
    "\n",
    "        Q: James Paris Lee is best known for investing the Lee-Metford rifle and another rifle often referred to by what acronymn?\n",
    "        A: James Paris Lee is best known for investing the Lee-Metford rifle and Lee-Enfield series of rifles. Lee-Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
    "\n",
    "        Q: Was Lonny (magazine) was founded in 2008?\n",
    "        A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
    "\n",
    "        Q: What year did Edburga of Minster-in-Thanet's father die?\n",
    "        A: The father of Edburga of Minster-in-Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
    "\n",
    "        Q: Were Lonny and Allure both founded in the 1990s?\n",
    "        A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
    "\n",
    "        Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
    "        A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
    "\n",
    "        Q: When was Jan de Bont born?\n",
    "        A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
    "\n",
    "        Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
    "        A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
    "\n",
    "        Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
    "        A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
    "\n",
    "        Q: Are both Bruce Chatwin and O. Henry writers?\n",
    "        A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
    "\n",
    "        Q: Which city is Lake Wales Medical Center located?\n",
    "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
    "\n",
    "        Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
    "        A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
    "\n",
    "        Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
    "        A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
    "\n",
    "        Now, please answer the following question in the same format:\n",
    "        Q: {question}\n",
    "        A: \n",
    "        \"\"\"\n",
    "\n",
    "class OpenBookSolving(Action):\n",
    "    def __init__(self, llm_query_function=query_llm, external_knowledge_query_function=bm25_search):\n",
    "        self.llm_query_function = llm_query_function\n",
    "        self.external_knowledge_query_function = external_knowledge_query_function\n",
    "\n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Solve the node by querying the LLM.\"\"\"\n",
    "        print(f\"Solving node '{node.question}' using the Open-Book model.\")\n",
    "        # if node.solved:\n",
    "        if node.solved and node.ob_answer:\n",
    "            print(f\"Node '{node.question}' is already solved using the Open-Book model: {node.return_best_answer()}\")\n",
    "            return node.return_best_answer()\n",
    "        \n",
    "        topic_entities = []\n",
    "        question = node.question # dont change the original question, we may need it later.\n",
    "        # if you have dependencies as <1> in your question that are not solved, solve them first and then solve this node.\n",
    "        ref_tokens = re.findall(r\"<\\d+>\", question)\n",
    "        if len(ref_tokens):\n",
    "            children_indices = [int(token[1:-1]) for token in ref_tokens]\n",
    "            print(f\"Node '{question}' has dependencies on children: {children_indices}. Solving them first.\")\n",
    "            for i in children_indices:\n",
    "                print(f\"Solving child of <{i}> of node '{question}'\")\n",
    "                # i-1 because children are 0 indexed while in question they are 1 indexed.\n",
    "                child = node.parent.children[i-1] # .parent.children because he is my sibling and i want to solve him.\n",
    "                # Its better to get the best answer from the child instead of using the same solver again.\n",
    "                # answer = self.execute(child)\n",
    "                answer = child.return_best_answer()\n",
    "                # replace the placeholder with the answer in the question.\n",
    "                question = question.replace(f\"<{i}>\", answer)\n",
    "                topic_entities.append(answer)\n",
    "        \n",
    "        # TODO:: I am also thinking of adding my children answers to the topic_entities, so that they can be used in the external knowledge search.\n",
    "        # This was not in the original code, but i think it can be useful. It will be some kind of child aggregation also embedded in the ob ? \n",
    "        # I think that will be so useful, especially if we decided not to solve by all types, but by only one of them for example.\n",
    "        # for child in node.children:\n",
    "        #     if child.solved:\n",
    "        #         topic_entities.append(child.return_best_answer())\n",
    "\n",
    "        print(f\"node question after replacing dependencies: {question}\")\n",
    "        \n",
    "        # Get relevant contexts from external knowledge sources\n",
    "        contexts = self._get_contexts(question, topic_entities)\n",
    "        prompt = self._create_solving_prompt(question, contexts)\n",
    "        print(\"Prompt for solving:\", prompt)\n",
    "        response, log_probs = self.llm_query_function(prompt)\n",
    "        print(f\"LLM Response for '{node.question}': {response}\")\n",
    "        \n",
    "        if response:\n",
    "            # Extract the answer from the response\n",
    "            answer = self._extract_answer(response)\n",
    "            if answer:\n",
    "                node.solved = True\n",
    "                node.ob_answer = answer\n",
    "                if \"unknown\" not in answer.lower():\n",
    "                    node.ob_log_probs = log_probs\n",
    "                else:\n",
    "                    node.ob_log_probs = [-1000]\n",
    "                    \n",
    "                print(f\"Extracted answer: {answer}\")\n",
    "                return node.ob_answer\n",
    "            else:\n",
    "                print(\"Failed to extract answer from the response.\")\n",
    "                \n",
    "                # TODO:: we should handle this case better, maybe reask the question or something else.\n",
    "        return None\n",
    "\n",
    "    def _extract_answer(self, response):\n",
    "        \"\"\"Extract the answer from the LLM's response.\"\"\"\n",
    "        # Look for the phrase \"So the answer is:\" and extract the text after it\n",
    "        answer_prefix = \"So the answer is:\"\n",
    "        if answer_prefix in response:\n",
    "            # Split the response at the prefix and take the part after it\n",
    "            answer = response.split(answer_prefix)[-1].strip()\n",
    "            # Remove any trailing punctuation or extra spaces\n",
    "            answer = answer.rstrip(\".\").strip()\n",
    "            # if \"unknown\" not in answer.lower():\n",
    "            return answer\n",
    "        return None\n",
    "    \n",
    "    def _get_contexts(self, question, topic_entities):\n",
    "        for k in range(5, 0, -1):\n",
    "            contexts = []\n",
    "            hist = set()\n",
    "            # i have made serpapi off, since the quota is 100 only / month ! :(\n",
    "            r = bm25_search(question, k, use_serpapi=False) \n",
    "            for datum in r:\n",
    "                title, text = datum[\"title\"], datum[\"text\"]\n",
    "                stamp = title + text\n",
    "                if not stamp in hist:\n",
    "                    hist.add(stamp)\n",
    "                    contexts.append([title, text])\n",
    "            for e in topic_entities:\n",
    "                r = bm25_search(e, k, use_serpapi=False)\n",
    "                for datum in r:\n",
    "                    title, text = datum[\"title\"], datum[\"text\"]\n",
    "                    stamp = title + text\n",
    "                    if stamp not in hist:\n",
    "                        contexts.append([title, text])\n",
    "                        hist.add(stamp)\n",
    "        \n",
    "        return contexts\n",
    "\n",
    "    # TODO:: I just used the single-hop prompt, havent used multi-hop prompt yet.\n",
    "    def _create_solving_prompt(self, question, contexts):\n",
    "        return f\"\"\"\n",
    "        Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
    "        Answer in the following format:\n",
    "        [Explanation]. So the answer is: [Answer]\n",
    "\n",
    "        #1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
    "        Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
    "        #2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
    "        Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
    "        #3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
    "        Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
    "        Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour staged?\n",
    "        A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
    "\n",
    "        #1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
    "        Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
    "        #2 Wikipedia Title: Hallelujah I Love Her So\n",
    "        Text: \"Hallelujah I Love Her So\" Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B-side \"What Would I Do Without You\" Released 1956 Format 7\" 45rpm Recorded 1956 Genre Soul, rhythm and blues Length 2:35 Label Atlantic Songwriter(s) Ray Charles Producer(s) Jerry Wexler.\n",
    "        #3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
    "        Text: \"The First Time Ever I Saw Your Face\" Single by Roberta Flack from the album First Take Released March 7, 1972 Recorded 1969 Genre Soul, vocal jazz Length 5:22 Label Atlantic Songwriter(s) Ewan MacColl Producer(s) Joel Dorn.\n",
    "        Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
    "        A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
    "{''.join(f\"\\n        #{idx + 1} Wikipedia Title: {title}\\n        Text: {text}\" for idx, (title, text) in enumerate(contexts))}\n",
    "        Q: {question}\n",
    "        A:\n",
    "        \"\"\"\n",
    "\n",
    "class ChildrenAggregationSolving(Action):\n",
    "    def __init__(self, llm_query_function=query_llm, external_knowledge_query_function=bm25_search):\n",
    "        self.llm_query_function = llm_query_function\n",
    "        self.external_knowledge_query_function = external_knowledge_query_function\n",
    "    \n",
    "    def resolve_references(self, child_question, siblings):\n",
    "        # resolve the references in the child question given his siblings.\n",
    "        ref_tokens = re.findall(r\"<\\d+>\", child_question)\n",
    "        if len(ref_tokens):\n",
    "            children_indices = [int(token[1:-1]) for token in ref_tokens]\n",
    "            for i in children_indices:\n",
    "                child = siblings[i-1]\n",
    "                # Its better to get the best answer from the child instead of using the same solver again.\n",
    "                # ref_answer = self.execute(child)\n",
    "                ref_answer = child.return_best_answer()\n",
    "                # replace the placeholder with the answer in the question.\n",
    "                child_question = child_question.replace(f\"<{i}>\", ref_answer)\n",
    "        return child_question\n",
    "                    \n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Solve the node by querying the LLM.\"\"\"\n",
    "        print(f\"Solving node '{node.question}' using the Children Aggregation model.\")\n",
    "        # if node.solved:\n",
    "        if node.solved and node.child_aggregation_answer:\n",
    "            print(f\"Node '{node.question}' is already solved using the Children Aggregation model: {node.return_best_answer()}\")\n",
    "            return node.return_best_answer()\n",
    "        \n",
    "        if len(node.children) == 0:\n",
    "            print(f\"Node '{node.question}' has no children to aggregate.\")\n",
    "            return None\n",
    "        \n",
    "        if all(child.solved for child in node.children) == False:\n",
    "            print(f\"Node '{node.question}' has unsolved children to aggregate.\")\n",
    "            return None\n",
    "        \n",
    "        # Note, in original prob tree, they did the decomposition in one shot, so he used one probability for the whole decomposition of the question (saved in parent).\n",
    "        # while, in our case we do node by node, so we have decomposition log probs for each child node.\n",
    "        question = node.question\n",
    "        contexts = []\n",
    "        for child in node.children:\n",
    "            child_question = child.question\n",
    "            # we need to resolve the references in the child question given his siblings, since we will put it inside the prompt.\n",
    "            child_question = self.resolve_references(child_question, node.children)\n",
    "            child_answer = child.return_best_answer()\n",
    "            contexts.append(f\"{child_question} {child_answer}\")\n",
    "\n",
    "        prompt = self._create_solving_prompt(question, contexts)        \n",
    "        print(\"Prompt for solving:\", prompt)\n",
    "        \n",
    "        response, log_probs = self.llm_query_function(prompt)\n",
    "        print(f\"LLM Response for '{node.question}': {response}\")\n",
    "        \n",
    "        if response:\n",
    "            # Extract the answer from the response\n",
    "            answer = self._extract_answer(response)\n",
    "            if answer:\n",
    "                node.solved = True\n",
    "                node.child_aggregation_answer = answer\n",
    "                if \"unknown\" not in answer.lower():\n",
    "                    node.child_aggregation_log_probs = log_probs\n",
    "                else:\n",
    "                    node.child_aggregation_log_probs = [-1000]\n",
    "                print(f\"Extracted answer: {answer}\")\n",
    "                return node.child_aggregation_answer\n",
    "            else:\n",
    "                print(\"Failed to extract answer from the response.\")\n",
    "                # TODO:: we should handle this case better, maybe reask the question or something else.\n",
    "        return None\n",
    "\n",
    "    def _extract_answer(self, response):\n",
    "        \"\"\"Extract the answer from the LLM's response.\"\"\"\n",
    "        # Look for the phrase \"So the answer is:\" and extract the text after it\n",
    "        answer_prefix = \"So the answer is:\"\n",
    "        if answer_prefix in response:\n",
    "            # Split the response at the prefix and take the part after it\n",
    "            answer = response.split(answer_prefix)[-1].strip()\n",
    "            # Remove any trailing punctuation or extra spaces\n",
    "            answer = answer.rstrip(\".\").strip()\n",
    "            # if \"unknown\" not in answer.lower():\n",
    "            return answer\n",
    "        return None\n",
    "\n",
    "    def _create_solving_prompt(self, question, contexts):\n",
    "        return f\"\"\"\n",
    "        Given a question and context, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
    "        Answer in the following format:\n",
    "        [Explanation]. So the answer is: [Answer]\n",
    "\n",
    "        #\n",
    "        Context:\n",
    "        Which famous fashion show Stella Maxwell has been a model for? Victoria's Secret.\n",
    "        Since when Victoria's Secret? 1977.\n",
    "\n",
    "        Question:\n",
    "        Stella Maxwell has been a model for a famous fashion shown since when?\n",
    "\n",
    "        Answer:\n",
    "        Stella Maxwell has been a model for a famous fashion shown, Victoria's Secret since 2015. So the answer is: since 2015.\n",
    "        #\n",
    "        Context:\n",
    "        Who is the American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers? Devean George.\n",
    "        William Novac co-wrote the memoir of Devean George? no.\n",
    "\n",
    "        Question:\n",
    "        William Novac co-wrote the memoir of what American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers?\n",
    "\n",
    "        Answer:\n",
    "        William Novac co-wrote the memoir of Magic Johnson, an American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers. So the answer is: Magic Johnson.\n",
    "        #\n",
    "        Context:\n",
    "        Which athlete rode 400 miles across his country to bring attention to the plight of the disabled in the country? Emmanuel Ofosu Yeboah.\n",
    "        What is the title of the documentary narrated by Oprah Winfrey about Emmanuel Ofosu Yeboah? Emmanuel's Gift.\n",
    "\n",
    "        Question:\n",
    "        Oprah Winfrey narrated a documentary about this athlete who rode 400 miles across his country to bring attention to the plight of the disabled in the country?\n",
    "\n",
    "        Answer:\n",
    "        Oprah Winfrey narrated a documentary about the athelete Emmanuel Ofosu Yeboah, who rode 400 miles across his country to bring attention to the plight of the disabled in the country. So the answer is: Emmanuel Ofosu Yeboah.\n",
    "        #\n",
    "        Context:\n",
    "{''.join(f\"        {context}\\n\" for context in contexts)}\n",
    "        Question:\n",
    "        {question}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySolvingStrategy(Action):\n",
    "    def __init__(self, solvers: Action):\n",
    "        self.solvers = solvers\n",
    "        pass\n",
    "\n",
    "    # TODO:: if the child node also have children, we should solve them first. For now we are just solving the most confident child directly, without checking its children.\n",
    "    # TODO:: what if the order matters like we wanted to solve node that contains <1> and node 1 not solved ?? :) should we solve our dependency first ??\n",
    "    def execute(self, node: Node):\n",
    "            \"\"\"\n",
    "            Solve the most confident child first and check if it resolves the parent node's question.\n",
    "            \"\"\"\n",
    "\n",
    "            # Get the most confident child thats still unsolved.\n",
    "            confident_children_sorted = node.get_confident_children_sorted()\n",
    "            most_confident_unsolved_child = None\n",
    "            for child in confident_children_sorted:\n",
    "                if not child.solved:\n",
    "                    most_confident_unsolved_child = child\n",
    "                    break\n",
    "            \n",
    "            if most_confident_unsolved_child is None:\n",
    "                print(f\"No unsolved children found for node: {node.question}, so will solve it directly.\")\n",
    "                # TODO:: should we solve the node itself if all children are solved ??\n",
    "                # but thats wrong, because we then dont make use of the children to solve the parent node, we just solve parent as same as children. ???\n",
    "                self.choose_solver_and_execute(node)\n",
    "                return\n",
    "                # return False\n",
    "            \n",
    "            print(f\"Solving most confident child: {most_confident_unsolved_child.question}\")\n",
    "            # Solve the most confident child\n",
    "            self.choose_solver_and_execute(most_confident_unsolved_child)\n",
    "\n",
    "            # TODO:: Check if the solution resolves the parent node's question\n",
    "            # Still not sure how can we check this, was the simulation enough for that? I'd say yes. But do it step by step. or like include solved ones only.\n",
    "            # # Check if the solution resolves the parent node's question\n",
    "            # if node.solved:\n",
    "            #     print(f\"Parent node {node.question} resolved by: {most_confident_unsolved_child.question}\")\n",
    "            #     return True\n",
    "\n",
    "            # # If not, proceed to the next most confident child\n",
    "            # print(f\"Parent node {node.question} still not resolved.\")\n",
    "            # return False\n",
    "\n",
    "    def choose_solver_and_execute(self, node: Node):\n",
    "        # Choosing a random solving strategy, either Closed-Book, Open-Book, or Children Aggregation\n",
    "        random_index = random.randint(0, len(self.solvers) - 1)\n",
    "        print(f\"Using solving strategy: {random_index}\")\n",
    "        solver = self.solvers[random_index]\n",
    "        # Solve the node\n",
    "        solver.execute(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceSolver:\n",
    "    def __init__(self, cb_solver: Action, ob_solver: Action, child_agg_solver: Action):\n",
    "        self.solvers = [cb_solver, ob_solver, child_agg_solver]\n",
    "\n",
    "    def execute(self, node: Node):\n",
    "        \"\"\"Solve the tree using brute-force backtracking.\"\"\"\n",
    "        self._solve_node(node)\n",
    "        best_combination = self._find_best_combination(node)\n",
    "        return best_combination\n",
    "\n",
    "    def _solve_node(self, node: Node):\n",
    "        \"\"\"Solve a node with all solvers and recursively solve its children.\"\"\"\n",
    "        # Recursively solve children first\n",
    "        for child in node.children:\n",
    "            self._solve_node(child)\n",
    "\n",
    "        # Solve the node with all solvers\n",
    "        for solver in self.solvers:\n",
    "            solver.execute(node)\n",
    "            if solver.__class__.__name__ == \"ClosedBookSolving\":\n",
    "                node.add_solver_result(\"Closed-Book\", node.cb_answer, node.cb_log_probs)\n",
    "            elif solver.__class__.__name__ == \"OpenBookSolving\":\n",
    "                node.add_solver_result(\"Open-Book\", node.ob_answer, node.ob_log_probs)\n",
    "            elif solver.__class__.__name__ == \"ChildAggregationSolving\" and len(node.children) > 0:\n",
    "                node.add_solver_result(\"Child Aggregation\", node.child_aggregation_answer, node.child_aggregation_log_probs)\n",
    "\n",
    "    def _find_best_combination(self, node: Node):\n",
    "        \"\"\"Find the best combination of solver outputs for the tree.\"\"\"\n",
    "        if not node.children:\n",
    "            # For leaf nodes, return all solver results\n",
    "            return [node.solver_results]\n",
    "\n",
    "        # For non-leaf nodes, combine children's results with the current node's results\n",
    "        child_combinations = []\n",
    "        for child in node.children:\n",
    "            child_combinations.append(self._find_best_combination(child))\n",
    "\n",
    "        # Generate all combinations of solver outputs\n",
    "        combinations = []\n",
    "        for child_combination in child_combinations:\n",
    "            for solver_result in node.solver_results:\n",
    "                combination = {\n",
    "                    \"node\": node,\n",
    "                    \"solver_result\": solver_result,\n",
    "                    \"children\": child_combination,\n",
    "                }\n",
    "                combinations.append(combination)\n",
    "\n",
    "        return combinations\n",
    "    \n",
    "\n",
    "def evaluate_combinations(root_node: Node, combinations, correct_answer: str):\n",
    "    \"\"\"Evaluate all combinations and return the best one.\"\"\"\n",
    "    best_combination = None\n",
    "    best_score = -float('inf')\n",
    "\n",
    "    for combination in combinations:\n",
    "        # Check if the root node's answer is correct\n",
    "        root_answer = combination[\"solver_result\"][\"answer\"]\n",
    "        if root_answer == correct_answer:\n",
    "            score = combination[\"solver_result\"][\"log_probs\"] or 0.0\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_combination = combination\n",
    "\n",
    "    return best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import math\n",
    "# from collections import defaultdict\n",
    "\n",
    "# class MABSolvingStrategy(Action):\n",
    "#     def __init__(self, solvers: list):\n",
    "#         self.solvers = solvers\n",
    "#         self.node_attempts = defaultdict(int)  # Tracks how often each node is solved\n",
    "#         self.total_attempts = 0  # Global counter for total solving attempts\n",
    "#         self.exploration_coefficient = 1.5  # Tune this for more/less exploration\n",
    "\n",
    "#     def execute(self, node: Node):\n",
    "#         \"\"\"\n",
    "#         Solve a node using Multi-Armed Bandit (UCB-based) exploration vs. exploitation.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Get children sorted by confidence\n",
    "#         confident_children_sorted = node.get_confident_children_sorted()\n",
    "        \n",
    "#         if not confident_children_sorted:\n",
    "#             print(f\"No children found for node {node.question}, solving it directly.\")\n",
    "#             self.choose_solver_and_execute(node)\n",
    "#             return\n",
    "\n",
    "#         # Compute UCB scores for unsolved children\n",
    "#         best_child = None\n",
    "#         best_ucb_score = float('-inf')\n",
    "\n",
    "#         for child in confident_children_sorted:\n",
    "#             if child.solved:\n",
    "#                 continue\n",
    "            \n",
    "#             visits = self.node_attempts[child]\n",
    "#             ucb_score = child.calculate_avg_log_probs(child.decomposition_log_probs) + self.exploration_coefficient * math.sqrt(math.log(self.total_attempts + 1) / (visits + 1))\n",
    "            \n",
    "#             if ucb_score > best_ucb_score:\n",
    "#                 best_ucb_score = ucb_score\n",
    "#                 best_child = child\n",
    "\n",
    "#         if best_child:\n",
    "#             print(f\"Solving child: {best_child.question} with UCB score {best_ucb_score:.3f}\")\n",
    "#             self.node_attempts[best_child] += 1\n",
    "#             self.total_attempts += 1\n",
    "#             self.choose_solver_and_execute(best_child)\n",
    "#         else:\n",
    "#             print(f\"All children solved, solving parent: {node.question}\")\n",
    "#             self.choose_solver_and_execute(node)\n",
    "\n",
    "#     def choose_solver_and_execute(self, node: Node):\n",
    "#         # Randomly select a solving strategy (Closed-Book, Open-Book, Child Aggregation)\n",
    "#         solver = random.choice(self.solvers)\n",
    "#         print(f\"Using solver: {solver.__class__.__name__} for node: {node.question}\")\n",
    "#         solver.execute(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeTreeOfThought:\n",
    "    def __init__(self, decompose_action, prune_action, simulate_action, solving_strategy, max_depth=5, max_iterations=1):\n",
    "        self.decompose_action = decompose_action\n",
    "        self.prune_action = prune_action\n",
    "        self.simulate_action = simulate_action\n",
    "        self.solving_strategy = solving_strategy\n",
    "        self.max_depth = max_depth  # Maximum depth of the tree\n",
    "        self.max_iterations = max_iterations  # Maximum number of iterations\n",
    "\n",
    "    def execute(self, root_node):\n",
    "        \"\"\"\n",
    "        Execute the iterative tree-of-thought reasoning algorithm.\n",
    "        \"\"\"\n",
    "        iteration = 0\n",
    "        while iteration < self.max_iterations:\n",
    "            print(f\"Iteration {iteration + 1}:\")\n",
    "\n",
    "            # TODO:: maybe remove it from here, and put it in the solving strategy.\n",
    "            # Step 1: Decompose the root node\n",
    "            print(\"Decomposing the tree...\")\n",
    "            self.decompose_action.execute_all(root_node, max_children=2)\n",
    "            root_node.print_tree()\n",
    "\n",
    "            # Step 2: Prune irrelevant or redundant nodes\n",
    "            # print(\"Pruning the tree...\")\n",
    "            # self.prune_action.execute(root_node)\n",
    "            # root_node.print_tree()\n",
    "\n",
    "            # Step 3: Solve the most confident child nodes\n",
    "            print(\"Solving the tree...\")\n",
    "            self.solving_strategy.execute(root_node)\n",
    "            root_node.print_tree()\n",
    "\n",
    "            # Step 4: Check if the root node is resolved\n",
    "            if root_node.solved:\n",
    "                print(\"Root node resolved!\")\n",
    "                return root_node.return_best_answer()\n",
    "\n",
    "            # Step 5: Increment iteration counter\n",
    "            iteration += 1\n",
    "\n",
    "        print(\"Stopping: Maximum iterations reached.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Decomposing the tree...\n",
      "Prompt for expansion: \n",
      "        You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "        - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "        - Existing Children: A list of atomic subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "        ### Task:\n",
      "\n",
      "        1. **Carefully analyze the reasoning tree**:\n",
      "            - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "            - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "        2. **Follow these rules for decomposition**:\n",
      "            - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "            - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "            - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "            - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "                - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "                - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "            - **Atomic questions**: Each new child node must ask **one and only one question**. Do not combine multiple questions into a single node.\n",
      "\n",
      "        3. **Define stopping criteria**:\n",
      "            - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "            - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "            - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "        4. **Output Format**:\n",
      "            - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "        ---\n",
      "\n",
      "        ### Examples for Guidance\n",
      "\n",
      "        #### Example 1:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "        #### Example 2:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "        - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "        #### Example 3:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "        - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "        #### Example 4:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        #### Example 5:\n",
      "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"Which city was Lake Wales Medical Center located in?\"\n",
      "\n",
      "        #### Example 6:\n",
      "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
      "        - Existing Children: [\"Which city was Lake Wales Medical Center located in?\"]\n",
      "        - Response: \"What was the 2014 population of <1>?\"\n",
      "\n",
      "        #### Example 7:\n",
      "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
      "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \"Power\"?\"]\n",
      "        - Response: \"<1> played a character on \"Entourage\" that has what last name?\"\n",
      "        \n",
      "        #### Example 8:\n",
      "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
      "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \"Power\"?\", \"<1> played a character on \"Entourage\" that has what last name?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        #### Example 9:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"Who is Edburga of Minster-in-Thanet's father?\"\n",
      "\n",
      "        #### Example 10:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\"]\n",
      "        - Response: \"What year did <1> die?\"\n",
      "\n",
      "        #### Example 11:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\", \"What year did <1> die?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        ---\n",
      "\n",
      "        - Current Node: Which star in the Maltese Bippy died in 1987?\n",
      "        - Existing Children: []\n",
      "        - Response:\n",
      "        \n",
      "LLM Response: What is the name of the star in the Maltese Bippy?\n",
      "Prompt for expansion: \n",
      "        You are helping to decompose a complex question into smaller reasoning steps. Here is the current state of the tree:\n",
      "        - Current Node: The main question that needs to be broken down into smaller steps.\n",
      "        - Existing Children: A list of atomic subquestions (thoughts) already generated to help answer the main question.\n",
      "\n",
      "        ### Task:\n",
      "\n",
      "        1. **Carefully analyze the reasoning tree**:\n",
      "            - If the existing children fully address the current node and no further meaningful steps are needed, respond only with \"Done\"\n",
      "            - If the current node needs further decomposition, suggest a single new child node that directly contributes to solving the main question.\n",
      "\n",
      "        2. **Follow these rules for decomposition**:\n",
      "            - **Focus on essential steps**: Suggest only subquestions that directly contribute to resolving the current node. Avoid peripheral details unless they are crucial.\n",
      "            - **Avoid redundancy**: Do not repeat or rephrase existing children. Each new child node must add unique and meaningful information.\n",
      "            - **Simplify complexity**: Keep subquestions clear and actionable. Avoid unnecessary depth unless it is required to make progress.\n",
      "            - **Reference previous answers**: If a new child node depends on answers from previous children, use placeholders like `<1>`, `<2>`, etc., to reference them. For example:\n",
      "                - If the first child is \"How many members does The Border Surrender have?\", you can reference its answer as `<1>`.\n",
      "                - If the second child is \"How many members does Unsane have?\", you can reference its answer as `<2>`.\n",
      "            - **Atomic questions**: Each new child node must ask **one and only one question**. Do not combine multiple questions into a single node.\n",
      "\n",
      "        3. **Define stopping criteria**:\n",
      "            - Consider the decomposition complete if the existing children comprehensively address all aspects of the current node.\n",
      "            - Do not over-decompose or create unnecessary subquestions by adding minor variations or excessive detail.\n",
      "            - Respond with \"Done\" in that case when no further decomposition is needed.\n",
      "\n",
      "        4. **Output Format**:\n",
      "            - Return either the new child node or \"Done\" without any additional context.\n",
      "\n",
      "        ---\n",
      "\n",
      "        ### Examples for Guidance\n",
      "\n",
      "        #### Example 1:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"How many members does The Border Surrender have?\"\n",
      "\n",
      "        #### Example 2:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\"]\n",
      "        - Response: \"How many members does Unsane have?\"\n",
      "\n",
      "        #### Example 3:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\"]\n",
      "        - Response: \"Which is larger, <1> or <2>?\"\n",
      "\n",
      "        #### Example 4:\n",
      "        - Current Node: \"Does The Border Surrender or Unsane have more members?\"\n",
      "        - Existing Children: [\"How many members does The Border Surrender have?\", \"How many members does Unsane have?\", \"Which is larger, <1> or <2>?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        #### Example 5:\n",
      "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"Which city was Lake Wales Medical Center located in?\"\n",
      "\n",
      "        #### Example 6:\n",
      "        - Current Node: \"What was the 2014 population of the city where Lake Wales Medical Center is located?\"\n",
      "        - Existing Children: [\"Which city was Lake Wales Medical Center located in?\"]\n",
      "        - Response: \"What was the 2014 population of <1>?\"\n",
      "\n",
      "        #### Example 7:\n",
      "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
      "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \"Power\"?\"]\n",
      "        - Response: \"<1> played a character on \"Entourage\" that has what last name?\"\n",
      "        \n",
      "        #### Example 8:\n",
      "        - Current Node: \"The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\"\n",
      "        - Existing Children: [\"Which actor stars as Joe Proctor on the series \"Power\"?\", \"<1> played a character on \"Entourage\" that has what last name?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        #### Example 9:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: []\n",
      "        - Response: \"Who is Edburga of Minster-in-Thanet's father?\"\n",
      "\n",
      "        #### Example 10:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\"]\n",
      "        - Response: \"What year did <1> die?\"\n",
      "\n",
      "        #### Example 11:\n",
      "        - Current Node: \"What year did Edburga of Minster-in-Thanet's father die?\"\n",
      "        - Existing Children: [\"Who is Edburga of Minster-in-Thanet's father?\", \"What year did <1> die?\"]\n",
      "        - Response: \"Done\"\n",
      "\n",
      "        ---\n",
      "\n",
      "        - Current Node: Which star in the Maltese Bippy died in 1987?\n",
      "        - Existing Children: ['What is the name of the star in the Maltese Bippy?']\n",
      "        - Response:\n",
      "        \n",
      "LLM Response: Did <1> die in 1987?\n",
      "Node(question=Which star in the Maltese Bippy died in 1987?, children=['What is the name of the star in the Maltese Bippy?', 'Did <1> die in 1987?'], decomposition_log_probs=None)\n",
      "  Node(question=What is the name of the star in the Maltese Bippy?, children=[], decomposition_log_probs=[-0.0625, -1.328125, -6.4373016e-05, -0.071777344, -6.7949295e-06, -0.0013809204, -0.25585938, -0.18359375, -8.916855e-05, -0.017089844, -0.00015163422, -1.1920929e-07, -0.0026855469, -8.583069e-06, -0.28125, -5.841255e-06])\n",
      "  Node(question=Did <1> die in 1987?, children=[], decomposition_log_probs=[-0.48242188, -0.11328125, 0, -2.2888184e-05, -3.6001205e-05, 0, 0, 0, 0, -2.7418137e-06, -6.4373016e-06])\n",
      "Solving the tree...\n",
      "Solving node 'What is the name of the star in the Maltese Bippy?' using the Closed-Book model.\n",
      "Prompt for solving: \n",
      "        Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "        The exact format should be:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        Example Format:\n",
      "\n",
      "        Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "        A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "        Q: How many episodes were in the South Korean television series in which Ryu Hye-young played Bo-ra?\n",
      "        A: The South Korean television series in which Ryu Hye-young played Bo-ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "        Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "        A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "        Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "        Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "        A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "        Q: In what country was Lost Gravity manufactured?\n",
      "        A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "        Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "        A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2009?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "        Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para-military training?\n",
      "        A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para-military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "        Q: Does The Border Surrender or Unsane have more members?\n",
      "        A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "        Q: James Paris Lee is best known for investing the Lee-Metford rifle and another rifle often referred to by what acronymn?\n",
      "        A: James Paris Lee is best known for investing the Lee-Metford rifle and Lee-Enfield series of rifles. Lee-Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2008?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "        Q: What year did Edburga of Minster-in-Thanet's father die?\n",
      "        A: The father of Edburga of Minster-in-Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "        Q: Were Lonny and Allure both founded in the 1990s?\n",
      "        A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "        Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "        A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "        Q: When was Jan de Bont born?\n",
      "        A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "        Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "        A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "        Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "        A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "        Q: Are both Bruce Chatwin and O. Henry writers?\n",
      "        A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "        Q: Which city is Lake Wales Medical Center located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "        Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "        A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "        Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "        A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "        Now, please answer the following question in the same format:\n",
      "        Q: What is the name of the star in the Maltese Bippy?\n",
      "        A: \n",
      "        \n",
      "LLM Response for 'What is the name of the star in the Maltese Bippy?': Q: What is the name of the star in the Maltese Bippy?\n",
      "A: The Maltese Bippy is a 1969 film starring Terence Stamp and Ingrid Thulin. The star in the Maltese Bippy is Mira. So the answer is: Mira.\n",
      "Extracted answer: Mira\n",
      "Solving node 'What is the name of the star in the Maltese Bippy?' using the Open-Book model.\n",
      "node question after replacing dependencies: What is the name of the star in the Maltese Bippy?\n",
      "Prompt for solving: \n",
      "        Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "        Answer in the following format:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        #1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "        #2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "        #3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "        Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour staged?\n",
      "        A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "        #1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "        Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "        #2 Wikipedia Title: Hallelujah I Love Her So\n",
      "        Text: \"Hallelujah I Love Her So\" Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B-side \"What Would I Do Without You\" Released 1956 Format 7\" 45rpm Recorded 1956 Genre Soul, rhythm and blues Length 2:35 Label Atlantic Songwriter(s) Ray Charles Producer(s) Jerry Wexler.\n",
      "        #3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "        Text: \"The First Time Ever I Saw Your Face\" Single by Roberta Flack from the album First Take Released March 7, 1972 Recorded 1969 Genre Soul, vocal jazz Length 5:22 Label Atlantic Songwriter(s) Ewan MacColl Producer(s) Joel Dorn.\n",
      "        Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "        A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "        #1 Wikipedia Title: The Maltese Bippy\n",
      "        Text: The Maltese Bippy is a 1969 film directed by Norman Panama and released by Metro-Goldwyn-Mayer. It stars Dan Rowan and Dick Martin.\n",
      "        Q: What is the name of the star in the Maltese Bippy?\n",
      "        A:\n",
      "        \n",
      "LLM Response for 'What is the name of the star in the Maltese Bippy?': The stars of The Maltese Bippy are Dan Rowan and Dick Martin. So the answer is: Dan Rowan and Dick Martin.\n",
      "Extracted answer: Dan Rowan and Dick Martin\n",
      "Solving node 'What is the name of the star in the Maltese Bippy?' using the Children Aggregation model.\n",
      "Node 'What is the name of the star in the Maltese Bippy?' has no children to aggregate.\n",
      "Solving node 'Did <1> die in 1987?' using the Closed-Book model.\n",
      "Node 'Did <1> die in 1987?' has dependencies on children: [1]. Solving them first.\n",
      "Solving child of <1> of node 'Did <1> die in 1987?'\n",
      "Prompt for solving: \n",
      "        Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "        The exact format should be:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        Example Format:\n",
      "\n",
      "        Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "        A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "        Q: How many episodes were in the South Korean television series in which Ryu Hye-young played Bo-ra?\n",
      "        A: The South Korean television series in which Ryu Hye-young played Bo-ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "        Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "        A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "        Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "        Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "        A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "        Q: In what country was Lost Gravity manufactured?\n",
      "        A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "        Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "        A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2009?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "        Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para-military training?\n",
      "        A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para-military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "        Q: Does The Border Surrender or Unsane have more members?\n",
      "        A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "        Q: James Paris Lee is best known for investing the Lee-Metford rifle and another rifle often referred to by what acronymn?\n",
      "        A: James Paris Lee is best known for investing the Lee-Metford rifle and Lee-Enfield series of rifles. Lee-Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2008?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "        Q: What year did Edburga of Minster-in-Thanet's father die?\n",
      "        A: The father of Edburga of Minster-in-Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "        Q: Were Lonny and Allure both founded in the 1990s?\n",
      "        A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "        Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "        A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "        Q: When was Jan de Bont born?\n",
      "        A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "        Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "        A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "        Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "        A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "        Q: Are both Bruce Chatwin and O. Henry writers?\n",
      "        A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "        Q: Which city is Lake Wales Medical Center located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "        Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "        A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "        Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "        A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "        Now, please answer the following question in the same format:\n",
      "        Q: Did Dan Rowan and Dick Martin die in 1987?\n",
      "        A: \n",
      "        \n",
      "LLM Response for 'Did Dan Rowan and Dick Martin die in 1987?': Q: Did Dan Rowan and Dick Martin die in 1987?\n",
      "A: Dan Rowan died on September 22, 1987. Dick Martin died on May 24, 2008. Therefore, only Dan Rowan died in 1987. So the answer is: no.\n",
      "Extracted answer: no\n",
      "Solving node 'Did <1> die in 1987?' using the Open-Book model.\n",
      "Node 'Did <1> die in 1987?' has dependencies on children: [1]. Solving them first.\n",
      "Solving child of <1> of node 'Did <1> die in 1987?'\n",
      "node question after replacing dependencies: Did Dan Rowan and Dick Martin die in 1987?\n",
      "Prompt for solving: \n",
      "        Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "        Answer in the following format:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        #1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "        #2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "        #3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "        Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour staged?\n",
      "        A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "        #1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "        Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "        #2 Wikipedia Title: Hallelujah I Love Her So\n",
      "        Text: \"Hallelujah I Love Her So\" Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B-side \"What Would I Do Without You\" Released 1956 Format 7\" 45rpm Recorded 1956 Genre Soul, rhythm and blues Length 2:35 Label Atlantic Songwriter(s) Ray Charles Producer(s) Jerry Wexler.\n",
      "        #3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "        Text: \"The First Time Ever I Saw Your Face\" Single by Roberta Flack from the album First Take Released March 7, 1972 Recorded 1969 Genre Soul, vocal jazz Length 5:22 Label Atlantic Songwriter(s) Ewan MacColl Producer(s) Joel Dorn.\n",
      "        Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "        A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "        #1 Wikipedia Title: Dan Rowan\n",
      "        Text: Daniel Hale \"Dan\" Rowan (July 22, 1922 – September 22, 1987) was an American comedian. He was featured in the television show \"Rowan & Martin's Laugh-In\", where he played straight man to Dick Martin, and won the 1969 Emmy for Outstanding Variety or Musical Series.\n",
      "        #2 Wikipedia Title: The Maltese Bippy\n",
      "        Text: The Maltese Bippy is a 1969 film directed by Norman Panama and released by Metro-Goldwyn-Mayer. It stars Dan Rowan and Dick Martin.\n",
      "        Q: Did Dan Rowan and Dick Martin die in 1987?\n",
      "        A:\n",
      "        \n",
      "LLM Response for 'Did <1> die in 1987?': The information about Dan Rowan's death is found in the text about Dan Rowan, but there is no information about Dick Martin's death. So the answer is: Unknown.\n",
      "Extracted answer: Unknown\n",
      "Solving node 'Did <1> die in 1987?' using the Children Aggregation model.\n",
      "Node 'Did <1> die in 1987?' has no children to aggregate.\n",
      "Solving node 'Which star in the Maltese Bippy died in 1987?' using the Closed-Book model.\n",
      "Prompt for solving: \n",
      "        Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "        The exact format should be:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        Example Format:\n",
      "\n",
      "        Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "        A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "        Q: How many episodes were in the South Korean television series in which Ryu Hye-young played Bo-ra?\n",
      "        A: The South Korean television series in which Ryu Hye-young played Bo-ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "        Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "        A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "        Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "        Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "        A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "        Q: In what country was Lost Gravity manufactured?\n",
      "        A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "        Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "        A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2009?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "        Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para-military training?\n",
      "        A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para-military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "        Q: Does The Border Surrender or Unsane have more members?\n",
      "        A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "        Q: James Paris Lee is best known for investing the Lee-Metford rifle and another rifle often referred to by what acronymn?\n",
      "        A: James Paris Lee is best known for investing the Lee-Metford rifle and Lee-Enfield series of rifles. Lee-Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "        Q: Was Lonny (magazine) was founded in 2008?\n",
      "        A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "        Q: What year did Edburga of Minster-in-Thanet's father die?\n",
      "        A: The father of Edburga of Minster-in-Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "        Q: Were Lonny and Allure both founded in the 1990s?\n",
      "        A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "        Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "        A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "        Q: When was Jan de Bont born?\n",
      "        A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "        Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "        A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "        Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "        A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "        Q: Are both Bruce Chatwin and O. Henry writers?\n",
      "        A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "        Q: Which city is Lake Wales Medical Center located?\n",
      "        A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "        Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "        A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "        Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "        A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "        Now, please answer the following question in the same format:\n",
      "        Q: Which star in the Maltese Bippy died in 1987?\n",
      "        A: \n",
      "        \n",
      "LLM Response for 'Which star in the Maltese Bippy died in 1987?': Q: Which star in the Maltese Bippy died in 1987?\n",
      "A: The movie \"Bippy\" refers to the 1963 film \"The Maltese Bippy\". The star of \"The Maltese Bippy\" who died in 1987 is Sterling Hayden. So the answer is: Sterling Hayden.\n",
      "Extracted answer: Sterling Hayden\n",
      "Solving node 'Which star in the Maltese Bippy died in 1987?' using the Open-Book model.\n",
      "node question after replacing dependencies: Which star in the Maltese Bippy died in 1987?\n",
      "Prompt for solving: \n",
      "        Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "        Answer in the following format:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        #1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "        #2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "        #3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "        Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "        Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour staged?\n",
      "        A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "        #1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "        Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "        #2 Wikipedia Title: Hallelujah I Love Her So\n",
      "        Text: \"Hallelujah I Love Her So\" Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B-side \"What Would I Do Without You\" Released 1956 Format 7\" 45rpm Recorded 1956 Genre Soul, rhythm and blues Length 2:35 Label Atlantic Songwriter(s) Ray Charles Producer(s) Jerry Wexler.\n",
      "        #3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "        Text: \"The First Time Ever I Saw Your Face\" Single by Roberta Flack from the album First Take Released March 7, 1972 Recorded 1969 Genre Soul, vocal jazz Length 5:22 Label Atlantic Songwriter(s) Ewan MacColl Producer(s) Joel Dorn.\n",
      "        Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "        A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "        #1 Wikipedia Title: The Maltese Bippy\n",
      "        Text: The Maltese Bippy is a 1969 film directed by Norman Panama and released by Metro-Goldwyn-Mayer. It stars Dan Rowan and Dick Martin.\n",
      "        Q: Which star in the Maltese Bippy died in 1987?\n",
      "        A:\n",
      "        \n",
      "LLM Response for 'Which star in the Maltese Bippy died in 1987?': Dan Rowan died in 1987. So the answer is: Dan Rowan.\n",
      "Extracted answer: Dan Rowan\n",
      "Solving node 'Which star in the Maltese Bippy died in 1987?' using the Children Aggregation model.\n",
      "Prompt for solving: \n",
      "        Given a question and context, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "        Answer in the following format:\n",
      "        [Explanation]. So the answer is: [Answer]\n",
      "\n",
      "        #\n",
      "        Context:\n",
      "        Which famous fashion show Stella Maxwell has been a model for? Victoria's Secret.\n",
      "        Since when Victoria's Secret? 1977.\n",
      "\n",
      "        Question:\n",
      "        Stella Maxwell has been a model for a famous fashion shown since when?\n",
      "\n",
      "        Answer:\n",
      "        Stella Maxwell has been a model for a famous fashion shown, Victoria's Secret since 2015. So the answer is: since 2015.\n",
      "        #\n",
      "        Context:\n",
      "        Who is the American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers? Devean George.\n",
      "        William Novac co-wrote the memoir of Devean George? no.\n",
      "\n",
      "        Question:\n",
      "        William Novac co-wrote the memoir of what American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers?\n",
      "\n",
      "        Answer:\n",
      "        William Novac co-wrote the memoir of Magic Johnson, an American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers. So the answer is: Magic Johnson.\n",
      "        #\n",
      "        Context:\n",
      "        Which athlete rode 400 miles across his country to bring attention to the plight of the disabled in the country? Emmanuel Ofosu Yeboah.\n",
      "        What is the title of the documentary narrated by Oprah Winfrey about Emmanuel Ofosu Yeboah? Emmanuel's Gift.\n",
      "\n",
      "        Question:\n",
      "        Oprah Winfrey narrated a documentary about this athlete who rode 400 miles across his country to bring attention to the plight of the disabled in the country?\n",
      "\n",
      "        Answer:\n",
      "        Oprah Winfrey narrated a documentary about the athelete Emmanuel Ofosu Yeboah, who rode 400 miles across his country to bring attention to the plight of the disabled in the country. So the answer is: Emmanuel Ofosu Yeboah.\n",
      "        #\n",
      "        Context:\n",
      "        What is the name of the star in the Maltese Bippy? Dan Rowan and Dick Martin\n",
      "        Did Dan Rowan and Dick Martin die in 1987? no\n",
      "\n",
      "        Question:\n",
      "        Which star in the Maltese Bippy died in 1987?\n",
      "\n",
      "        Answer:\n",
      "        \n",
      "LLM Response for 'Which star in the Maltese Bippy died in 1987?': None of the stars in the Maltese Bippy, Dan Rowan and Dick Martin, died in 1987. So the answer is: Unknown.\n",
      "Extracted answer: Unknown\n",
      "Node(question=Which star in the Maltese Bippy died in 1987?, children=['What is the name of the star in the Maltese Bippy?', 'Did <1> die in 1987?'], decomposition_log_probs=None)\n",
      "  Node(question=What is the name of the star in the Maltese Bippy?, children=[], decomposition_log_probs=[-0.0625, -1.328125, -6.4373016e-05, -0.071777344, -6.7949295e-06, -0.0013809204, -0.25585938, -0.18359375, -8.916855e-05, -0.017089844, -0.00015163422, -1.1920929e-07, -0.0026855469, -8.583069e-06, -0.28125, -5.841255e-06])\n",
      "  Node(question=Did <1> die in 1987?, children=[], decomposition_log_probs=[-0.48242188, -0.11328125, 0, -2.2888184e-05, -3.6001205e-05, 0, 0, 0, 0, -2.7418137e-06, -6.4373016e-06])\n",
      "Root node resolved!\n",
      "Final Answer: Dan Rowan\n"
     ]
    }
   ],
   "source": [
    "# Initialize the root node with the question\n",
    "# question = 'What event in 1920 was established by the director of the play \"The Miracle\"?' -> salzburg festival\n",
    "# question = 'Are Catasetum and Origanum in the same family?' -> no\n",
    "# question = 'The 2015 Austrian thriller film Jack tells the story of a serial killer who died in what year?' # !! Bad decomposition, should be fixed.\n",
    "# question = 'A guitar player called Noodles is a longtime member of which band, The Smashing Pumpkins or The Offspring?' -> The Offspring\n",
    "# question = 'What is the city in which Bauerfield International Ariport is based out of' -> Port Vila\n",
    "# question = 'What is the name of the movie that stars Katrina Bowden and was directed by Sean Anders?' -> wrong decomposition !!\n",
    "question = \"Which star in the Maltese Bippy died in 1987?\"\n",
    "root_node = Node(question)\n",
    "\n",
    "# Create the actions\n",
    "decompose_action = DecomposeAction()\n",
    "llm_prune_action = LLMBasedPruneAction()\n",
    "confidence_prune_action = ConfidenceBasedPruneAction()\n",
    "simulate_action = SimulateAnswerAction(parser)\n",
    "\n",
    "# Create the iterative tree-of-thought reasoning algorithm\n",
    "tree_of_thought = IterativeTreeOfThought(\n",
    "    decompose_action=decompose_action,\n",
    "    prune_action=confidence_prune_action,\n",
    "    simulate_action=simulate_action,\n",
    "    # solving_strategy=GreedySolvingStrategy([ClosedBookSolving(), OpenBookSolving(), ChildrenAggregationSolving()]),\n",
    "    solving_strategy=BruteForceSolver(ClosedBookSolving(), OpenBookSolving(), ChildrenAggregationSolving()),\n",
    "    max_depth=5,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "# Execute the algorithm\n",
    "answer = tree_of_thought.execute(root_node)\n",
    "print(\"Final Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions by (ob, cb, child aggreg):  True True False\n",
      "Solutions by (ob, cb, child aggreg):  Dan Rowan  -   Sterling Hayden  -   Unknown\n",
      "confidences by (ob, cb, child aggreg): -0.058378024851285786  -   -0.1454313908838827  -   -1000.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/TGe4hAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKp0lEQVR4nO3de3zP9f//8ft7dnDcZhkz5jBkI8RkJpGsNtPBx0p89AmfRfWhE+pDKilF8tFB9fFdKRTJoRRF5JBDa3xETiOnhbGhtZMxY8/fH128f73b9rI3m/fG7Xq5vC+8n6/n8/V6PPfubfde79fr+bYZY4wAAABQJDdXFwAAAFCeEZYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAuMTevXt1xx13yMfHRzabTYsWLdKMGTNks9mUnJx80fGNGjXSwIEDy7xOACAsAdew/fv36+GHH1ZwcLAqV64sb29v3XzzzXrrrbd0+vTpMj32gAEDtH37dr3yyiv6+OOP1b59+zI9Xnl19uxZvfXWW2rbtq28vb3l6+urli1basiQIdq9e7erywMgyd3VBQBwja+//lr33XefvLy89OCDD+qGG27Q2bNntX79ej399NPauXOn4uPjy+TYp0+fVkJCgsaMGaNhw4bZ2//xj3+ob9++8vLyKpPjlkexsbFaunSp+vXrp8GDBys/P1+7d+/WkiVL1KlTJ4WEhLi6ROCaR1gCrkEHDx5U37591bBhQ61atUp169a1bxs6dKj27dunr7/+usyOf+LECUmSr6+vQ3ulSpVUqVKlMjtuebNp0yYtWbJEr7zyip599lmHbe+8844yMjKuWC1nzpyRp6en3Nz4wAH4K94VwDVo0qRJysnJ0fTp0x2C0gVNmzbVE088YX9+7tw5vfzyy2rSpIm8vLzUqFEjPfvss8rLy3MY16hRI915551av369OnTooMqVKys4OFizZs2y93nxxRfVsGFDSdLTTz8tm82mRo0aSVKR1ywZYzR+/HjVr19fVatWVbdu3bRz584i55WRkaEnn3xSQUFB8vLyUtOmTfXaa6+poKDA3ic5OVk2m02TJ09WfHy8fU433XSTNm3aVGifu3fvVp8+feTv768qVaqoefPmGjNmjEOflJQU/fOf/1SdOnXk5eWlli1b6sMPPyzmp///7d+/X5J08803F9pWqVIlXXfddYWOExcXp8DAQHl5ealx48Z69NFHdfbsWXufAwcO6L777pOfn5+qVq2qjh07Fgq+a9askc1m09y5c/Xcc8+pXr16qlq1qrKysiRJiYmJio6Olo+Pj6pWraquXbtqw4YNDvvIzs7Wk08+qUaNGsnLy0u1a9fW7bffrp9++umi8wYqGs4sAdegxYsXKzg4WJ06dSpR/4ceekgzZ87UvffeqxEjRigxMVETJkxQUlKSvvjiC4e++/bt07333qu4uDgNGDBAH374oQYOHKiwsDC1bNlSvXv3lq+vr5566in169dPMTExql69erHHfuGFFzR+/HjFxMQoJiZGP/30k+644w6HgCBJubm56tq1q1JSUvTwww+rQYMG+uGHHzR69GgdO3ZMb775pkP/OXPmKDs7Ww8//LBsNpsmTZqk3r1768CBA/Lw8JAkbdu2Tbfccos8PDw0ZMgQNWrUSPv379fixYv1yiuvSJLS0tLUsWNH2Ww2DRs2TP7+/lq6dKni4uKUlZWlJ598sti5XQiNs2fP1s033yx39+L/ST569Kg6dOigjIwMDRkyRCEhIUpJSdGCBQuUm5srT09PpaWlqVOnTsrNzdXjjz+u6667TjNnztTdd9+tBQsW6G9/+5vDPl9++WV5enpq5MiRysvLk6enp1atWqUePXooLCxMY8eOlZubmz766CPddtttWrdunTp06CBJeuSRR7RgwQINGzZMLVq00G+//ab169crKSlJ7dq1K3YeQIVkAFxTMjMzjSRzzz33lKj/1q1bjSTz0EMPObSPHDnSSDKrVq2ytzVs2NBIMmvXrrW3HT9+3Hh5eZkRI0bY2w4ePGgkmddff91hnx999JGRZA4ePGgf6+npaXr27GkKCgrs/Z599lkjyQwYMMDe9vLLL5tq1aqZX375xWGfo0aNMpUqVTKHDh1yOPZ1111n0tPT7f2+/PJLI8ksXrzY3talSxdTo0YN8+uvvzrs88+1xMXFmbp165qTJ0869Onbt6/x8fExubm5pjgFBQWma9euRpKpU6eO6devn3n33XcLHc8YYx588EHj5uZmNm3aVOR+jDHmySefNJLMunXr7Nuys7NN48aNTaNGjcz58+eNMcasXr3aSDLBwcEO9RUUFJhmzZqZqKgohznm5uaaxo0bm9tvv93e5uPjY4YOHVrs3ICrCR/DAdeYCx+11KhRo0T9v/nmG0nS8OHDHdpHjBghSYU+4mnRooVuueUW+3N/f381b95cBw4ccLrW7777TmfPntVjjz0mm81mby/qbM38+fN1yy23qGbNmjp58qT9ERkZqfPnz2vt2rUO/e+//37VrFnT/vxCzRfqPHHihNauXat//vOfatCggcPYC7UYY7Rw4ULdddddMsY4HDcqKkqZmZmWH0vZbDZ9++23Gj9+vGrWrKlPP/1UQ4cOVcOGDXX//ffbr1kqKCjQokWLdNdddxV51+CFer755ht16NBBnTt3tm+rXr26hgwZouTkZO3atcth3IABA1SlShX7861bt2rv3r36+9//rt9++80+l1OnTql79+5au3at/SNNX19fJSYm6ujRo8XOD7ha8DEccI3x9vaW9Mc1JyXx66+/ys3NTU2bNnVoDwgIkK+vr3799VeH9r8GC0mqWbOmfv/9d6drvbDvZs2aObT7+/s7BB3pj3Wbtm3bJn9//yL3dfz4ccs6L+zvQp0XQtMNN9xQbH0nTpxQRkaG4uPji71z8K/H/SsvLy+NGTNGY8aM0bFjx/T999/rrbfe0rx58+Th4aFPPvlEJ06cUFZWlmUt0h8/r/Dw8ELtoaGh9u1/3kfjxo0d+u3du1fSHyGqOJmZmapZs6YmTZqkAQMGKCgoSGFhYYqJidGDDz6o4OBgyxqBioiwBFxjvL29FRgYqB07djg17s9ndqwUdzebMcap4zmroKBAt99+u5555pkit19//fUOz0ujzgtnWR544IFiA0br1q1LvL+6deuqb9++io2NVcuWLTVv3jzNmDGjxOOd9eezStL/n8/rr7+uG2+8scgxF64v69Onj2655RZ98cUXWr58uV5//XW99tpr+vzzz9WjR48yqxlwBcIScA268847FR8fr4SEBEVERFj2bdiwoQoKCrR37177GQrpjwubMzIy7Bcpl4UL+967d6/DGYsTJ04UOlPVpEkT5eTkKDIyslSOfeF4VqHS399fNWrU0Pnz50vtuJLk4eGh1q1ba+/evTp58qRq164tb2/viwbchg0bas+ePYXaLyxuebHXqkmTJpL+CNQlmU/dunX1r3/9S//61790/PhxtWvXTq+88gphCVcdrlkCrkHPPPOMqlWrpoceekhpaWmFtu/fv19vvfWWJCkmJkaSCt1NNmXKFElSz549y6zOyMhIeXh4aOrUqQ5nfP5ai/THmY6EhAR9++23hbZlZGTo3LlzTh3b399fXbp00YcffqhDhw45bLtQS6VKlRQbG6uFCxcWGWQurCdVnL179xba94V6ExISVLNmTfn7+8vNzU29evXS4sWL9b///a9Q/wv1xMTEaOPGjUpISLBvO3XqlOLj49WoUSO1aNHCsp6wsDA1adJEkydPVk5OTrHzOX/+vDIzMx221a5dW4GBgYWWkwCuBpxZAq5BTZo00Zw5c3T//fcrNDTUYQXvH374QfPnz7d/71qbNm00YMAAxcfHKyMjQ127dtXGjRs1c+ZM9erVS926dSuzOv39/TVy5EhNmDBBd955p2JiYrRlyxYtXbpUtWrVcuj79NNP66uvvtKdd95pX6rg1KlT2r59uxYsWKDk5ORCYy7m7bffVufOndWuXTsNGTJEjRs3VnJysr7++mtt3bpVkjRx4kStXr1a4eHhGjx4sFq0aKH09HT99NNP+u6775Senl7s/n/++Wf9/e9/V48ePXTLLbfIz89PKSkpmjlzpo4ePao333zT/nHhq6++quXLl6tr164aMmSIQkNDdezYMc2fP1/r16+Xr6+vRo0apU8//VQ9evTQ448/Lj8/P82cOVMHDx7UwoULL7rgpJubmz744AP16NFDLVu21KBBg1SvXj2lpKRo9erV8vb21uLFi5Wdna369evr3nvvVZs2bVS9enV999132rRpk/7zn/849TMGKgQX3okHwMV++eUXM3jwYNOoUSPj6elpatSoYW6++WYzdepUc+bMGXu//Px8M27cONO4cWPj4eFhgoKCzOjRox36GPPH0gE9e/YsdJyuXbuarl272p+XdOkAY4w5f/68GTdunKlbt66pUqWKufXWW82OHTtMw4YNHZYOMOaP2+RHjx5tmjZtajw9PU2tWrVMp06dzOTJk83Zs2ctj22MMZLM2LFjHdp27Nhh/va3vxlfX19TuXJl07x5c/P888879ElLSzNDhw41QUFBxsPDwwQEBJju3bub+Pj4Qsf467iJEyearl27mrp16xp3d3dTs2ZNc9ttt5kFCxYU6v/rr7+aBx980Pj7+xsvLy8THBxshg4davLy8ux99u/fb+699157vR06dDBLlixx2M+FpQPmz59fZF1btmwxvXv3Ntddd53x8vIyDRs2NH369DErV640xhiTl5dnnn76adOmTRtTo0YNU61aNdOmTRvz3nvvWc4XqKhsxpTxVZcAAAAVGNcsAQAAWCAsAQAAWCAsAQAAWKhwYendd99Vo0aNVLlyZYWHh2vjxo2W/efPn6+QkBBVrlxZrVq1sn91wwXGGL3wwguqW7euqlSposjISPsqtgAAABUqLH322WcaPny4xo4dq59++klt2rRRVFRUsV8n8MMPP6hfv36Ki4vTli1b1KtXL/Xq1cthPZRJkybp7bff1rRp05SYmKhq1aopKipKZ86cuVLTAgAA5ViFuhsuPDxcN910k9555x1JfyzNHxQUpMcee0yjRo0q1P/+++/XqVOntGTJEntbx44ddeONN2ratGkyxigwMFAjRozQyJEjJf3xvUd16tTRjBkz1Ldv3yszMQAAUG5VmEUpz549q82bN2v06NH2Njc3N0VGRjqsVvtnCQkJhb4pPSoqSosWLZIkHTx4UKmpqQ7L+vv4+Cg8PFwJCQnFhqW8vDyHVWoLCgqUnp6u6667rsTfnwUAAFzLGKPs7GwFBgZaLtpaYcLSyZMndf78edWpU8ehvU6dOvbvPfqr1NTUIvunpqbat19oK65PUSZMmKBx48Y5PQcAAFD+HD58WPXr1y92e4UJS+XJ6NGjHc5YZWZmqkGDBjp8+LC8vb1L9Vg3jC38PVcA/r8d46JcXUKp4L0OFK+s3udZWVkKCgpSjRo1LPtVmLBUq1YtVapUqdCXfqalpSkgIKDIMQEBAZb9L/yZlpamunXrOvS58cYbi63Fy8tLXl5ehdq9vb1LPSy5eVUt1f0BV5vSfs+5Cu91oHhl/T6/2CU0FeZuOE9PT4WFhWnlypX2toKCAq1cuVIRERFFjomIiHDoL0krVqyw92/cuLECAgIc+mRlZSkxMbHYfQIAgGtLhTmzJEnDhw/XgAED1L59e3Xo0EFvvvmmTp06pUGDBkmSHnzwQdWrV08TJkyQJD3xxBPq2rWr/vOf/6hnz56aO3eu/ve//yk+Pl7SH0nyySef1Pjx49WsWTM1btxYzz//vAIDA9WrVy9XTRMAAJQjFSos3X///Tpx4oReeOEFpaam6sYbb9SyZcvsF2gfOnTI4Wr2Tp06ac6cOXruuef07LPPqlmzZlq0aJFuuOEGe59nnnlGp06d0pAhQ5SRkaHOnTtr2bJlqly58hWfHwAAKH8q1DpL5VVWVpZ8fHyUmZlZ6p+rNhr1danuD7jaJE/s6eoSSgXvdaB4ZfU+L+nv7wpzzRIAAIArEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsVJiwlJ6erv79+8vb21u+vr6Ki4tTTk6O5ZgzZ85o6NChuu6661S9enXFxsYqLS3Nvv3nn39Wv379FBQUpCpVqig0NFRvvfVWWU8FAABUIBUmLPXv3187d+7UihUrtGTJEq1du1ZDhgyxHPPUU09p8eLFmj9/vr7//nsdPXpUvXv3tm/fvHmzateurU8++UQ7d+7UmDFjNHr0aL3zzjtlPR0AAFBB2IwxxtVFXExSUpJatGihTZs2qX379pKkZcuWKSYmRkeOHFFgYGChMZmZmfL399ecOXN07733SpJ2796t0NBQJSQkqGPHjkUea+jQoUpKStKqVatKXF9WVpZ8fHyUmZkpb2/vS5hh8RqN+rpU9wdcbZIn9nR1CaWC9zpQvLJ6n5f093eFOLOUkJAgX19fe1CSpMjISLm5uSkxMbHIMZs3b1Z+fr4iIyPtbSEhIWrQoIESEhKKPVZmZqb8/PxKr3gAAFChubu6gJJITU1V7dq1Hdrc3d3l5+en1NTUYsd4enrK19fXob1OnTrFjvnhhx/02Wef6euvrf8PLy8vT3l5efbnWVlZJZgFAACoiFx6ZmnUqFGy2WyWj927d1+RWnbs2KF77rlHY8eO1R133GHZd8KECfLx8bE/goKCrkiNAADgynPpmaURI0Zo4MCBln2Cg4MVEBCg48ePO7SfO3dO6enpCggIKHJcQECAzp49q4yMDIezS2lpaYXG7Nq1S927d9eQIUP03HPPXbTu0aNHa/jw4fbnWVlZBCYAAK5SLg1L/v7+8vf3v2i/iIgIZWRkaPPmzQoLC5MkrVq1SgUFBQoPDy9yTFhYmDw8PLRy5UrFxsZKkvbs2aNDhw4pIiLC3m/nzp267bbbNGDAAL3yyislqtvLy0teXl4l6gsAACq2CnGBd2hoqKKjozV48GBt3LhRGzZs0LBhw9S3b1/7nXApKSkKCQnRxo0bJUk+Pj6Ki4vT8OHDtXr1am3evFmDBg1SRESE/U64HTt2qFu3brrjjjs0fPhwpaamKjU1VSdOnHDZXAEAQPlSIS7wlqTZs2dr2LBh6t69u9zc3BQbG6u3337bvj0/P1979uxRbm6uve2NN96w983Ly1NUVJTee+89+/YFCxboxIkT+uSTT/TJJ5/Y2xs2bKjk5OQrMi8AAFC+VYh1lso71lkCXId1loCrH+ssAQAAlGOEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAuEJQAAAAsVJiylp6erf//+8vb2lq+vr+Li4pSTk2M55syZMxo6dKiuu+46Va9eXbGxsUpLSyuy72+//ab69evLZrMpIyOjDGYAAAAqogoTlvr376+dO3dqxYoVWrJkidauXashQ4ZYjnnqqae0ePFizZ8/X99//72OHj2q3r17F9k3Li5OrVu3LovSAQBABVYhwlJSUpKWLVumDz74QOHh4ercubOmTp2quXPn6ujRo0WOyczM1PTp0zVlyhTddtttCgsL00cffaQffvhBP/74o0Pf//73v8rIyNDIkSOvxHQAAEAFUiHCUkJCgnx9fdW+fXt7W2RkpNzc3JSYmFjkmM2bNys/P1+RkZH2tpCQEDVo0EAJCQn2tl27dumll17SrFmz5OZWsh9HXl6esrKyHB4AAODqVCHCUmpqqmrXru3Q5u7uLj8/P6WmphY7xtPTU76+vg7tderUsY/Jy8tTv3799Prrr6tBgwYlrmfChAny8fGxP4KCgpybEAAAqDBcGpZGjRolm81m+di9e3eZHX/06NEKDQ3VAw884PS4zMxM++Pw4cNlVCEAAHA1d1cefMSIERo4cKBln+DgYAUEBOj48eMO7efOnVN6eroCAgKKHBcQEKCzZ88qIyPD4exSWlqafcyqVau0fft2LViwQJJkjJEk1apVS2PGjNG4ceOK3LeXl5e8vLxKMkUAAFDBuTQs+fv7y9/f/6L9IiIilJGRoc2bNyssLEzSH0GnoKBA4eHhRY4JCwuTh4eHVq5cqdjYWEnSnj17dOjQIUVEREiSFi5cqNOnT9vHbNq0Sf/85z+1bt06NWnS5HKnBwAArgIuDUslFRoaqujoaA0ePFjTpk1Tfn6+hg0bpr59+yowMFCSlJKSou7du2vWrFnq0KGDfHx8FBcXp+HDh8vPz0/e3t567LHHFBERoY4dO0pSoUB08uRJ+/H+eq0TAAC4NlWIsCRJs2fP1rBhw9S9e3e5ubkpNjZWb7/9tn17fn6+9uzZo9zcXHvbG2+8Ye+bl5enqKgovffee64oHwAAVFA2c+FCHVyyrKws+fj4KDMzU97e3qW670ajvi7V/QFXm+SJPV1dQqngvQ4Ur6ze5yX9/V0hlg4AAABwFcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACAhcsKS2fOnCmtOgAAAMolp8NSQUGBXn75ZdWrV0/Vq1fXgQMHJEnPP/+8pk+fXuoFAgAAuJLTYWn8+PGaMWOGJk2aJE9PT3v7DTfcoA8++KBUiwMAAHA1p8PSrFmzFB8fr/79+6tSpUr29jZt2mj37t2lWhwAAICrOR2WUlJS1LRp00LtBQUFys/PL5WiAAAAygunw1KLFi20bt26Qu0LFixQ27ZtS6UoAACA8sLd2QEvvPCCBgwYoJSUFBUUFOjzzz/Xnj17NGvWLC1ZsqQsagQAAHAZp88s3XPPPVq8eLG+++47VatWTS+88IKSkpK0ePFi3X777WVRIwAAgMs4fWZJkm655RatWLGitGsBAAAod5w+s7Rp0yYlJiYWak9MTNT//ve/UikKAACgvHA6LA0dOlSHDx8u1J6SkqKhQ4eWSlEAAADlhdNhadeuXWrXrl2h9rZt22rXrl2lUhQAAEB54XRY8vLyUlpaWqH2Y8eOyd39ki6BAgAAKLecDkt33HGHRo8erczMTHtbRkaGnn32We6GAwAAVx2nTwVNnjxZXbp0UcOGDe2LUG7dulV16tTRxx9/XOoFAgAAuJLTYalevXratm2bZs+erZ9//llVqlTRoEGD1K9fP3l4eJRFjQAAAC5zSRcZVatWTUOGDCntWgAAAMqdSwpLe/fu1erVq3X8+HEVFBQ4bHvhhRdKpTAAAIDywOmw9P777+vRRx9VrVq1FBAQIJvNZt9ms9kISwAA4KridFgaP368XnnlFf373/8ui3oAAADKFaeXDvj999913333lUUtAAAA5Y7TYem+++7T8uXLy6IWAACAcsfpj+GaNm2q559/Xj/++KNatWpVaLmAxx9/vNSKAwAAcDWnw1J8fLyqV6+u77//Xt9//73DNpvNRlgCAABXFafD0sGDB8uiDgAAgHLpkr/59uzZszp48KCaNGlyRb5ANz09XY899pgWL14sNzc3xcbG6q233lL16tWLHXPmzBmNGDFCc+fOVV5enqKiovTee++pTp06Dv1mzJihKVOm6JdffpG3t7fuu+8+vfvuu2U9pRJJntjT1SUAAHBNc/oC79zcXMXFxalq1apq2bKlDh06JEl67LHHNHHixFIv8IL+/ftr586dWrFihZYsWaK1a9dedBXxp556SosXL9b8+fP1/fff6+jRo+rdu7dDnylTpmjMmDEaNWqUdu7cqe+++05RUVFlNg8AAFCx2IwxxpkBTzzxhDZs2KA333xT0dHR2rZtm4KDg/Xll1/qxRdf1JYtW0q9yKSkJLVo0UKbNm1S+/btJUnLli1TTEyMjhw5osDAwEJjMjMz5e/vrzlz5ujee++VJO3evVuhoaFKSEhQx44d9fvvv6tevXpavHixunfvfsn1ZWVlycfHR5mZmfL29r7k/QC4djUa9bWrSwDKrbL6lKWkv7+dPrO0aNEivfPOO+rcubPD6t0tW7bU/v37L63ai0hISJCvr689KElSZGSk3NzclJiYWOSYzZs3Kz8/X5GRkfa2kJAQNWjQQAkJCZKkFStWqKCgQCkpKQoNDVX9+vXVp08fHT582LKevLw8ZWVlOTwAAMDVyemwdOLECdWuXbtQ+6lTpxzCU2lKTU0tdEx3d3f5+fkpNTW12DGenp7y9fV1aK9Tp459zIEDB1RQUKBXX31Vb775phYsWKD09HTdfvvtOnv2bLH1TJgwQT4+PvZHUFDQ5U0QAACUW06Hpfbt2+vrr///6eILAemDDz5QRESEU/saNWqUbDab5WP37t3OllhiBQUFys/P19tvv62oqCh17NhRn376qf2LgoszevRoZWZm2h8XOxMFAAAqLqdvY3v11VfVo0cP7dq1S+fOndNbb72lXbt26Ycffii07tLFjBgxQgMHDrTsExwcrICAAB0/ftyh/dy5c0pPT1dAQECR4wICAnT27FllZGQ4nF1KS0uzj6lbt64kqUWLFvbt/v7+qlWrlv3C9aJ4eXnJy8vLsm4AAHB1cDosde7cWVu3btXEiRPVqlUrLV++XO3atVNCQoJatWrl1L78/f3l7+9/0X4RERHKyMjQ5s2bFRYWJklatWqVCgoKFB4eXuSYsLAweXh4aOXKlYqNjZUk7dmzR4cOHbKfAbv55pvt7fXr15f0xxIFJ0+eVMOGDZ2aCwAAuDo5fTecq/To0UNpaWmaNm2a8vPzNWjQILVv315z5syRJKWkpKh79+6aNWuWOnToIEl69NFH9c0332jGjBny9vbWY489Jkn64Ycf7Pvt1auX9u3bp/j4eHl7e2v06NE6cOCAtm7dWuirXIrD3XAALhd3wwHFc/XdcCU6s+TM3V5lFRZmz56tYcOGqXv37vZFKd9++2379vz8fO3Zs0e5ubn2tjfeeMPe98+LUv7ZrFmz9NRTT6lnz55yc3NT165dtWzZshIHJQAAcHUr0ZklNze3Et/pdv78+csuqqLhzBKAy8WZJaB4FeLM0p/vDEtOTtaoUaM0cOBA+7U/CQkJmjlzpiZMmHCZZQMAAJQvJQpLXbt2tf/9pZde0pQpU9SvXz972913361WrVopPj5eAwYMKP0qAQAAXMTpdZYSEhIcVtK+oH379tq4cWOpFAUAAFBeOB2WgoKC9P777xdq/+CDD1jJGgAAXHWcXmfpjTfeUGxsrJYuXWpf42jjxo3au3evFi5cWOoFAgAAuJLTZ5ZiYmL0yy+/6K677lJ6errS09N111136ZdfflFMTExZ1AgAAOAyTp9Zkv74KO7VV18t7VoAAADKnRKFpW3btumGG26Qm5ubtm3bZtm3devWpVIYAABAeVCisHTjjTcqNTVVtWvX1o033iibzaai1rK02WzX5KKUAADg6lWisHTw4EH7F94ePHiwTAsCAAAoT0oUlv72t79p5cqVqlmzpmbOnKmRI0eqatWqZV0bAACAy5XobrikpCSdOnVKkjRu3Djl5OSUaVEAAADlRYmvWRo0aJA6d+4sY4wmT56s6tWrF9n3hRdeKNUCAQAAXKlEYWnGjBkaO3aslixZIpvNpqVLl8rdvfBQm81GWAIAAFeVEoWl5s2ba+7cuZIkNzc3rVy5UrVr1y7TwgAAAMoDpxelLCgoKIs6AAAAyqVLWsF77969Wr16tY4fP14oPPExHAAAuJo4HZbef/99Pfroo6pVq5YCAgJks9ns27hmCQAAXG2cDkvjx4/XK6+8on//+99lUQ8AAEC5UqJ1lv7s999/13333VcWtQAAAJQ7Toel++67T8uXLy+LWgAAAModpz+Ga9q0qZ5//nn9+OOPatWqlTw8PBy2P/7446VWHAAAgKvZjDHGmQGNGzcufmc2mw4cOHDZRVU0WVlZ8vHxUWZmpry9vV1dDoAKqNGor11dAlBuJU/sWSb7Lenvb6fPLB08ePCyCgMAAKhInL5m6c+MMXLyxBQAAECFcklhadasWWrVqpWqVKmiKlWqqHXr1vr4449LuzYAAACXc/pjuClTpuj555/XsGHDdPPNN0uS1q9fr0ceeUQnT57UU089VepFAgAAuIrTYWnq1Kn673//qwcffNDedvfdd6tly5Z68cUXCUsAAOCq4vTHcMeOHVOnTp0KtXfq1EnHjh0rlaIAAADKC6fDUtOmTTVv3rxC7Z999pmaNWtWKkUBAACUF05/DDdu3Djdf//9Wrt2rf2apQ0bNmjlypVFhigAAICKzOkzS7GxsUpMTFStWrW0aNEiLVq0SLVq1dLGjRv1t7/9rSxqBAAAcBmnzyxJUlhYmD755JPSrgUAAKDcKfGZpaNHj2rkyJHKysoqtC0zM1NPP/200tLSSrU4AAAAVytxWJoyZYqysrKK/O4UHx8fZWdna8qUKaVaHAAAgKuVOCwtW7bMYW2lv3rwwQe1ZMmSUikKAACgvChxWDp48KAaNGhQ7Pb69esrOTm5NGoCAAAoN0oclqpUqWIZhpKTk1WlSpXSqKlI6enp6t+/v7y9veXr66u4uDjl5ORYjjlz5oyGDh2q6667TtWrV1dsbGyh66o2bdqk7t27y9fXVzVr1lRUVJR+/vnnMpsHAACoWEoclsLDwy2/LHfWrFnq0KFDqRRVlP79+2vnzp1asWKFlixZorVr12rIkCGWY5566iktXrxY8+fP1/fff6+jR4+qd+/e9u05OTmKjo5WgwYNlJiYqPXr16tGjRqKiopSfn5+mc0FAABUHDZjjClJx9WrV+v222/Xk08+qaefflp16tSRJKWlpWnSpEl66623tHz5ct12222lXmRSUpJatGihTZs2qX379pL+uIYqJiZGR44cUWBgYKExmZmZ8vf315w5c3TvvfdKknbv3q3Q0FAlJCSoY8eO+t///qebbrpJhw4dUlBQkCRp+/btat26tfbu3aumTZuWqL6srCz5+PgoMzOzyAvgAeBiGo362tUlAOVW8sSeZbLfkv7+LvGZpW7duundd9/VO++8o8DAQNWsWVN+fn4KDAzUu+++q6lTp5ZJUJKkhIQE+fr62oOSJEVGRsrNzU2JiYlFjtm8ebPy8/MVGRlpbwsJCVGDBg2UkJAgSWrevLmuu+46TZ8+XWfPntXp06c1ffp0hYaGqlGjRmUyFwAAULE4tSjlww8/rDvvvFPz5s3Tvn37ZIzR9ddfr3vvvVf169cvqxqVmpqq2rVrO7S5u7vLz89PqampxY7x9PSUr6+vQ3udOnXsY2rUqKE1a9aoV69eevnllyVJzZo107fffit39+J/NHl5ecrLy7M/L2rtKQAAcHVwegXvevXq6amnniqVg48aNUqvvfaaZZ+kpKRSOVZRTp8+rbi4ON1888369NNPdf78eU2ePFk9e/bUpk2bir1gfcKECRo3blyZ1QUAAMqPS/q6k9IyYsQIDRw40LJPcHCwAgICdPz4cYf2c+fOKT09XQEBAUWOCwgI0NmzZ5WRkeFwdiktLc0+Zs6cOUpOTlZCQoLc3NzsbTVr1tSXX36pvn37Frnv0aNHa/jw4fbnWVlZ9mueAADA1cWlYcnf31/+/v4X7RcREaGMjAxt3rxZYWFhkqRVq1apoKBA4eHhRY4JCwuTh4eHVq5cqdjYWEnSnj17dOjQIUVEREiScnNz5ebmJpvNZh934XlBQUGx9Xh5ecnLy6vE8wQAABVXiS/wdqXQ0FBFR0dr8ODB2rhxozZs2KBhw4apb9++9jvhUlJSFBISoo0bN0r64ytY4uLiNHz4cK1evVqbN2/WoEGDFBERoY4dO0qSbr/9dv3+++8aOnSokpKStHPnTg0aNEju7u7q1q2by+YLAADKjwoRliRp9uzZCgkJUffu3RUTE6POnTsrPj7evj0/P1979uxRbm6uve2NN97QnXfeqdjYWHXp0kUBAQH6/PPP7dtDQkK0ePFibdu2TREREbrlllt09OhRLVu2THXr1r2i8wMAAOVTiddZ+rOMjAwtWLBA+/fv19NPPy0/Pz/99NNPqlOnjurVq1cWdZZrrLME4HKxzhJQPFevs+T0NUvbtm1TZGSkfHx8lJycrMGDB8vPz0+ff/65Dh06pFmzZl1W4QAAAOWJ0x/DDR8+XAMHDtTevXtVuXJle3tMTIzWrl1bqsUBAAC4mtNhadOmTXr44YcLtderV6/YBSIBAAAqKqfDkpeXV5ErVv/yyy8lWgYAAACgInE6LN1999166aWXlJ+fL0my2Ww6dOiQ/v3vf9vXMwIAALhaOB2W/vOf/ygnJ0e1a9fW6dOn1bVrVzVt2lQ1atTQK6+8UhY1AgAAuIzTd8P5+PhoxYoVWr9+vbZt26acnBy1a9dOkZGRZVEfAACAS13y15107txZnTt3Ls1aAAAAyh2nw9Lbb79dZLvNZlPlypXVtGlTdenSRZUqVbrs4gAAAFzN6bD0xhtv6MSJE8rNzVXNmjUlSb///ruqVq2q6tWr6/jx4woODtbq1asVFBRU6gUDAABcSU5f4P3qq6/qpptu0t69e/Xbb7/pt99+0y+//KLw8HC99dZbOnTokAICAvTUU0+VRb0AAABXlNNnlp577jktXLhQTZo0sbc1bdpUkydPVmxsrA4cOKBJkyaxjAAAALgqOH1m6dixYzp37lyh9nPnztlX8A4MDFR2dvblVwcAAOBiToelbt266eGHH9aWLVvsbVu2bNGjjz6q2267TZK0fft2NW7cuPSqBAAAcBGnw9L06dPl5+ensLAweXl5ycvLS+3bt5efn5+mT58uSapevbr+85//lHqxAAAAV5rT1ywFBARoxYoV2r17t3755RdJUvPmzdW8eXN7n27dupVehQAAAC50yYtShoSEKCQkpDRrAQAAKHcuKSwdOXJEX331lQ4dOqSzZ886bJsyZUqpFAYAAFAeOB2WVq5cqbvvvlvBwcHavXu3brjhBiUnJ8sYo3bt2pVFjQAAAC7j9AXeo0eP1siRI7V9+3ZVrlxZCxcu1OHDh9W1a1fdd999ZVEjAACAyzgdlpKSkvTggw9Kktzd3XX69GlVr15dL730kl577bVSLxAAAMCVnA5L1apVs1+nVLduXe3fv9++7eTJk6VXGQAAQDng9DVLHTt21Pr16xUaGqqYmBiNGDFC27dv1+eff66OHTuWRY0AAAAu43RYmjJlinJyciRJ48aNU05Ojj777DM1a9aMO+EAAMBVx6mwdP78eR05ckStW7eW9MdHctOmTSuTwgAAAMoDp65ZqlSpku644w79/vvvZVUPAABAueL0Bd433HCDDhw4UBa1AAAAlDtOh6Xx48dr5MiRWrJkiY4dO6asrCyHBwAAwNXE6Qu8Y2JiJEl33323bDabvd0YI5vNpvPnz5dedQAAAC7mdFhavXp1WdQBAABQLjkdlrp27VoWdQAAAJRLTl+zJEnr1q3TAw88oE6dOiklJUWS9PHHH2v9+vWlWhwAAICrOR2WFi5cqKioKFWpUkU//fST8vLyJEmZmZl69dVXS71AAAAAV7qku+GmTZum999/Xx4eHvb2m2++WT/99FOpFgcAAOBqToelPXv2qEuXLoXafXx8lJGRURo1AQAAlBtOh6WAgADt27evUPv69esVHBxcKkUBAACUF06HpcGDB+uJJ55QYmKibDabjh49qtmzZ2vkyJF69NFHy6JGAAAAl3F66YBRo0apoKBA3bt3V25urrp06SIvLy+NHDlSjz32WFnUCAAA4DJOn1my2WwaM2aM0tPTtWPHDv344486ceKEXn755bKozy49PV39+/eXt7e3fH19FRcXp5ycHMsx8fHxuvXWW+Xt7S2bzVbkNVWXsl8AAHDtcDosffLJJ8rNzZWnp6datGihDh06qHr16mVRm4P+/ftr586dWrFihZYsWaK1a9dqyJAhlmNyc3MVHR2tZ599tlT3CwAArh02Y4xxZoC/v79Onz6tu+++Ww888ICioqJUqVKlsqpPkpSUlKQWLVpo06ZNat++vSRp2bJliomJ0ZEjRxQYGGg5fs2aNerWrZt+//13+fr6ltp+L8jKypKPj48yMzPl7e19aZMEcE1rNOprV5cAlFvJE3uWyX5L+vvb6TNLx44d09y5c2Wz2dSnTx/VrVtXQ4cO1Q8//HBZBVtJSEiQr6+vPdBIUmRkpNzc3JSYmHjF95uXl6esrCyHBwAAuDo5HZbc3d115513avbs2Tp+/LjeeOMNJScnq1u3bmrSpElZ1KjU1FTVrl27UB1+fn5KTU294vudMGGCfHx87I+goKBLrgEAAJRvl/TdcBdUrVpVUVFR6tGjh5o1a6bk5GSnxo8aNUo2m83ysXv37sspsUyMHj1amZmZ9sfhw4ddXRIAACgjTi8dIP1x4fQXX3yh2bNna+XKlQoKClK/fv20YMECp/YzYsQIDRw40LJPcHCwAgICdPz4cYf2c+fOKT09XQEBAc6Wb3ep+/Xy8pKXl9clHxcAAFQcToelvn37asmSJapatar69Omj559/XhEREZd0cH9/f/n7+1+0X0REhDIyMrR582aFhYVJklatWqWCggKFh4df0rHLcr8AAODq4fTHcJUqVdK8efN07NgxvfPOOw5BaceOHaVa3AWhoaGKjo7W4MGDtXHjRm3YsEHDhg1T37597XespaSkKCQkRBs3brSPS01N1datW+1fz7J9+3Zt3bpV6enpJd4vAAC4tjkdlmbPnq2YmBj7cgHZ2dmKj49Xhw4d1KZNm1Iv8M/HDQkJUffu3RUTE6POnTsrPj7evj0/P1979uxRbm6uvW3atGlq27atBg8eLEnq0qWL2rZtq6+++qrE+wUAANc2p9dZumDt2rWaPn26Fi5cqMDAQPXu3VuxsbG66aabSrvGco91lgBcLtZZAorn6nWWnLpmKTU1VTNmzND06dOVlZWlPn36KC8vT4sWLVKLFi0uu2gAAIDypsQfw911111q3ry5tm3bpjfffFNHjx7V1KlTy7I2AAAAlyvxmaWlS5fq8ccf16OPPqpmzZqVZU0AAADlRonPLK1fv17Z2dkKCwtTeHi43nnnHZ08ebIsawMAAHC5Eoeljh076v3339exY8f08MMPa+7cuQoMDFRBQYFWrFih7OzssqwTAADAJZxeOqBatWr65z//qfXr12v79u0aMWKEJk6cqNq1a+vuu+8uixoBAABc5rK+G6558+aaNGmSjhw5ok8//bS0agIAACg3LissXVCpUiX16tXLYbFHAACAq0GphCUAAICrFWEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAQoUJS+np6erfv7+8vb3l6+uruLg45eTkWI6Jj4/XrbfeKm9vb9lsNmVkZDhsT05OVlxcnBo3bqwqVaqoSZMmGjt2rM6ePVuGMwEAABVJhQlL/fv3186dO7VixQotWbJEa9eu1ZAhQyzH5ObmKjo6Ws8++2yR23fv3q2CggL93//9n3bu3Kk33nhD06ZNK7Y/AAC49tiMMcbVRVxMUlKSWrRooU2bNql9+/aSpGXLlikmJkZHjhxRYGCg5fg1a9aoW7du+v333+Xr62vZ9/XXX9d///tfHThwoMT1ZWVlycfHR5mZmfL29i7xOAC4oNGor11dAlBuJU/sWSb7Lenv7wpxZikhIUG+vr72oCRJkZGRcnNzU2JiYqkeKzMzU35+fqW6TwAAUHG5u7qAkkhNTVXt2rUd2tzd3eXn56fU1NRSO86+ffs0depUTZ482bJfXl6e8vLy7M+zsrJKrQYAAFC+uPTM0qhRo2Sz2Swfu3fvviK1pKSkKDo6Wvfdd58GDx5s2XfChAny8fGxP4KCgq5IjQAA4Mpz6ZmlESNGaODAgZZ9goODFRAQoOPHjzu0nzt3Tunp6QoICLjsOo4ePapu3bqpU6dOio+Pv2j/0aNHa/jw4fbnWVlZBCYAAK5SLg1L/v7+8vf3v2i/iIgIZWRkaPPmzQoLC5MkrVq1SgUFBQoPD7+sGlJSUtStWzeFhYXpo48+kpvbxU+2eXl5ycvL67KOCwAAKoYKcYF3aGiooqOjNXjwYG3cuFEbNmzQsGHD1LdvX/udcCkpKQoJCdHGjRvt41JTU7V161bt27dPkrR9+3Zt3bpV6enp9jG33nqrGjRooMmTJ+vEiRNKTU0t1eugAABAxVYhLvCWpNmzZ2vYsGHq3r273NzcFBsbq7ffftu+PT8/X3v27FFubq69bdq0aRo3bpz9eZcuXSRJH330kQYOHKgVK1Zo37592rdvn+rXr+9wvAqwogIAALgCKsQ6S+Ud6ywBuFysswQUj3WWAAAAyjHCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgAXCEgAAgIUKE5bS09PVv39/eXt7y9fXV3FxccrJybEcEx8fr1tvvVXe3t6y2WzKyMgotm9eXp5uvPFG2Ww2bd26tXSLBwAAFVaFCUv9+/fXzp07tWLFCi1ZskRr167VkCFDLMfk5uYqOjpazz777EX3/8wzzygwMLC0ygUAAFcJd1cXUBJJSUlatmyZNm3apPbt20uSpk6dqpiYGE2ePLnYkPPkk09KktasWWO5/6VLl2r58uVauHChli5dWpqlAwCACq5CnFlKSEiQr6+vPShJUmRkpNzc3JSYmHhZ+05LS9PgwYP18ccfq2rVqiUak5eXp6ysLIcHAAC4OlWIsJSamqratWs7tLm7u8vPz0+pqamXvF9jjAYOHKhHHnnEIYhdzIQJE+Tj42N/BAUFXXINAACgfHNpWBo1apRsNpvlY/fu3WV2/KlTpyo7O1ujR492atzo0aOVmZlpfxw+fLiMKgQAAK7m0muWRowYoYEDB1r2CQ4OVkBAgI4fP+7Qfu7cOaWnpysgIOCSj79q1SolJCTIy8vLob19+/bq37+/Zs6cWeQ4Ly+vQmMAAMDVyaVhyd/fX/7+/hftFxERoYyMDG3evFlhYWGS/gg6BQUFCg8Pv+Tjv/322xo/frz9+dGjRxUVFaXPPvvssvYLAACuHhXibrjQ0FBFR0dr8ODBmjZtmvLz8zVs2DD17dvXfidcSkqKunfvrlmzZqlDhw6S/rjWKTU1Vfv27ZMkbd++XTVq1FCDBg3k5+enBg0aOBynevXqkqQmTZqofv36V3CGAACgvKoQF3hL0uzZsxUSEqLu3bsrJiZGnTt3Vnx8vH17fn6+9uzZo9zcXHvbtGnT1LZtWw0ePFiS1KVLF7Vt21ZfffXVFa8fAABUTDZjjHF1ERVdVlaWfHx8lJmZKW9vb1eXA6ACajTqa1eXAJRbyRN7lsl+S/r7u8KcWQIAAHAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAICFCrEoJQBc7crq1mgAl48zSwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABYISwAAABbcXV3A1cAYI0nKyspycSUAAKCkLvzevvB7vDiEpVKQnZ0tSQoKCnJxJQAAwFnZ2dny8fEpdrvNXCxO4aIKCgp09OhR1ahRQzabzdXllLmsrCwFBQXp8OHD8vb2dnU5V8y1Om+JuV+Lc79W5y0x92tp7sYYZWdnKzAwUG5uxV+ZxJmlUuDm5qb69eu7uowrztvb+5p4M/3VtTpviblfi3O/VuctMfdrZe5WZ5Qu4AJvAAAAC4QlAAAAC4QlOM3Ly0tjx46Vl5eXq0u5oq7VeUvM/Vqc+7U6b4m5X6tzt8IF3gAAABY4swQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsIRC0tPT1b9/f3l7e8vX11dxcXHKycmx7P/YY4+pefPmqlKliho0aKDHH39cmZmZDv1sNluhx9y5c8t6OpbeffddNWrUSJUrV1Z4eLg2btxo2X/+/PkKCQlR5cqV1apVK33zzTcO240xeuGFF1S3bl1VqVJFkZGR2rt3b1lO4ZI5M/f3339ft9xyi2rWrKmaNWsqMjKyUP+BAwcWen2jo6PLehpOc2beM2bMKDSnypUrO/S5Wl/zW2+9tcj3bM+ePe19KsJrvnbtWt11110KDAyUzWbTokWLLjpmzZo1ateunby8vNS0aVPNmDGjUB9n/+1wBWfn/vnnn+v222+Xv7+/vL29FRERoW+//dahz4svvljoNQ8JCSnDWZQTBviL6Oho06ZNG/Pjjz+adevWmaZNm5p+/foV23/79u2md+/e5quvvjL79u0zK1euNM2aNTOxsbEO/SSZjz76yBw7dsz+OH36dFlPp1hz5841np6e5sMPPzQ7d+40gwcPNr6+viYtLa3I/hs2bDCVKlUykyZNMrt27TLPPfec8fDwMNu3b7f3mThxovHx8TGLFi0yP//8s7n77rtN48aNXTrPojg797///e/m3XffNVu2bDFJSUlm4MCBxsfHxxw5csTeZ8CAASY6Otrh9U1PT79SUyoRZ+f90UcfGW9vb4c5paamOvS5Wl/z3377zWHeO3bsMJUqVTIfffSRvU9FeM2/+eYbM2bMGPP5558bSeaLL76w7H/gwAFTtWpVM3z4cLNr1y4zdepUU6lSJbNs2TJ7H2d/lq7i7NyfeOIJ89prr5mNGzeaX375xYwePdp4eHiYn376yd5n7NixpmXLlg6v+YkTJ8p4Jq5HWIKDXbt2GUlm06ZN9ralS5cam81mUlJSSryfefPmGU9PT5Ofn29vK8mb9Urq0KGDGTp0qP35+fPnTWBgoJkwYUKR/fv06WN69uzp0BYeHm4efvhhY4wxBQUFJiAgwLz++uv27RkZGcbLy8t8+umnZTCDS+fs3P/q3LlzpkaNGmbmzJn2tgEDBph77rmntEstVc7O+6OPPjI+Pj7F7u9aes3feOMNU6NGDZOTk2Nvqwiv+Z+V5N+gZ555xrRs2dKh7f777zdRUVH255f7s3SFS/33t0WLFmbcuHH252PHjjVt2rQpvcIqCD6Gg4OEhAT5+vqqffv29rbIyEi5ubkpMTGxxPvJzMyUt7e33N0dv35w6NChqlWrljp06KAPP/xQxkXLfJ09e1abN29WZGSkvc3NzU2RkZFKSEgockxCQoJDf0mKioqy9z948KBSU1Md+vj4+Cg8PLzYfbrCpcz9r3Jzc5Wfny8/Pz+H9jVr1qh27dpq3ry5Hn30Uf3222+lWvvluNR55+TkqGHDhgoKCtI999yjnTt32rddS6/59OnT1bdvX1WrVs2hvTy/5pfiYu/z0vhZVhQFBQXKzs4u9D7fu3evAgMDFRwcrP79++vQoUMuqvDKISzBQWpqqmrXru3Q5u7uLj8/P6WmppZoHydPntTLL7+sIUOGOLS/9NJLmjdvnlasWKHY2Fj961//0tSpU0utdmecPHlS58+fV506dRza69SpU+w8U1NTLftf+NOZfbrCpcz9r/79738rMDDQ4RdGdHS0Zs2apZUrV+q1117T999/rx49euj8+fOlWv+lupR5N2/eXB9++KG+/PJLffLJJyooKFCnTp105MgRSdfOa75x40bt2LFDDz30kEN7eX/NL0Vx7/OsrCydPn26VN4/FcXkyZOVk5OjPn362NvCw8M1Y8YMLVu2TP/973918OBB3XLLLcrOznZhpWXP/eJdcDUYNWqUXnvtNcs+SUlJl32crKws9ezZUy1atNCLL77osO3555+3/71t27Y6deqUXn/9dT3++OOXfVxcORMnTtTcuXO1Zs0ah4ud+/bta/97q1at1Lp1azVp0kRr1qxR9+7dXVHqZYuIiFBERIT9eadOnRQaGqr/+7//08svv+zCyq6s6dOnq1WrVurQoYND+9X4muMPc+bM0bhx4/Tll186/A90jx497H9v3bq1wsPD1bBhQ82bN09xcXGuKPWK4MzSNWLEiBFKSkqyfAQHBysgIEDHjx93GHvu3Dmlp6crICDA8hjZ2dmKjo5WjRo19MUXX8jDw8Oyf3h4uI4cOaK8vLzLnp+zatWqpUqVKiktLc2hPS0trdh5BgQEWPa/8Kcz+3SFS5n7BZMnT9bEiRO1fPlytW7d2rJvcHCwatWqpX379l12zaXhcuZ9gYeHh9q2bWuf07Xwmp86dUpz584t0S/C8vaaX4ri3ufe3t6qUqVKqfx3VN7NnTtXDz30kObNm1foI8m/8vX11fXXX1+hX/OSICxdI/z9/RUSEmL58PT0VEREhDIyMrR582b72FWrVqmgoEDh4eHF7j8rK0t33HGHPD099dVXXxW6vbooW7duVc2aNV3yhY2enp4KCwvTypUr7W0FBQVauXKlw5mEP4uIiHDoL0krVqyw92/cuLECAgIc+mRlZSkxMbHYfbrCpcxdkiZNmqSXX35Zy5Ytc7imrThHjhzRb7/9prp165ZK3ZfrUuf9Z+fPn9f27dvtc7raX3Ppj+Uy8vLy9MADD1z0OOXtNb8UF3ufl8Z/R+XZp59+qkGDBunTTz91WCaiODk5Odq/f3+Ffs1LxNVXmKP8iY6ONm3btjWJiYlm/fr1plmzZg5LBxw5csQ0b97cJCYmGmOMyczMNOHh4aZVq1Zm3759DreUnjt3zhhjzFdffWXef/99s337drN3717z3nvvmapVq5oXXnjBJXM05o/bf728vMyMGTPMrl27zJAhQ4yvr6/91vB//OMfZtSoUfb+GzZsMO7u7mby5MkmKSnJjB07tsilA3x9fc2XX35ptm3bZu65555yexu5M3OfOHGi8fT0NAsWLHB4fbOzs40xxmRnZ5uRI0eahIQEc/DgQfPdd9+Zdu3amWbNmpkzZ864ZI5FcXbe48aNM99++63Zv3+/2bx5s+nbt6+pXLmy2blzp73P1fqaX9C5c2dz//33F2qvKK95dna22bJli9myZYuRZKZMmWK2bNlifv31V2OMMaNGjTL/+Mc/7P0vLB3w9NNPm6SkJPPuu+8WuXSA1c+yvHB27rNnzzbu7u7m3XffdXifZ2Rk2PuMGDHCrFmzxhw8eNBs2LDBREZGmlq1apnjx49f8fldSYQlFPLbb7+Zfv36merVqxtvb28zaNAg+y9FY4w5ePCgkWRWr15tjDFm9erVRlKRj4MHDxpj/lh+4MYbbzTVq1c31apVM23atDHTpk0z58+fd8EM/7+pU6eaBg0aGE9PT9OhQwfz448/2rd17drVDBgwwKH/vHnzzPXXX288PT1Ny5Ytzddff+2wvaCgwDz//POmTp06xsvLy3Tv3t3s2bPnSkzFac7MvWHDhkW+vmPHjjXGGJObm2vuuOMO4+/vbzw8PEzDhg3N4MGDy90vD2Ocm/eTTz5p71unTh0TExPjsOaMMVfva26MMbt37zaSzPLlywvtq6K85sX9+3RhrgMGDDBdu3YtNObGG280np6eJjg42GFtqQusfpblhbNz79q1q2V/Y/5YRqFu3brG09PT1KtXz9x///1m3759V3ZiLmAzxkX3bgMAAFQAXLMEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEAABggbAEABZsNpsWLVrk6jIAuBBhCcBVa+DAgerVq5erywBQwRGWAAAALBCWAFwTbr31Vj3++ON65pln5Ofnp4CAAL344osOffbu3asuXbqocuXKatGihVasWFFoP4cPH1afPn3k6+srPz8/3XPPPUpOTpYk7d69W1WrVtWcOXPs/efNm6cqVapo165dZTk9AGWIsATgmjFz5kxVq1ZNiYmJmjRpkl566SV7ICooKFDv3r3l6empxMRETZs2Tf/+978dxufn5ysqKko1atTQunXrtGHDBlWvXl3R0dE6e/asQkJCNHnyZP3rX//SoUOHdOTIET3yyCN67bXX1KJFC1dMGUAp4It0AVy1Bg4cqIyMDC1atEi33nqrzp8/r3Xr1tm3d+jQQbfddpsmTpyo5cuXq2fPnvr1118VGBgoSVq2bJl69OihL774Qr169dInn3yi8ePHKykpSTabTZJ09uxZ+fr6atGiRbrjjjskSXfeeaeysrLk6empSpUqadmyZfb+ACoed1cXAABXSuvWrR2e161bV8ePH5ckJSUlKSgoyB6UJCkiIsKh/88//6x9+/apRo0aDu1nzpzR/v377c8//PBDXX/99XJzc9POnTsJSkAFR1gCcM3w8PBweG6z2VRQUFDi8Tk5OQoLC9Ps2bMLbfP397f//eeff9apU6fk5uamY8eOqW7dupdeNACXIywBgKTQ0FAdPnzYIdz8+OOPDn3atWunzz77TLVr15a3t3eR+0lPT9fAgQM1ZswYHTt2TP3799dPP/2kKlWqlPkcAJQNLvAGAEmRkZG6/vrrNWDAAP38889at26dxowZ49Cnf//+qlWrlu655x6tW7dOBw8e1Jo1a/T444/ryJEjkqRHHnlEQUFBeu655zRlyhSdP39eI0eOdMWUAJQSwhIASHJzc9MXX3yh06dPq0OHDnrooYf0yiuvOPSpWrWq1q5dqwYNGqh3794KDQ1VXFyczpw5I29vb82aNUvffPONPv74Y7m7u6tatWr65JNP9P7772vp0qUumhmAy8XdcAAAABY4swQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGCBsAQAAGDh/wFuvYBeuet8uQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Solutions by (ob, cb, child aggreg): \", root_node.ob_log_probs != None, root_node.cb_log_probs != None, root_node.child_aggregation_log_probs != None and root_node.child_aggregation_log_probs != [-1000])\n",
    "print(\"Solutions by (ob, cb, child aggreg): \", root_node.ob_answer, \" -  \", root_node.cb_answer, \" -  \", root_node.child_aggregation_answer)\n",
    "print(\"confidences by (ob, cb, child aggreg):\", root_node.calculate_avg_log_probs(root_node.ob_log_probs), \" -  \", root_node.calculate_avg_log_probs(root_node.cb_log_probs), \" -  \", root_node.calculate_avg_log_probs(root_node.child_aggregation_log_probs))\n",
    "root_node.plot_confidence_heatmap_for_my_solvers() # ob, cb, child_agg\n",
    "root_node.plot_confidence_bars_for_my_solvers() # ob, cb, child_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver Selection based on a ML model ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the tree to match probtree preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'children': ['What was the typical page count of Weird Tales magazine during the 1930s?',\n",
       "    'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?',\n",
       "    'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'],\n",
       "   'children_sum_scores': [-2.04336368615382,\n",
       "    -0.7338265208047,\n",
       "    -5.4407544111175],\n",
       "   'children_log_probs_lengths': [18, 20, 22]}}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dictionary structure should have question as key and the generated tree as value\n",
    "trees = {question: updated_tree_structure}\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "{'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': {'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': [['What was the typical page count of Weird Tales magazine during the 1930s?', 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'], -0.13696574363460032]}}\n"
     ]
    }
   ],
   "source": [
    "new_trees_format = {}\n",
    "\n",
    "for key, value in trees.items():\n",
    "    print(f\"Question: {key}\")\n",
    "    new_trees_format[key] = {}\n",
    "    for node, data in value.items():\n",
    "        # Calculate the score for the parent node based on the children scores, just by summing them / total length\n",
    "        # Now we do it by adding all of them and normalizing at the end. (as if all are generated at once as in prob tree)\n",
    "        # TODO:: may change this to some other calculation which is more powerful.\n",
    "        score = sum(data['children_sum_scores']) / sum(data['children_log_probs_lengths']) if sum(data['children_log_probs_lengths']) > 0 else -100\n",
    "        new_trees_format[key][node] = [data['children'], score]\n",
    "\n",
    "print(new_trees_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new_trees_format, open('question_decompositions.json', 'w'), indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "----------------------------------------------------------------\n",
      "father Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "qds {'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?': [['What was the typical page count of Weird Tales magazine during the 1930s?', 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'], -0.13696574363460032]}\n",
      "question in qds :: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "qds[question] [['What was the typical page count of Weird Tales magazine during the 1930s?', 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?'], -0.13696574363460032]\n",
      "qds[question][0] ['What was the typical page count of Weird Tales magazine during the 1930s?', 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?']\n",
      "any([x == question for x in qds[question][0]]) returned false\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "raw_data = new_trees_format.copy()\n",
    "print(len(raw_data.keys()))\n",
    "\n",
    "def check(question):\n",
    "    if re.search(r'<\\d+>', question):\n",
    "        return True\n",
    "tree = {}\n",
    "for father in raw_data:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"father\", father)\n",
    "    if check(father):\n",
    "        print(\"checked father returned true\", father)\n",
    "        print(father)\n",
    "        continue\n",
    "    qds = raw_data[father]\n",
    "    print(\"qds\", qds)\n",
    "    if qds is None:\n",
    "        continue\n",
    "    tree[father] = {}\n",
    "    for question in qds:\n",
    "        print(\"question in qds ::\", question)\n",
    "        if check(question):\n",
    "            print(\"checked question returned true ::\", question)\n",
    "            continue\n",
    "        print(\"qds[question]\", qds[question])\n",
    "        print(\"qds[question][0]\", qds[question][0])\n",
    "        if any([x == question for x in qds[question][0]]):\n",
    "            print(\"any([x == question for x in qds[question][0]]) returned true\")\n",
    "            print(\"found !!!\")\n",
    "            exit(1)\n",
    "            tree[father][question] = [[], None]\n",
    "        else:\n",
    "            print(\"any([x == question for x in qds[question][0]]) returned false\")\n",
    "            tree[father][question] = qds[question]\n",
    "    if len(qds[question]) > 3:\n",
    "        print(father)\n",
    "        print(qds[question])\n",
    "        print('haha')\n",
    "\n",
    "# json.dump(tree, open('valid_tree.json', 'w'), indent = 2)\n",
    "print(len(tree))\n",
    "question_decompositions = {}\n",
    "for father in tree:\n",
    "    qds = tree[father]\n",
    "    for q in qds:\n",
    "        if q not in question_decompositions:\n",
    "            question_decompositions[q] = qds[q]\n",
    "        else:\n",
    "            if question_decompositions[q] != qds[q]:\n",
    "                print(question_decompositions[q])\n",
    "                print(qds[q])\n",
    "            else:\n",
    "                print('haha')\n",
    "\n",
    "\n",
    "json.dump(question_decompositions, open('tree.json', 'w'), indent = 2)\n",
    "print(len(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'idx': 0, 'question_text': 'What was the typical page count of Weird Tales magazine during the 1930s?', 'sons': [], 'qd_logprob': None, 'fa': 3}, {'idx': 1, 'question_text': 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'sons': [], 'qd_logprob': None, 'fa': 3}, {'idx': 2, 'question_text': 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?', 'sons': [], 'qd_logprob': None, 'fa': 3}, {'idx': 3, 'question_text': 'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?', 'sons': [0, 1, 2], 'qd_logprob': -0.13696574363460032}]]\n"
     ]
    }
   ],
   "source": [
    "raw_data = [json.loads(line.strip()) for line in open('../../released_data/hotpotqa__v2_test_random_500.jsonl')]\n",
    "q2sub_q = json.load(open(\"./tree.json\"))\n",
    "q2dq = json.load(open(\"./question_decompositions.json\"))\n",
    "trees = []\n",
    "\n",
    "def dfs(q, tree):\n",
    "    # we can have cycles !!!! we must detect them otherwise we will fall in infinite loop :( \n",
    "    sons = []\n",
    "    for sub_q in q2sub_q.get(q, [[]])[0]:\n",
    "        son_idx = dfs(sub_q, tree)\n",
    "        sons.append(son_idx)\n",
    "    idx = len(tree)\n",
    "    tree.append({\n",
    "        \"idx\": idx,\n",
    "        \"question_text\": q,\n",
    "        \"sons\": sons,\n",
    "        \"qd_logprob\": q2sub_q.get(q, [[], None])[1]\n",
    "    })    \n",
    "    for son_idx in sons:\n",
    "        tree[son_idx][\"fa\"] = idx\n",
    "    return idx\n",
    "\n",
    "for item in raw_data:\n",
    "    question = item['question_text'].strip()\n",
    "    # just added this since we dont have answers for all 500 questions now, just some of them\n",
    "    try:\n",
    "        question = list(q2dq[question].keys())[0]\n",
    "    except:\n",
    "        continue\n",
    "    assert question in q2sub_q, question\n",
    "    tree = []\n",
    "    # just added this to overcome the cyclic problem for now\n",
    "    try:\n",
    "        dfs(question, tree)\n",
    "    except:\n",
    "        continue\n",
    "    trees.append(tree)\n",
    "\n",
    "print(trees)\n",
    "json.dump(trees, open(\"trees.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run script to get answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1 | Start Processing...\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "1\n",
      "node {'idx': 0, 'question_text': 'What was the typical page count of Weird Tales magazine during the 1930s?', 'sons': [], 'qd_logprob': None, 'fa': 3}\n",
      "question, ref_tokens What was the typical page count of Weird Tales magazine during the 1930s? []\n",
      "Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "\n",
      "The exact format should be:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "Example Format:\n",
      "\n",
      "Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "Q: How many episodes were in the South Korean television series in which Ryu Hye−young played Bo−ra?\n",
      "A: The South Korean television series in which Ryu Hye−young played Bo−ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "Q: In what country was Lost Gravity manufactured?\n",
      "A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2009?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para−military training?\n",
      "A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para−military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "Q: Does The Border Surrender or Unsane have more members?\n",
      "A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "Q: James Paris Lee is best known for investing the Lee−Metford rifle and another rifle often referred to by what acronymn?\n",
      "A: James Paris Lee is best known for investing the Lee−Metford rifle and Lee–Enfield series of rifles. Lee–Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2008?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "Q: What year did Edburga of Minster−in−Thanet's father die?\n",
      "A: The father of Edburga of Minster−in−Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "Q: Were Lonny and Allure both founded in the 1990s?\n",
      "A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "Q: When was Jan de Bont born?\n",
      "A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "Q: Are both Bruce Chatwin and O. Henry writers？\n",
      "A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "Q: Which city is Lake Wales Medical Center located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "Now, please answer the following question in the same format:\n",
      "Q: What was the typical page count of Weird Tales magazine during the 1930s?\n",
      "A:\n",
      "node[\"cb_answer\"] ('128.', -0.04674831330879125, 'Weird Tales magazine was a pulp magazine that was published from 1923 to 1954. During the 1930s, the typical page count of Weird Tales magazine was 128 pages. So the answer is: 128.') \n",
      "\n",
      "single hop prompt Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "Answer in the following format:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "#1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "#2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "#3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "#1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "#2 Wikipedia Title: Hallelujah I Love Her So\n",
      "Text: ``Hallelujah I Love Her So ''Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B - side`` What Would I Do Without You'' Released 1956 Format 7 ''45rpm Recorded 1956 Genre soul rhythm and blues Length 2: 35 Label Atlantic Songwriter (s) Ray Charles Producer (s) Jerry Wexler Ray Charles singles chronology ``A Fool for You'' (1955)`` Hallelujah I Love Her So ''(1956) ``Mary Ann'' (1956)`` A Fool for You ''(1955) ``Hallelujah I Love Her So'' (1956)`` Mary Ann ''(1956)\n",
      "#3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "Text: ``The First Time Ever I Saw Your Face ''Single by Roberta Flack from the album First Take Released March 7, 1972 (1972 - 03 - 07) Recorded 1969 Genre Soul vocal jazz Length 5: 22 4: 15 (1972 radio edit) Label Atlantic 2864 Songwriter (s) Ewan MacColl Producer (s) Joel Dorn Roberta Flack singles chronology`` Will You Still Love Me Tomorrow'' (1972) ``The First Time Ever I Saw Your Face ''(1972)`` Where Is the Love'' (1972) ``Will You Still Love Me Tomorrow ''(1972)`` The First Time Ever I Saw Your Face'' (1972) ``Where Is the Love ''(1972)\n",
      "Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "#1 Wikipedia Title: Oberoi family\n",
      "Text: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.\n",
      "#2 Wikipedia Title: The Oberoi Group\n",
      "Text: The Oberoi Group is a hotel company with its head office in Delhi. Founded in 1934, the company owns and/or operates 30+ luxury hotels and two river cruise ships in six countries, primarily under its Oberoi Hotels & Resorts and Trident Hotels brands.\n",
      "#3 Wikipedia Title: Mohan Singh Oberoi\n",
      "Text: Rai Bahadur Mohan Singh Oberoi (15 August 1898 – 3 May 2002) was an Indian hotelier, the founder and chairman of Oberoi Hotels & Resorts, India's second-largest hotel company, with 35 hotels in India, Sri Lanka, Nepal, Egypt, Australia and Hungary.\n",
      "Q: The Oberoi family is part of which hotel company?\n",
      "A: The Oberoi family is part of the hotel company The Oberoi Group. So the answer is: The Oberoi Group.\n",
      "\n",
      "#1 Wikipedia Title: The Opener of the Way\n",
      "Text: Most of the stories had appeared in the magazine \"Weird Tales\" in the 1930s and 1940s.\n",
      "#2 Wikipedia Title: Weird Tales (disambiguation)\n",
      "Text: Weird Tales is a pulp magazine.\n",
      "#3 Wikipedia Title: Terror Tales\n",
      "Text: Terror Tales was the name of two American publications: a pulp magazine of the weird menace genre of the 1930s, and a horror comic in the 1960s and 1970s.\n",
      "#4 Wikipedia Title: Hugh Doak Rankin\n",
      "Text: Hugh Doak Rankin, born Hugh Dearborn Copp (July 2, 1878— January 3, 1956) was an American artist who illustrated the science fiction magazine \"Weird Tales\" in the 1920s and 1930s.\n",
      "#5 Wikipedia Title: Weird Tales (album)\n",
      "Text: Weird Tales is American band Golden Smog's second album, released in 1998. The title comes from the pulp magazine \"Weird Tales\", the cover art being from the October 1933 issue, by Margaret Brundage.\n",
      "Q: What was the typical page count of Weird Tales magazine during the 1930s?\n",
      "A:\n",
      "single hop response [{'finish_reason': 'eos', 'index': 0, 'logprobs': {'token_ids': [14109, 13, 128009], 'token_logprobs': [-0.8359375, -0.011474609, -0.0095825195], 'tokens': ['Unknown', '.', '<|eot_id|>']}, 'message': {'content': 'Unknown.', 'role': 'assistant', 'tool_calls': []}, 'seed': 14412588295753599000}]\n",
      "node[\"ob_answer\"] ('Unknown.', -100, 'Unknown.') \n",
      "\n",
      "node[\"answer\"] ('128.', -0.04674831330879125, 'Weird Tales magazine was a pulp magazine that was published from 1923 to 1954. During the 1930s, the typical page count of Weird Tales magazine was 128 pages. So the answer is: 128.') \n",
      "\n",
      "node {'idx': 1, 'question_text': 'Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?', 'sons': [], 'qd_logprob': None, 'fa': 3}\n",
      "question, ref_tokens Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s? []\n",
      "Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "\n",
      "The exact format should be:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "Example Format:\n",
      "\n",
      "Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "Q: How many episodes were in the South Korean television series in which Ryu Hye−young played Bo−ra?\n",
      "A: The South Korean television series in which Ryu Hye−young played Bo−ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "Q: In what country was Lost Gravity manufactured?\n",
      "A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2009?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para−military training?\n",
      "A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para−military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "Q: Does The Border Surrender or Unsane have more members?\n",
      "A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "Q: James Paris Lee is best known for investing the Lee−Metford rifle and another rifle often referred to by what acronymn?\n",
      "A: James Paris Lee is best known for investing the Lee−Metford rifle and Lee–Enfield series of rifles. Lee–Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2008?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "Q: What year did Edburga of Minster−in−Thanet's father die?\n",
      "A: The father of Edburga of Minster−in−Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "Q: Were Lonny and Allure both founded in the 1990s?\n",
      "A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "Q: When was Jan de Bont born?\n",
      "A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "Q: Are both Bruce Chatwin and O. Henry writers？\n",
      "A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "Q: Which city is Lake Wales Medical Center located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "Now, please answer the following question in the same format:\n",
      "Q: Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?\n",
      "A:\n",
      "node[\"cb_answer\"] ('yes.', -0.12651993165155342, 'Robert E. Howard was a writer, best known for creating the character Conan the Barbarian. He was a frequent contributor to Weird Tales magazine during the 1930s. So the answer is: yes.') \n",
      "\n",
      "single hop prompt Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "Answer in the following format:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "#1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "#2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "#3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "#1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "#2 Wikipedia Title: Hallelujah I Love Her So\n",
      "Text: ``Hallelujah I Love Her So ''Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B - side`` What Would I Do Without You'' Released 1956 Format 7 ''45rpm Recorded 1956 Genre soul rhythm and blues Length 2: 35 Label Atlantic Songwriter (s) Ray Charles Producer (s) Jerry Wexler Ray Charles singles chronology ``A Fool for You'' (1955)`` Hallelujah I Love Her So ''(1956) ``Mary Ann'' (1956)`` A Fool for You ''(1955) ``Hallelujah I Love Her So'' (1956)`` Mary Ann ''(1956)\n",
      "#3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "Text: ``The First Time Ever I Saw Your Face ''Single by Roberta Flack from the album First Take Released March 7, 1972 (1972 - 03 - 07) Recorded 1969 Genre Soul vocal jazz Length 5: 22 4: 15 (1972 radio edit) Label Atlantic 2864 Songwriter (s) Ewan MacColl Producer (s) Joel Dorn Roberta Flack singles chronology`` Will You Still Love Me Tomorrow'' (1972) ``The First Time Ever I Saw Your Face ''(1972)`` Where Is the Love'' (1972) ``Will You Still Love Me Tomorrow ''(1972)`` The First Time Ever I Saw Your Face'' (1972) ``Where Is the Love ''(1972)\n",
      "Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "#1 Wikipedia Title: Oberoi family\n",
      "Text: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.\n",
      "#2 Wikipedia Title: The Oberoi Group\n",
      "Text: The Oberoi Group is a hotel company with its head office in Delhi. Founded in 1934, the company owns and/or operates 30+ luxury hotels and two river cruise ships in six countries, primarily under its Oberoi Hotels & Resorts and Trident Hotels brands.\n",
      "#3 Wikipedia Title: Mohan Singh Oberoi\n",
      "Text: Rai Bahadur Mohan Singh Oberoi (15 August 1898 – 3 May 2002) was an Indian hotelier, the founder and chairman of Oberoi Hotels & Resorts, India's second-largest hotel company, with 35 hotels in India, Sri Lanka, Nepal, Egypt, Australia and Hungary.\n",
      "Q: The Oberoi family is part of which hotel company?\n",
      "A: The Oberoi family is part of the hotel company The Oberoi Group. So the answer is: The Oberoi Group.\n",
      "\n",
      "#1 Wikipedia Title: The Children of the Night\n",
      "Text: \"The Children of the Night\" is a 1931 short story by Robert E. Howard, belonging to the Cthulhu Mythos. It was first published in the pulp magazine \"Weird Tales\" in the April/May 1931 issue. Howard earned $60 for this publication.\n",
      "#2 Wikipedia Title: The Shadow Kingdom\n",
      "Text: \"The Shadow Kingdom\" by Robert E. Howard is the first of Howard's Kull stories, set in his fictional Thurian Age. It was first published in the pulp magazine \"Weird Tales\" in August 1929.\n",
      "#3 Wikipedia Title: Strange Tales (pulp magazine)\n",
      "Text: Strange Tales (cover-titled Strange Tales of Mystery and Terror) was a U.S. pulp magazine first published from 1931 to 1933 by Clayton Publications. It specialized in fantasy and weird fiction, and was a significant competitor to \"Weird Tales\", the leading magazine in the field. Its published stories include \"Wolves of Darkness\" by Jack Williamson, as well as work by Robert E. Howard and Clark Ashton Smith. The magazine ceased publication when Clayton entered bankruptcy. It was temporarily revived by Wildside Press, which published three issues edited by Robert M. Price from 2003 to 2007.\n",
      "#4 Wikipedia Title: Almuric\n",
      "Text: Almuric is a science fiction novel by Robert E. Howard. It was originally serialized in three parts in the magazine \"Weird Tales\" beginning in May 1939. The novel was first published in book form in 1964 by Ace Books.\n",
      "#5 Wikipedia Title: Nameless Cults (short story collection)\n",
      "Text: Nameless Cults: The Cthulhu Mythos Fiction of Robert E. Howard is a collection of Cthulhu Mythos short stories by Robert E. Howard. It was first published in the US in 2001 by Chaosium Press. All of these stories had been published previously, between 1929 and 1985, in \"Weird Tales\", \"From Beyond the Dark Gateway\", \"Strange Tales\", \"Weirdbook\", \"Fantasy Crosswinds\", \"Coven\", \"Fantasy Book\", \"Dark Things\", and \"The Fantasy Magazine\".\n",
      "Q: Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s?\n",
      "A:\n",
      "single hop response [{'finish_reason': 'eos', 'index': 0, 'logprobs': {'token_ids': [35632, 469, 13, 20462, 574, 264, 21420, 26373, 311, 77253, 54955, 14756, 2391, 279, 220, 7285, 15, 82, 13, 2100, 279, 4320, 374, 25, 10035, 13, 128009], 'token_logprobs': [-0.515625, -4.7683716e-07, -2.6226044e-06, -3.5762787e-07, -0.16601562, -0.0018081665, -0.0018005371, -8.34465e-07, -3.5762787e-07, -0.47460938, 0, -6.556511e-06, -0.002532959, -5.9604645e-07, 0, 0, 0, -9.536743e-07, -0.640625, -0.0011138916, -5.4836273e-06, 0, 0, 0, -0.0007095337, -0.00015544891, -2.348423e-05], 'tokens': ['Robert', ' E', '.', ' Howard', ' was', ' a', ' frequent', ' contributor', ' to', ' Weird', ' Tales', ' magazine', ' during', ' the', ' ', '193', '0', 's', '.', ' So', ' the', ' answer', ' is', ':', ' yes', '.', '<|eot_id|>']}, 'message': {'content': 'Robert E. Howard was a frequent contributor to Weird Tales magazine during the 1930s. So the answer is: yes.', 'role': 'assistant', 'tool_calls': []}, 'seed': 10842579307428823000}]\n",
      "node[\"ob_answer\"] ('yes.', -0.09489628515758158, 'Robert E. Howard was a frequent contributor to Weird Tales magazine during the 1930s. So the answer is: yes.') \n",
      "\n",
      "node[\"answer\"] ('yes.', -0.09489628515758158, 'Robert E. Howard was a frequent contributor to Weird Tales magazine during the 1930s. So the answer is: yes.') \n",
      "\n",
      "node {'idx': 2, 'question_text': 'Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?', 'sons': [], 'qd_logprob': None, 'fa': 3}\n",
      "question, ref_tokens Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine? []\n",
      "Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "\n",
      "The exact format should be:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "Example Format:\n",
      "\n",
      "Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "Q: How many episodes were in the South Korean television series in which Ryu Hye−young played Bo−ra?\n",
      "A: The South Korean television series in which Ryu Hye−young played Bo−ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "Q: In what country was Lost Gravity manufactured?\n",
      "A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2009?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para−military training?\n",
      "A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para−military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "Q: Does The Border Surrender or Unsane have more members?\n",
      "A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "Q: James Paris Lee is best known for investing the Lee−Metford rifle and another rifle often referred to by what acronymn?\n",
      "A: James Paris Lee is best known for investing the Lee−Metford rifle and Lee–Enfield series of rifles. Lee–Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2008?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "Q: What year did Edburga of Minster−in−Thanet's father die?\n",
      "A: The father of Edburga of Minster−in−Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "Q: Were Lonny and Allure both founded in the 1990s?\n",
      "A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "Q: When was Jan de Bont born?\n",
      "A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "Q: Are both Bruce Chatwin and O. Henry writers？\n",
      "A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "Q: Which city is Lake Wales Medical Center located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "Now, please answer the following question in the same format:\n",
      "Q: Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?\n",
      "A:\n",
      "node[\"cb_answer\"] (\"Robert E. Howard wrote for several fiction magazines in the 1930s, including Weird Tales. Weird Tales was a prominent magazine that published many of Howard's works, including his famous Conan the Barbarian stories. Therefore, the answer is: yes.\", -100, \"Robert E. Howard wrote for several fiction magazines in the 1930s, including Weird Tales. Weird Tales was a prominent magazine that published many of Howard's works, including his famous Conan the Barbarian stories. Therefore, the answer is: yes.\") \n",
      "\n",
      "single hop prompt Given a question and the relevant Wikipedia text, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "Answer in the following format:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "#1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "#2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "#3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "Q: Which track was the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. So the answer is: Mount Panorama Circuit.\n",
      "\n",
      "#1 Wikipedia Title: So Long, See You Tomorrow (album)\n",
      "Text: So Long, See You Tomorrow is the fourth album by the London indie rock band Bombay Bicycle Club, released on 3 February 2014. The album is named after the novel of the same name by William Maxwell.\n",
      "#2 Wikipedia Title: Hallelujah I Love Her So\n",
      "Text: ``Hallelujah I Love Her So ''Single by Ray Charles from the album Ray Charles (or, Hallelujah I Love Her So) B - side`` What Would I Do Without You'' Released 1956 Format 7 ''45rpm Recorded 1956 Genre soul rhythm and blues Length 2: 35 Label Atlantic Songwriter (s) Ray Charles Producer (s) Jerry Wexler Ray Charles singles chronology ``A Fool for You'' (1955)`` Hallelujah I Love Her So ''(1956) ``Mary Ann'' (1956)`` A Fool for You ''(1955) ``Hallelujah I Love Her So'' (1956)`` Mary Ann ''(1956)\n",
      "#3 Wikipedia Title: The First Time Ever I Saw Your Face\n",
      "Text: ``The First Time Ever I Saw Your Face ''Single by Roberta Flack from the album First Take Released March 7, 1972 (1972 - 03 - 07) Recorded 1969 Genre Soul vocal jazz Length 5: 22 4: 15 (1972 radio edit) Label Atlantic 2864 Songwriter (s) Ewan MacColl Producer (s) Joel Dorn Roberta Flack singles chronology`` Will You Still Love Me Tomorrow'' (1972) ``The First Time Ever I Saw Your Face ''(1972)`` Where Is the Love'' (1972) ``Will You Still Love Me Tomorrow ''(1972)`` The First Time Ever I Saw Your Face'' (1972) ``Where Is the Love ''(1972)\n",
      "Q: Is the performer of So Long, See You Tomorrow Bombay Bicycle Club?\n",
      "A: The performer of So Long, See You Tomorrow is Bombay Bicycle Club. So the answer is: yes.\n",
      "\n",
      "#1 Wikipedia Title: Oberoi family\n",
      "Text: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.\n",
      "#2 Wikipedia Title: The Oberoi Group\n",
      "Text: The Oberoi Group is a hotel company with its head office in Delhi. Founded in 1934, the company owns and/or operates 30+ luxury hotels and two river cruise ships in six countries, primarily under its Oberoi Hotels & Resorts and Trident Hotels brands.\n",
      "#3 Wikipedia Title: Mohan Singh Oberoi\n",
      "Text: Rai Bahadur Mohan Singh Oberoi (15 August 1898 – 3 May 2002) was an Indian hotelier, the founder and chairman of Oberoi Hotels & Resorts, India's second-largest hotel company, with 35 hotels in India, Sri Lanka, Nepal, Egypt, Australia and Hungary.\n",
      "Q: The Oberoi family is part of which hotel company?\n",
      "A: The Oberoi family is part of the hotel company The Oberoi Group. So the answer is: The Oberoi Group.\n",
      "\n",
      "#1 Wikipedia Title: Strange Tales (pulp magazine)\n",
      "Text: Strange Tales (cover-titled Strange Tales of Mystery and Terror) was a U.S. pulp magazine first published from 1931 to 1933 by Clayton Publications. It specialized in fantasy and weird fiction, and was a significant competitor to \"Weird Tales\", the leading magazine in the field. Its published stories include \"Wolves of Darkness\" by Jack Williamson, as well as work by Robert E. Howard and Clark Ashton Smith. The magazine ceased publication when Clayton entered bankruptcy. It was temporarily revived by Wildside Press, which published three issues edited by Robert M. Price from 2003 to 2007.\n",
      "#2 Wikipedia Title: Almuric\n",
      "Text: Almuric is a science fiction novel by Robert E. Howard. It was originally serialized in three parts in the magazine \"Weird Tales\" beginning in May 1939. The novel was first published in book form in 1964 by Ace Books.\n",
      "#3 Wikipedia Title: The Shadow Kingdom\n",
      "Text: \"The Shadow Kingdom\" by Robert E. Howard is the first of Howard's Kull stories, set in his fictional Thurian Age. It was first published in the pulp magazine \"Weird Tales\" in August 1929.\n",
      "#4 Wikipedia Title: Nameless Cults (short story collection)\n",
      "Text: Nameless Cults: The Cthulhu Mythos Fiction of Robert E. Howard is a collection of Cthulhu Mythos short stories by Robert E. Howard. It was first published in the US in 2001 by Chaosium Press. All of these stories had been published previously, between 1929 and 1985, in \"Weird Tales\", \"From Beyond the Dark Gateway\", \"Strange Tales\", \"Weirdbook\", \"Fantasy Crosswinds\", \"Coven\", \"Fantasy Book\", \"Dark Things\", and \"The Fantasy Magazine\".\n",
      "#5 Wikipedia Title: The Children of the Night\n",
      "Text: \"The Children of the Night\" is a 1931 short story by Robert E. Howard, belonging to the Cthulhu Mythos. It was first published in the pulp magazine \"Weird Tales\" in the April/May 1931 issue. Howard earned $60 for this publication.\n",
      "Q: Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine?\n",
      "A:\n",
      "single hop response [{'finish_reason': 'eos', 'index': 0, 'logprobs': {'token_ids': [35632, 469, 13, 20462, 6267, 304, 3892, 64188, 32947, 304, 279, 220, 7285, 15, 82, 11, 2737, 330, 1687, 2668, 54955, 498, 330, 92434, 54955, 498, 323, 3885, 13, 2100, 279, 4320, 374, 25, 912, 13, 128009], 'token_logprobs': [-0.7421875, -2.2649765e-06, -4.029274e-05, -3.5762787e-07, -0.18847656, -0.076171875, -0.140625, -0.40820312, -0.00091934204, -0.15332031, -3.695488e-06, 0, -1.1920929e-07, 0, -1.1920929e-07, -0.0013427734, -0.008117676, -0.20898438, -0.00044441223, 0, 0, -0.048583984, -0.0011749268, -0.0010223389, -5.722046e-06, -0.0011749268, -0.001876831, -0.0018844604, -0.079589844, -0.002456665, -7.4863434e-05, 0, 0, 0, -0.104003906, -0.18457031, -0.00018596649], 'tokens': ['Robert', ' E', '.', ' Howard', ' wrote', ' in', ' several', ' pulp', ' magazines', ' in', ' the', ' ', '193', '0', 's', ',', ' including', ' \"', 'We', 'ird', ' Tales', '\",', ' \"', 'Strange', ' Tales', '\",', ' and', ' others', '.', ' So', ' the', ' answer', ' is', ':', ' no', '.', '<|eot_id|>']}, 'message': {'content': 'Robert E. Howard wrote in several pulp magazines in the 1930s, including \"Weird Tales\", \"Strange Tales\", and others. So the answer is: no.', 'role': 'assistant', 'tool_calls': []}, 'seed': 4209444113414413000}]\n",
      "node[\"ob_answer\"] ('no.', -0.07117768385748104, 'Robert E. Howard wrote in several pulp magazines in the 1930s, including \"Weird Tales\", \"Strange Tales\", and others. So the answer is: no.') \n",
      "\n",
      "node[\"answer\"] ('no.', -0.07117768385748104, 'Robert E. Howard wrote in several pulp magazines in the 1930s, including \"Weird Tales\", \"Strange Tales\", and others. So the answer is: no.') \n",
      "\n",
      "node {'idx': 3, 'question_text': 'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?', 'sons': [0, 1, 2], 'qd_logprob': -0.13696574363460032}\n",
      "question, ref_tokens Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s? []\n",
      "Please answer the following question by breaking it down step-by-step, and ensure that your response is formatted according to the example provided below.\n",
      "\n",
      "The exact format should be:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "Example Format:\n",
      "\n",
      "Q: Jeremy Theobald and Christopher Nolan share what profession?\n",
      "A: Jeremy Theobald is an actor and producer. Christopher Nolan is a director, producer, and screenwriter. Therefore, they both share the profession of being a producer. So the answer is: producer.\n",
      "\n",
      "Q: How many episodes were in the South Korean television series in which Ryu Hye−young played Bo−ra?\n",
      "A: The South Korean television series in which Ryu Hye−young played Bo−ra is Reply 1988. The number of episodes Reply 1988 has is 20. So the answer is: 20.\n",
      "\n",
      "Q: Vertical Limit stars which actor who also played astronaut Alan Shepard in \"The Right Stuff\"?\n",
      "A: The movie Vertical Limit starred actors including Chiris O'Donnell, Robin Tunney, Scott Glenn, etc. The actor who played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the actor who stars in Vertical Limit and played astronaut Alan Shepard in \"The Right Stuff\" is Scott Glenn. So the answer is: Scott Glenn.\n",
      "\n",
      "Q: What was the 2014 population of the city where Lake Wales Medical Center is located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. The population of Polk County in 2014 was 15,140. So the answer is: 15,140.\n",
      "\n",
      "Q: Who was born first? Jan de Bont or Raoul Walsh?\n",
      "A: Jan de Bont was born on 22 October 1943. Raoul Walsh was born on March 11, 1887. Thus, Raoul Walsh was born the first. So the answer is: Raoul Walsh.\n",
      "\n",
      "Q: In what country was Lost Gravity manufactured?\n",
      "A: The Lost Gravity (roller coaster) was manufactured by Mack Rides. Mack Rides is a German company. So the answer is: Germany.\n",
      "\n",
      "Q: Which of the following had a debut album entitled \"We Have an Emergency\": Hot Hot Heat or The Operation M.D.?\n",
      "A: The debut album of the band \"Hot Hot Heat\" was \"Make Up the Breakdown\". The debut album of the band \"The Operation M.D.\" was \"We Have an Emergency\". So the answer is: The Operation M.D..\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2009?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: yes.\n",
      "\n",
      "Q: In which country did this Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" receive para−military training?\n",
      "A: The Australian who was detained in Guantanamo Bay detention camp and published \"Guantanamo: My Journey\" is David Hicks. David Hicks received his para−military training in Afghanistan. So the answer is: Afghanistan.\n",
      "\n",
      "Q: Does The Border Surrender or Unsane have more members?\n",
      "A: The Border Surrender band has following members: Keith Austin, Simon Shields, Johnny Manning and Mark Austin. That is, it has 4 members. Unsane has following members: Chris Spencer, Cooper, and Jon Syverson. That is, it has 3 members. Thus, The Border Surrender has more members. So the answer is: The Border Surrender.\n",
      "\n",
      "Q: James Paris Lee is best known for investing the Lee−Metford rifle and another rifle often referred to by what acronymn?\n",
      "A: James Paris Lee is best known for investing the Lee−Metford rifle and Lee–Enfield series of rifles. Lee–Enfield is often referred to by the acronym of SMLE. So the answer is: SMLE.\n",
      "\n",
      "Q: Was Lonny (magazine) was founded in 2008?\n",
      "A: Lonny (magazine) was founded in 2009. So the answer is: no.\n",
      "\n",
      "Q: What year did Edburga of Minster−in−Thanet's father die?\n",
      "A: The father of Edburga of Minster−in−Thanet is King Centwine. Centwine died after 685. So the answer is: after 685.\n",
      "\n",
      "Q: Were Lonny and Allure both founded in the 1990s?\n",
      "A: Lonny (magazine) was founded in 2009. Allure (magazine) was founded in 1991. Thus, of the two, only Allure was founded in 1990s. So the answer is: no.\n",
      "\n",
      "Q: The actor that stars as Joe Proctor on the series \"Power\" also played a character on \"Entourage\" that has what last name?\n",
      "A: The actor that stars as Joe Proctor on the series \"Power\" is Jerry Ferrara. Jerry Ferrara also played a character on Entourage named Turtle Assante. Turtle Assante's last name is Assante. So the answer is: Assante.\n",
      "\n",
      "Q: When was Jan de Bont born?\n",
      "A: Jan de Bont was born on 22 October 1943. So the answer is: 22 October 1943.\n",
      "\n",
      "Q: Nobody Loves You was written by John Lennon and released on what album that was issued by Apple Records, and was written, recorded, and released during his 18 month separation from Yoko Ono?\n",
      "A: Nobody Loves You was written by John Lennon and released on the album Walls and Bridges. The album issued by Apple Records, and written, recorded, and released during John Lennon's 18 month separation from Yoko Ono is Walls and Bridges. So the answer is: Walls and Bridges.\n",
      "\n",
      "Q: How many awards did the \"A Girl Like Me\" singer win at the American Music Awards of 2012?\n",
      "A: The singer of \"A Girl Like Me\" is Rihanna. In the American Music Awards of 2012, Rihana won one award. So the answer is: one.\n",
      "\n",
      "Q: Are both Bruce Chatwin and O. Henry writers？\n",
      "A: Bruce Chatwin was an English travel writer, novelist, and journalist. O. Henry was an American writer. So both Bruce Chatwin and O. Henry are writers. So the answer is: yes.\n",
      "\n",
      "Q: Which city is Lake Wales Medical Center located?\n",
      "A: Lake Wales Medical Center is located in the city of Polk County, Florida. So the answer is: Polk County, Florida.\n",
      "\n",
      "Q: Dadi Denis studied at a Maryland college whose name was changed in 1890 to honor what man?\n",
      "A: Dadi Denis studied at the Maryland college Morgan State University. In 1890, the university's name was changed to honor Reverend Lyttleton Morgan. So the answer is: Reverend Lyttleton Morgan.\n",
      "\n",
      "Q: William Orman Beerman was born in a city in northeastern Kansas that is the county seat of what county?\n",
      "A: William Orman Beerman was born in Manhattan, Kansas. Manhattan, Kansas is the county seat of Riley County. So the answer is: Riley County.\n",
      "\n",
      "Now, please answer the following question in the same format:\n",
      "Q: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "A:\n",
      "node[\"cb_answer\"] ('128.', -0.05677182762944357, 'The fiction magazine in which Robert E. Howard wrote in 1930s is Weird Tales. Typically, Weird Tales had 128 pages. So the answer is: 128.') \n",
      "\n",
      "Given a question and context, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "Answer in the following format:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "#1 Wikipedia Title: First (magazine)\n",
      "Text: FiRST is a Singaporean movie magazine formerly published monthly, now running as a weekly newspaper insert.\n",
      "#2 Wikipedia Title: Arthur's Magazine\n",
      "Text: Arthur's Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century. Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others. In May 1846 it was merged into \"Godey's Lady's Book\".\n",
      "#3 Wikipedia Title: First for Women\n",
      "Text: First for Women is a woman's magazine published by Bauer Media Group in the USA. The magazine was started in 1989. It is based in Englewood Cliffs, New Jersey. In 2011 the circulation of the magazine was 1,310,696 copies.\n",
      "#4 Wikipedia Title: First Eleven (magazine)\n",
      "Text: First Eleven is a British specialist magazine for parents of children at independent schools.\n",
      "#5 Wikipedia Title: Earth First! (magazine)\n",
      "Text: Earth First!, the radical environmental journal, is the official publication of the Earth First! movement. First published as a newsletter in 1980, it has existed alongside the movement as a way to spread commonly held beliefs in \"Earth First!\" culture, such as biocentrism, deep ecology, and direct action. The magazine is also commonly known as the \"Earth First! Journal\".\n",
      "Q: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "A: Arthur's Magazine was started in 1844. First for Women was started in 1989. So Arthur's Magazine was started first. So the answer is: Arthur's Magazine.\n",
      "\n",
      "#1 Wikipedia Title: The Oberoi Group\n",
      "Text: The Oberoi Group is a hotel company with its head office in Delhi. Founded in 1934, the company owns and/or operates 30+ luxury hotels and two river cruise ships in six countries, primarily under its Oberoi Hotels & Resorts and Trident Hotels brands.\n",
      "#2 Wikipedia Title: The Body Has a Head\n",
      "Text: The Body Has a Head is an album by King Missile frontman John S. Hall, released exclusively in Germany in 1996. Though billed as a Hall \"solo album,\" the collection features considerable input from multi-instrumentalists Sasha Forte, Bradford Reed, and Jane Scarpantoni, all of whom would become members of the next incarnation of King Missile (\"King Missile III\") and contribute to that group's \"debut\" album, 1998's \"Failure.\"\n",
      "#3 Wikipedia Title: Oberoi family\n",
      "Text: The Oberoi family is an Indian family that is famous for its involvement in hotels, namely through The Oberoi Group.\n",
      "#4 Wikipedia Title: Has-a\n",
      "Text: In database design, object-oriented programming and design (see object oriented program architecture), has-a (has_a or has a) is a composition relationship where one object (often called the constituted object, or part/constituent/member object) \"belongs to\" (is part or member of) another object (called the composite type), and behaves according to the rules of ownership. In simple words, has-a relationship in an object is called a member field of an object. Multiple has-a relationships will combine to form a possessive hierarchy.\n",
      "#5 Wikipedia Title: Oberoi Realty\n",
      "Text: Oberoi Realty is a real estate developer based in Mumbai, Maharashtra. It is led by Mr. Vikas Oberoi, CMD. The company has developed over 39 projects at locations across Mumbai. Its main interest is in Residential, Office Space, Retail, Hospitality and Social Infrastructure properties in Mumbai.\n",
      "Q: The Oberoi family is part of a hotel company that has a head office in what city?\n",
      "A: The Oberoi family is part of a hotel company The Oberoi Group. The Oberoi Group has a head office in Delhi. So the answer is: Delhi.\n",
      "\n",
      "#1 Wikipedia Title: 2014 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2014 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 9 February 2014, was the twelfth running of the Bathurst 12 Hour.\n",
      "#2 Wikipedia Title: 2015 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2015 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars and Group 3E Series Production Cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 8 February 2015, was the thirteenth running of the Bathurst 12 Hour.\n",
      "#3 Wikipedia Title: 2013 Liqui Moly Bathurst 12 Hour\n",
      "Text: The 2013 Liqui Moly Bathurst 12 Hour was an endurance race for a variety of GT and touring car classes, including: GT3 cars, GT4 cars, Group 3E Series Production Cars and Dubai 24 Hour cars. The event, which was staged at the Mount Panorama Circuit, near Bathurst, in New South Wales, Australia on 10 February 2013, was the eleventh running of the Bathurst 12 Hour. The race also incorporated the opening round of the 2013 Australian GT Championship. The Australian GT Championship was to compete as the first hour only and cars were permitted to enter for only that hour or to cross-enter for both the first hour and continue for the endurance race.\n",
      "#4 Wikipedia Title: Mount Panorama Circuit\n",
      "Text: Mount Panorama Circuit is a motor racing track located in Bathurst, New South Wales, Australia. It is situated on a hill with the dual official names of Mount Panorama and Wahluu and is best known as the home of the Bathurst 1000 motor race held each October, and the Bathurst 12 Hour event held each February. The 6.213 km long track is technically a street circuit, and is a public road, with normal speed restrictions, when no racing events are being run, and there are many residences which can only be accessed from the circuit.\n",
      "#5 Wikipedia Title: List of Mount Panorama races\n",
      "Text: This is a list of significant car races that have been held at the Mount Panorama Circuit near Bathurst, New South Wales, Australia. As Australia's most famous motor racing circuit, Mount Panorama has had a significant influence on the history and industry of Australian motor racing.\n",
      "Q: What is the length of the track where the 2013 Liqui Moly Bathurst 12 Hour was staged?\n",
      "A: The 2013 Liqui Moly Bathurst 12 Hour was staged at the Mount Panorama Circuit. Mount Panorama Circuit is 6.213 km long. So the answer is: 6.213 km long.\n",
      "\n",
      "#1 Wikipedia Title: Robert E. Howard bibliography (poems A–H)\n",
      "Text: A list of poems by Robert E. Howard (1906–1936), an American writer and poet in early 20th century Texas. His love of poetry came from being read to by his mother at a young age. However, his attempts to make a living by poetry were unsuccessful and he is today most remembered for his short stories and fiction. Nevertheless, Howard wrote hundreds of poems; many were published within his lifetime and the others published after his 1936 suicide.\n",
      "#2 Wikipedia Title: Robert E. Howard bibliography (poems I–O)\n",
      "Text: A list of poems by Robert E. Howard (1906–1936), an American writer and poet in early 20th century Texas. His love of poetry came from being read to by his mother at a young age. However, his attempts to make a living by poetry were unsuccessful and he is today most remembered for his short stories and fiction. Nevertheless, Howard wrote hundreds of poems; many were published within his lifetime and the others published after his 1936 suicide.\n",
      "#3 Wikipedia Title: Robert E. Howard bibliography (poems P–Z)\n",
      "Text: A list of poems by Robert E. Howard (1906–1936), an American writer and poet in early 20th century Texas. His love of poetry came from being read to by his mother at a young age. However, his attempts to make a living by poetry were unsuccessful and he is today most remembered for his short stories and fiction. Nevertheless, Howard wrote hundreds of poems; many were published within his lifetime and the others published after his 1936 suicide.\n",
      "#4 Wikipedia Title: Almuric\n",
      "Text: Almuric is a science fiction novel by Robert E. Howard. It was originally serialized in three parts in the magazine \"Weird Tales\" beginning in May 1939. The novel was first published in book form in 1964 by Ace Books.\n",
      "#5 Wikipedia Title: The Miscast Barbarian\n",
      "Text: The Miscast Barbarian: a Biography of Robert E. Howard is a biography of the writer Robert E. Howard by science-fiction writer L. Sprague de Camp, first published in hardcover and trade paperback in 1975 by Gerry de la Ree.\n",
      "Q: Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "A:\n",
      "node[\"ob_answer\"] ('Unknown.', -100, 'Unknown.') \n",
      "\n",
      "Given a question and context, answer the question in the same format as the examples provided, citing the relevant context first and then providing the answer. If you are unsure, respond with \"Unknown.\"\n",
      "Answer in the following format:\n",
      "[Explanation]. So the answer is: [Answer]\n",
      "\n",
      "#\n",
      "Context:\n",
      "Which famous fashion show Stella Maxwell has been a model for? Victoria's Secret.\n",
      "Since when Victoria's Secret? 1977.\n",
      "\n",
      "Question:\n",
      "Stella Maxwell has been a model for a famous fashion shown since when?\n",
      "\n",
      "Answer:\n",
      "Stella Maxwell has been a model for a famous fashion shown, Victoria's Secret since 2015. So the answer is: since 2015.\n",
      "#\n",
      "Context:\n",
      "Who is the American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers? Devean George.\n",
      "William Novac co-wrote the memoir of Devean George? no.\n",
      "\n",
      "Question:\n",
      "William Novac co-wrote the memoir of what American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers?\n",
      "\n",
      "Answer:\n",
      "William Novac co-wrote the memoir of Magic Johnson, an American retired professional basketball player who is current president of basketball operations for the Los Angeles Lakers. So the answer is: Magic Johnson.\n",
      "#\n",
      "Context:\n",
      "Which athlete rode 400 miles across his country to bring attention to the plight of the disabled in the country? Emmanuel Ofosu Yeboah.\n",
      "What is the title of the documentary narrated by Oprah Winfrey about Emmanuel Ofosu Yeboah? Emmanuel's Gift.\n",
      "\n",
      "Question:\n",
      "Oprah Winfrey narrated a documentary about this athlete who rode 400 miles across his country to bring attention to the plight of the disabled in the country?\n",
      "\n",
      "Answer:\n",
      "Oprah Winfrey narrated a documentary about the athelete Emmanuel Ofosu Yeboah, who rode 400 miles across his country to bring attention to the plight of the disabled in the country. So the answer is: Emmanuel Ofosu Yeboah.\n",
      "#\n",
      "Context:\n",
      "\n",
      "What was the typical page count of Weird Tales magazine during the 1930s? 128.\n",
      "Was Robert E. Howard a frequent contributor to Weird Tales magazine during the 1930s? yes.\n",
      "Was the fiction magazine in which Robert E. Howard wrote in 1930s primarily Weird Tales magazine? no.\n",
      "\n",
      "Question:\n",
      "Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?\n",
      "\n",
      "Answer:\n",
      "node[\"child_answer\"] ('Unknown.', -0.08761554519669083, 'The fiction magazine in which Robert E. Howard wrote in 1930s was not primarily Weird Tales magazine, but the typical page count of Weird Tales magazine during the 1930s was 128. So the answer is: Unknown.') \n",
      "\n",
      "node[\"answer\"] ('128.', -0.05677182762944357, 'The fiction magazine in which Robert E. Howard wrote in 1930s is Weird Tales. Typically, Weird Tales had 128 pages. So the answer is: 128.') \n",
      "\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from question_answering import *\n",
    "from tqdm import tqdm\n",
    "from parallel import parallel_process_data\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "key_pool = os.getenv('TOGETHER_API_KEY').split(',')\n",
    "\n",
    "PROC_NUM = len(key_pool)\n",
    "cnt = 0\n",
    "\n",
    "def solve(tree):\n",
    "    global cnt\n",
    "    cnt += 1\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(cnt)\n",
    "    #print(tree[-1])\n",
    "    try:\n",
    "        for node in tree:\n",
    "            print(\"node\", node)\n",
    "\n",
    "            question = node[\"question_text\"].strip()\n",
    "            ref_tokens = re.findall(r\"<\\d+>\", question)\n",
    "            topic_entities = []\n",
    "            print(\"question, ref_tokens\", question, ref_tokens)\n",
    "            # return\n",
    "            for ref_token in ref_tokens:\n",
    "                if \"fa\" in node and int(ref_token[1:-1]) <= len(tree[node[\"fa\"]][\"sons\"]):\n",
    "                    ref_idx = tree[node[\"fa\"]][\"sons\"][int(ref_token[1:-1])-1]\n",
    "                    print(\"ref_idx\", ref_idx)\n",
    "                    if \"answer\" in tree[ref_idx]:\n",
    "                        question = question.replace(ref_token, tree[ref_idx][\"answer\"][0])\n",
    "                        topic_entities.append(tree[ref_idx][\"answer\"][0])\n",
    "            node[\"question\"] = question\n",
    "            node[\"cb_answer\"] = get_cb_answer(question)\n",
    "            print('node[\"cb_answer\"]', node[\"cb_answer\"], \"\\n\")\n",
    "            if len(node[\"sons\"]) == 0:\n",
    "                node[\"ob_answer\"] = get_singlehop_ob_answer(question, topic_entities)\n",
    "                print('node[\"ob_answer\"]', node[\"ob_answer\"], \"\\n\")\n",
    "                #print(node[\"ob_answer\"])\n",
    "                node[\"answer\"] = aggregate_singlehop_answer(node[\"cb_answer\"], node[\"ob_answer\"])\n",
    "                print('node[\"answer\"]', node[\"answer\"], \"\\n\")\n",
    "            else:\n",
    "                node[\"ob_answer\"] = get_multihop_ob_answer(node, tree)\n",
    "                print('node[\"ob_answer\"]', node[\"ob_answer\"], \"\\n\")\n",
    "                #print(node[\"ob_answer\"])\n",
    "                node[\"child_answer\"], node[\"answer\"] = aggregate_multihop_answer(node, tree)\n",
    "                print('node[\"child_answer\"]', node[\"child_answer\"], \"\\n\")\n",
    "                print('node[\"answer\"]', node[\"answer\"], \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"ERROR CASE\", e)\n",
    "        print(tree[-1])\n",
    "        raise e\n",
    "\n",
    "\n",
    "trees = json.load(open(\"trees.json\", \"r\"))\n",
    "print(\"Total: %d | Start Processing...\"%len(trees))\n",
    "parallel_process_data(trees, solve, PROC_NUM)\n",
    "\n",
    "\n",
    "print(\"END\")\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "json.dump(trees, open(\"results/test.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR CASE \"What is the nationality of the foreign born victim of Singapore's caning punishment before Oliver Fricker experienced the same?\"\n",
      "ERROR CASE 'Dorian Gray is the main character of what philosophical novel whose editor feared the story was indecent, and deleted roughly five hundred words before publication?'\n",
      "ERROR CASE 'Who wrote the 1970 international hit song Murray Head is most recognized for?'\n",
      "ERROR CASE 'Where was the match held where Chicharito scored goals along with Antonio Valencia and Dimitar Berbatov?'\n",
      "ERROR CASE 'Where was Nexon who was composed by Adam Gubman located at?'\n",
      "ERROR CASE 'What event in 1920 was established by the director of the play \"The Miracle?\"'\n",
      "ERROR CASE 'This annual event held in several major cities in Finland is one of many all-night arts festival whose name is given to areas of high latitude in the weeks around what?'\n",
      "ERROR CASE \"Chun Woo-hee's notable films include a South Korean horror film about  a policeman who investigates a series of mysterious killings and what?\"\n",
      "ERROR CASE 'What team had Tony Roberts replaced by an American sportscaster from Buffalo, New York when he retired?'\n",
      "ERROR CASE 'Are Catasetum and Origanum in the same family?'\n",
      "ERROR CASE 'Cooperative Living Organization is located in a city that is the county seat of what county in Florida?'\n",
      "ERROR CASE 'The 2015 Austrian thriller film Jack tells the story of a serial killer who died in what year?'\n",
      "ERROR CASE 'Which musician played in the band Soulfly, Max Cavalera or Billy Idol?'\n",
      "ERROR CASE 'A guitar player called Noodles is a longtime member of which band, The Smashing Pumpkins or The Offspring?'\n",
      "ERROR CASE 'Which airport is located further north in the United States, San Angelo Regional Airport or Grand Junction Regional Airport?'\n",
      "ERROR CASE 'The 1978 NBA World Championship Series had as MVP which Hall of Fame class member of 1988?'\n",
      "ERROR CASE 'What is the name of the actress who has received a Drama Desk award and was part of the cast album for the 2007 Broadway production of the hit musical, \"Grease\"?'\n",
      "ERROR CASE 'Are Steve Perry and Leslie West both singers?'\n",
      "ERROR CASE 'What pop band features an Argentine actress that appeared in the television series \"Chiquititas\"?'\n",
      "ERROR CASE 'In what city did the 1959 William & Mary Indians football team lose against the #13 Naval Academy?'\n",
      "ERROR CASE 'Which star in the Maltese Bippy died in 1987?'\n",
      "ERROR CASE 'The 2005 film Remedy featured Frank Vincent from The Sopranos and several mob movies by which acclaimed director?'\n",
      "ERROR CASE 'What is the city in which Bauerfield International Ariport is based out of?'\n",
      "ERROR CASE 'What is the name of the movie that stars Katrina Bowden and was directed by Sean Anders?'\n",
      "ERROR CASE 'A man who played in the 1986 FIFA world cup played for what team during the 1982 Scottish League Cup Final?'\n",
      "ERROR CASE 'Based on a True Story... is an album by which country music star, with the single My Eyes?'\n",
      "ERROR CASE 'Little Brown Stein is a rivalry trophy that imitates a mug made out of what item?'\n",
      "ERROR CASE 'What was the island, on which Marinelli Glacier is located, formerly known as?'\n",
      "ERROR CASE 'In what county was Duffy Jackson born?'\n",
      "ERROR CASE 'What sort of dog did the same man who cared for the living gift that Martin Bormann gave Hitler have?'\n",
      "ERROR CASE 'How large of the area is the nature reserve south of Seacroft Esplanade?'\n",
      "ERROR CASE 'Viking: The Ultimate Obstacle Course was a game show that aired in Europe with the British presenter who was an Olympic participant in what sport?'\n",
      "ERROR CASE 'Chimaja Appawas the younger brother of a general of the Maratha Empire in India, who served as what to the fifth Maratha Chhatrapati Shahu from 1720 until his death?'\n",
      "ERROR CASE 'When will Flicker, created by a member of One Direction, be released?'\n",
      "ERROR CASE 'Who was born first, Kwok Kin Pong or Edison Chen?'\n",
      "ERROR CASE 'Luke Rockhold defeated the MMA fighter who was the first to earn a win against which champion in the UFC?'\n",
      "ERROR CASE \"Which genus's family comes first alphabetically, Crepis or Isatis?\"\n",
      "ERROR CASE 'What country does Haringey Heartlands and The Mall Wood Green have in common?'\n",
      "ERROR CASE 'C. Bernard Jackson founded the center that started the career of which actor, who played the part of Marty Castillo in \"Miami Vice\"?'\n",
      "ERROR CASE 'The McKinley Tariff was framed by the representative who was later assassinated in what month?'\n",
      "ERROR CASE 'Stephen susco wrote a movie produced by which american film actor?'\n",
      "ERROR CASE 'How many member universities are there in this conference of which the Connecticut Huskies baseball team is a competing member?'\n",
      "ERROR CASE 'Who starred in My Dog Skip and Malcolm in the Middle?'\n",
      "ERROR CASE 'In the 1962 German Grand Prix, a racer came second. What did this racer found?'\n",
      "ERROR CASE 'Chandgi Ram won a gold medal in 1970 in a continental multi-sport event held at which city ?'\n",
      "ERROR CASE \"Which film was released first, Home on the Range or Pete's Dragon?\"\n",
      "ERROR CASE 'Who was born first, Umar Israilov or Ramzan Kadyrov?'\n",
      "ERROR CASE 'Did Lewis Allen or Danny DeVito play Louie De Palma?'\n",
      "ERROR CASE 'Emily Beecham is best known for her role in a televsion series whose second season premiered on what date?'\n",
      "ERROR CASE 'How long did The Shire of Flinders, which encompassed the extremity of the Mornington Peninsula located south-east of Melbourne, Australia, exist?'\n",
      "ERROR CASE 'What county in Minnesota holds a 202 lb slab of greywacke covered in runes?'\n",
      "ERROR CASE 'What was the capital of India when the Taj Mahal was commissioned?'\n",
      "ERROR CASE 'Forest Hill, Texas is a suburb of which fifth-largest city in the state?'\n",
      "ERROR CASE 'At what school is the individual who was awarded the 2012 Nobel Prize in Physics, jointly with David J. Wineland, a professor?'\n",
      "ERROR CASE 'Which genus has the most number of species, Myrsine or Styrax?'\n",
      "ERROR CASE \"How much was Ammon Bundy's son ordered to pay in grazing fees?\"\n",
      "ERROR CASE 'How many films were directed by the director of Wise Blood?'\n",
      "ERROR CASE 'Rock Springs is a collection of short stories by an author born in what year?'\n",
      "ERROR CASE 'Which tennis player is older out of John Peers and Simone Bolelli?'\n",
      "ERROR CASE 'Who was the chief executive officer of the second largest US car rental company by sales?'\n",
      "ERROR CASE 'Don Holmes played for the football club that is based in what eastern suburb of Perth?'\n",
      "ERROR CASE 'In what country did Gildo Siopaes win a bronze medal for bobsledding in the 1964 Winter Olympics?'\n",
      "ERROR CASE 'Who was the narrator of the 26-episode series which featured the British national museum organization with branches at five locations in England?'\n",
      "ERROR CASE '\"Lost!\" is a song by a British rock band formed in what year?'\n",
      "ERROR CASE 'Which sport has been played at the BayArena in Leverkusen, Germany, since 1958?'\n",
      "ERROR CASE 'What member of the South Korean-Chinese boy group EXO stars in the upcoming movie \"The Underdog\"?'\n",
      "ERROR CASE 'Was Pocahontas made before Born in China?'\n",
      "ERROR CASE 'The Simpsons episode that aired on February 19, 2012 entitled \"At Long Last Leave\" represented what milestone for the show?'\n",
      "ERROR CASE 'Where is the American Hockey League, that Dan Frawley played in, located?'\n",
      "ERROR CASE 'what type of media does Ratatouille and PlayStation 3 have in common?'\n",
      "ERROR CASE 'What number installment of the Ghost School and Ghost School Horror was the film Voice?'\n",
      "ERROR CASE 'This team which is moving from Oakland, California to Las Vegas Nevada with share its stadium with what college?'\n",
      "ERROR CASE 'Are both Forman Christian College and Purbanchal University public schools?'\n",
      "ERROR CASE 'When was the  Argentine former footballer which  Dutch manager Ronald Koeman replaced in  2014–15 Southampton F.C. season born'\n",
      "ERROR CASE 'Were Paul Éluard and Georges Bataille from the same country?'\n",
      "ERROR CASE 'Which comic series involves characters such as Nick Fury and Baron von Strucker?'\n",
      "ERROR CASE 'Which is bigger, Griffon Bruxellois or English Mastiff?'\n",
      "ERROR CASE 'Did both  Slaughter-House Cases and United States v. Darby Lumber Co. involve civil rights law?'\n",
      "ERROR CASE 'Firstar Center was the name for two buildings before the company changed its name to match which company based in Minneapolis?'\n",
      "ERROR CASE 'Which current CBS NBA analyst played for the PORTLAND TRAILBLazers along with former UNLV teammate Stacey Augmon?'\n",
      "ERROR CASE 'What was the company that was co-owned by the person who Abbe error was named after?'\n",
      "ERROR CASE 'Are Toshi and Warrel Dane both in the band Sanctuary?'\n",
      "ERROR CASE 'what air force based named in honor of Carl Benjamin \"Ben\" Eielson is located 26 miles southeast of Fairbanks, Alaska?'\n",
      "ERROR CASE 'The 1996 film \"The Christmas Tree\" stars Andrew McCarthy and an actress that has won how any Emmy Awards?'\n",
      "ERROR CASE 'Why is Minister Pool important to Black Country and the West Midlands in England?'\n",
      "ERROR CASE \"What other country does the league that Taylor Eric Kemp played in represents the sport's highest level besides the United States?\"\n",
      "ERROR CASE \"Which American rock band, Sugar Ray or Against the Current gained mainstream fame in the 1990's?\"\n",
      "ERROR CASE 'This Fox News Specialist Host also took over what Fox Business Channel news program in 2013?'\n",
      "ERROR CASE 'Was Atom Egoyans biggest commercial success on stage or on film?'\n",
      "ERROR CASE 'What year did the movement that Tess Asplund protested in the viral image of her with her fist in the air disband?'\n",
      "ERROR CASE 'Are Macheng and Lianjiang, Guangdong both cities ?'\n",
      "ERROR CASE 'What term is the current chairman of Prince William County serving?'\n",
      "ERROR CASE 'what country are Mudvayne and Hellyeah both from?'\n",
      "ERROR CASE 'Who was born first, Antonin Artaud or  Elizabeth Taylor?'\n",
      "ERROR CASE 'Which movie is loosley based off the Brother Grimm\\'s \"Iron Henry\"?'\n",
      "ERROR CASE 'Which beverage is ignited prior to consumption, Flaming beverage or Blue Hawaii'\n",
      "ERROR CASE 'Toby Scott worked with which American singer born on May 24, 1941?'\n",
      "ERROR CASE 'Orson Scott Card first published his short story \"Killing Children\" in this American science-fiction magazine whose first issue was published when?'\n",
      "ERROR CASE 'Church of All Saints, Doddinghurst is part of the state church led by which person?'\n",
      "ERROR CASE 'What ingredient is in both Cosmopolitan and Cuba Libre?'\n",
      "ERROR CASE \"The winner of the the London Riders' Championship in 1953 scored how many points in the 1952 Individual Speedway World Championship?\"\n",
      "ERROR CASE 'Typically how many pages were in the fiction magazine in which Robert E. Howard wrote in 1930s?'\n",
      "ERROR CASE 'In 2009 the OCA announced major changes to it event lists, and in what city did this multi-sport event take place?'\n",
      "ERROR CASE 'This high school located in the Bronzeville neighborhood was named after a settler who was arrested by who?'\n",
      "ERROR CASE 'Are Florida Atlantic University and Cleveland State University both colleges in the US?'\n",
      "ERROR CASE 'In what year did the Danish plant ecologist who assisted a Danish chemist, famous for the introduction of the concept of pH die?'\n",
      "ERROR CASE 'The Prodigal Daughter, though a book about an American, is by a novelist of what nationality?'\n",
      "ERROR CASE 'Dulce Maria García Rivas took part in a \"Mask vs. Hair\" match with which female wrestler at Guerra de Titanes?'\n",
      "ERROR CASE 'Were both Tom Gullikson and Jürgen Melzer professional Austrian tennis players?'\n",
      "ERROR CASE 'What was the nationality of the author of \"The Sunlight on the Garden\"?'\n",
      "ERROR CASE 'The Secret of Moonacre was directed by the founder of which animation studio?'\n",
      "ERROR CASE 'What is the familial relationship of the founder of the Gulf Cartel to Juan García Ábrego?'\n",
      "ERROR CASE 'Who was born first Burton Cummings or Sharleen Spiteri?'\n",
      "ERROR CASE 'Which was published first Polarity or The Farming Game?'\n",
      "ERROR CASE 'Season of Migration to the North  is a counter narrative to a novella by what Polish-British novelist?'\n",
      "ERROR CASE 'What legend that lends its name to a modern medical term, inspired the plot of the horror film Ghostkeeper?'\n",
      "ERROR CASE 'H-63 is a highway that runs near the county seat of what Michigan county?'\n",
      "ERROR CASE 'Timothy J. Sloan was the CEO of Wells Fargo who succeeded the CEO who took the job in what month?'\n",
      "ERROR CASE 'Which  American politician and lawyer contested in San Francisco mayoral election, 2003'\n",
      "ERROR CASE 'The Pluralist school is said to have included what creator of the theory of atomism?'\n",
      "ERROR CASE 'Who was the running mate of the man about whose candidacy the 2016 book Insane Clown President: Dispatches from the 2016 Circus documents?'\n",
      "ERROR CASE 'which plant has the highest specie  Panicum or Populus'\n",
      "ERROR CASE 'Gene Sculatti write for CREEM sometime in the 60s or 70s, what famous term did CREEM coin for describing a genre of rock?'\n",
      "ERROR CASE 'When did the predecessor of The Eyes of Nye first air?'\n",
      "ERROR CASE 'When was the movie adaption of Jennifer Weiner\\'s novel \"In Her Shoes\" released?'\n",
      "ERROR CASE 'The 1994 \"The Shadow\" co-stars Lone, Penelope Ann Miller, Peter Boyle, Jonathan Winters, Tim Curry and an actor that has received how many Emmy Award nominations?'\n",
      "ERROR CASE 'What date in 2010 was a South Korean film starring  Kim Hyang-gi released?'\n",
      "ERROR CASE 'Force India VJM10 is a Formula One racing car previous driven by Nico Hülkenberg, and is now driven by which driver born 17 September 1996?'\n",
      "ERROR CASE '\"The Chance of a Lunchtime\" is an episode of a BBC sitcom writtem by who?'\n",
      "ERROR CASE \"Which region of Austria means 'Estate of the Salt Chamber' and covers the village of Obertraun, a popular destination for skiing and snowboarding in the winter?\"\n",
      "ERROR CASE 'Lucas da Silva Carvalho was an unused reserve runner for a Brazilian athletics track event which at top class events is run in lanes for the first what?'\n",
      "ERROR CASE 'Seal Harris was born in what county?'\n",
      "ERROR CASE 'Lawerence Turman had produced a film, with a character named \"Johnny 5\" that had a follow up sequel released in what year?'\n",
      "ERROR CASE 'After partially sinking in 1994, Celestyal Crystal was rebuilt for the purpose of what Bermudian company?'\n",
      "ERROR CASE 'Which former lead guitarist has a solo album named two disc compilation album?'\n",
      "ERROR CASE 'Who was born first, Brooklyn Decker or Andy Roddick?'\n",
      "ERROR CASE 'Football at the 2006 Asian Games with Wisoon Wichaya as its coach was played how many days prior to the opening ceromony in Doha, Qatar in 2006?'\n",
      "ERROR CASE 'Charlotte Hatherley initially came to prominence in a band formed in what year?'\n",
      "ERROR CASE 'What song was number 4 on the charts when a song from FutureSex/LoveSounds was number 1?'\n",
      "ERROR CASE 'Howard Van Doren Shaw was the designer of which 1917 Progressive Era community?'\n",
      "ERROR CASE 'This man who was born on April 25th, 1947, was a member of this lower house of the Hawaii State Legislature.'\n",
      "ERROR CASE 'What United Kingdom Prime Minister was succeeded in the 1990s by the Leader of the Conservative Party?'\n",
      "ERROR CASE 'Andrei Ivanovich Gorchakov commanded the 1st Infanty Corps in what major engagement of the Napoleonic Wars?'\n",
      "ERROR CASE 'Which comic book was also written by the writer of Crossed?'\n",
      "ERROR CASE 'The father of Manning Marius Kimmel retired from the Navy in what year?'\n",
      "ERROR CASE 'What occupation do Henry Moore and John Wesley have in common?'\n",
      "ERROR CASE 'What was the 2010 population of the town where Lake George Avenue Historic District is located?'\n",
      "ERROR CASE 'Of these two publication--Báiki and Sick--what type of publication is the one that was published most frequently?'\n",
      "ERROR CASE 'The 2000 ICC KnockOut Trophy was the debut of a Jamaican cricketer who is a right-handed what?'\n",
      "ERROR CASE 'Which novelist was German, David Guterson or Thomas Mann?'\n",
      "ERROR CASE 'Which 1962 film starring Tom Courtenay is based on a short story of the same name?'\n",
      "ERROR CASE 'Which Austrian writer and journalist introduced the term \"Journaille \"'\n",
      "ERROR CASE 'What profession does Stephen Jay Gould and Ann Beattie have in common?'\n",
      "ERROR CASE \"Suicide's 1977 released album features a song based on what brand's comic character?\"\n",
      "ERROR CASE 'My Neighbor Totoro was produced by a Japanese animation film studio founded in what year?'\n",
      "ERROR CASE 'In what year did both Orson Scott Card\\'s novel \"Ender\\'s Game\" and Keri Hulme\\'s \"The Bone People\" come out?'\n",
      "ERROR CASE 'Operalia, The World Opera Competition helped launch the career of an operatic soprano of what nationality?'\n",
      "ERROR CASE 'How many members were in the South Korean boy group whose first official sub-unit is Bastarz?'\n",
      "ERROR CASE 'Which casino closed first The Atlantic Club Casino Hotel or Trump Plaza Hotel and Casino ?'\n",
      "ERROR CASE 'What group of Elektra Records recording artists are known to be an indie pop band?'\n",
      "ERROR CASE 'Is Ordos City more west than Yangzhong?'\n",
      "ERROR CASE 'Between Valparaiso University and Old Dominion University, which institution has higher student enrollment?'\n",
      "ERROR CASE 'What type of media does J. T. Petty and Outlast have in common?'\n",
      "ERROR CASE 'How many girls and boys are in the seventeen sibling family featured on Counting On?'\n",
      "ERROR CASE 'How many episodes were in the original run of the HBO show that Kristin Davis played the character Charlotte York Goldenblatt?'\n",
      "ERROR CASE 'W41AP is a station owned by the daily newspaper serving what nearby city in Erie County?'\n",
      "ERROR CASE 'What English-American actor known for his role in \"Raiders of the Lost Ark\" starred in The Lodger?'\n",
      "ERROR CASE 'What is the birth name of the woman that \"A Woman Called Moses\" is based on?'\n",
      "ERROR CASE 'What political party is the current Attorney General of Missouri associated with?'\n",
      "ERROR CASE 'Who was the first Russian composer to make a lasting impression internationally, Alessandro Scarlatti or Pyotr Ilyich Tchaikovsky?'\n",
      "ERROR CASE 'What do a Flaming beverage and a Gin and tonic have in common?'\n",
      "ERROR CASE 'Which feature does the G-shock watch have that is tested by a leakage test?'\n",
      "ERROR CASE 'The man who currently serves as the wide receivers coach for the Dallas Cowboys used to coach at what college?'\n",
      "ERROR CASE 'What Canadian filmmaker created a film about Bettie Page in 2005?'\n",
      "ERROR CASE 'Kent Dairy Round Barn is near the city in what Montana county?'\n",
      "ERROR CASE 'Which Croatian professional basketball player (a shooting guard) did New Jersey Nets acquire during their 1990–91 season?'\n",
      "ERROR CASE 'What movie was released at a later date, My Dog Tulip or Monsters vs. Aliens?'\n",
      "ERROR CASE 'An Austrian-British psychoanalyst born in 1882 and innovative in object relations theory was also rigorous about what other type of therapy?'\n",
      "ERROR CASE \"Who is the controlling shareholder of the world's fourth-largest tyre manufacturer?\"\n",
      "ERROR CASE 'What type of the district is the Downtown Bentonville of the state in the southeastern region of the United States which is home to over 3 million people as of 2017?'\n",
      "ERROR CASE 'The View from the Bottom is the fifth studio album by an American rock band best known for what hit song?'\n",
      "ERROR CASE 'Who was attempting to regain the British throne until the Raids on Lachaber and Shiramore shut down his operations?'\n",
      "ERROR CASE 'Who starred as an American attorney in Grey Gardens?'\n",
      "ERROR CASE 'Triangle Brewing Company was started by a founder who had experience as what non-commercial alcohol producer?'\n",
      "ERROR CASE 'Which magazine had more previous names, Watercolor Artist or The General?'\n",
      "ERROR CASE 'Where is the county seat for people living in Henderson Point, Mississippi?'\n",
      "ERROR CASE 'What album did John Lennon release before the one that contained the song \"How?\"'\n",
      "ERROR CASE \"In which town was the amusement park that is operated by Britannia Jinky Jersey Ltd located where the first  Tomorrow's Parties Festival was held?.\"\n",
      "ERROR CASE 'In which movie the Stephanie Kay Panabaker was alongside with her elder sister Danielle Nicole Panabaker?'\n",
      "ERROR CASE 'Robert Smith founded the multinational company headquartered in what city?'\n",
      "ERROR CASE 'What is the name of the company in Independent Hill, Virginia that is also headquartered in Houston Texas?'\n",
      "ERROR CASE 'Which characters are akin to goblins and were added to a Tilted Mill Entertainment video game in 2009?'\n",
      "ERROR CASE 'The Bachelor was based on what novel written by an Austrian author?'\n",
      "ERROR CASE 'Which industrialist established a museum in Heckscher Park that features \"First Friday\" concerts?'\n",
      "ERROR CASE 'Which film was released first, Jawbreaker or Havenhurst?'\n",
      "ERROR CASE 'Did the the Battle of Stones River occur before the Battle of Saipan?'\n",
      "ERROR CASE 'What \"God Gave Me You\" artist wrote the song \"Imagine That\" for Diamond Rio?'\n",
      "ERROR CASE 'Alex Haley wrote what novel about a man that was born in 1750?'\n",
      "ERROR CASE 'Wind was directed by which American actress born on March 26, 1960?'\n",
      "ERROR CASE 'Which writer of \"Rewrite This Story\" are an American songwriting duo and composing team for musical theater, films, and television?'\n",
      "ERROR CASE 'Which song that John Kirby scored  is often the final piece of music played during an evening of revelry?'\n",
      "ERROR CASE '\"Lesbian Request Denied\" is the third episode of the first season of a series created by who?'\n",
      "ERROR CASE \"Where was one of Sergei Prokofiev's most well-known operas first performed in 1921?\"\n",
      "ERROR CASE 'California joined the Union due to the passage of a package of how many separate bills?'\n",
      "ERROR CASE 'Which type of character is featured by the P.L. Travers\\'s third book and last novel in the \"Mary Poppins\" series?'\n",
      "ERROR CASE 'What is the name of the singer who\\'s song was released as the lead single from the album \"Confessions\", and that had popular song stuck behind for eight consecutive weeks?'\n",
      "ERROR CASE 'Who founded gaming company which owns and operates the Red Rock Resort?'\n",
      "ERROR CASE 'Do Ray Wilson and Leo have the same nationality ?'\n",
      "ERROR CASE 'The creator of \"Wallace and Gromit\" also created what animation comedy that matched animated zoo animals with a soundtrack of people talking about their homes?'\n",
      "ERROR CASE 'What type of engine powered both the Saab 36 and the Avro Vulcan?'\n",
      "ERROR CASE 'When did the author of the book One More River is based on win the Nobel Prize?'\n",
      "ERROR CASE 'Who played the role of Nettie Harris in the 1985 film directed by Steven Spielberg?'\n",
      "ERROR CASE 'The head of the Foreign Relations Department of the Rastriya Janashakti Party holds a degree that can be abbreviated MS, M.S., or ScM, in what field?'\n",
      "ERROR CASE \"Who was the artist that recorded a duet in 1985 for the CBS TV series 'Dallas' with an artist that was born in 1951 and has twenty #1 hits?\"\n",
      "ERROR CASE 'Are Freakonomics and In the Realm of the Hackers both American documentaries?'\n",
      "ERROR CASE 'What was the code name of the campaign where Joe Foss received a Medal of Honor?'\n",
      "ERROR CASE 'What German state was Karl Julius Perleb born in?'\n",
      "ERROR CASE 'Who was born first, Johan Leysen or George Clooney?'\n",
      "ERROR CASE 'Alfred Balk served as the secretary of the Committee on the Employment of Minority Groups in the News Media under which United States Vice President?'\n",
      "ERROR CASE 'Who beacme a star as a comic book character created by Gerry Conway and Bob Oksner?'\n",
      "ERROR CASE 'Who has released more solo albums, Nick Carter or Brady Seals?'\n",
      "ERROR CASE 'Both Tsai Ming-liang and Giacomo Gentilomo were involved with which profession?'\n",
      "ERROR CASE 'Of the companies that sponsor the British League Riders Championship, which is owned and operated by Goodyear Tire and Rubber Company?'\n",
      "ERROR CASE 'Connetquot High School  is a public high school in what city in New York?'\n",
      "ERROR CASE '\"The Empire Builder\"\\'s Columbia River Subdivision was part of which line?'\n",
      "ERROR CASE 'The mass killing that took place at Oakland, California on April 2, 2012 was less deadly than the one that took place on October 1, 2015 in which state?'\n",
      "ERROR CASE 'Which Canadian rock band released a song called \"Counterparts\" and had a drummer who was inducted into the Modern Drummer Hall of Fame?'\n",
      "ERROR CASE 'What profession did Willi Forst and Elmer Clifton share?'\n",
      "ERROR CASE \"What city is the women's Vans Triple Crown of Surfing event hosted at?\"\n",
      "ERROR CASE 'Lou Cutell appeared on the third episode of the ninth season of an CBS sitcom that was what number episode overall?'\n",
      "ERROR CASE \"Who was the New York City Fire Commissioner at the time of Providenza Panno's death?\"\n",
      "ERROR CASE 'What was the name of the country ran by the president who maintained the mercenary unit, White Legion?'\n",
      "ERROR CASE 'What cuisine is described as a cultural blending of Mediterranean influences (such as those created by Italian and Spanish populations)?'\n",
      "ERROR CASE 'In which year was the King who made the 1925 Birthday Honours born?'\n",
      "ERROR CASE 'What is the name of the largest shipping facility in the Northeastern United States, where the Boston Red Socks play?'\n",
      "ERROR CASE 'What American actress who died in 2011 starred in Fear Stalk?'\n",
      "ERROR CASE 'The retired American professional basketball player Walt Williams attended this institution in 1988 that is in which conference today?'\n",
      "ERROR CASE 'What is the name of a member of the North Melbourne Football Club, whose brother Rob has starred in Bridgetowns Cricket Clubs Premiership in 2016/7?'\n",
      "ERROR CASE 'which American soldier and serial killer was Death of a Soldier based on'\n",
      "ERROR CASE 'What state is home to the Lake Wobegon Trails and the recording location for the live radio show \"A Prairie Home Companion\"?'\n",
      "ERROR CASE 'Which film stars more animals, The Jungle Book or The Lone Ranger?'\n",
      "ERROR CASE 'Lucy Pevensie is a character in the series of fantasy novels that have sold more than how many copies?'\n",
      "ERROR CASE 'What is the current job of the former partner in ice skating of Vladimir Fedorov?'\n",
      "ERROR CASE 'The Nike Mercurial Vapor is endorsed by a Stoke City football player who also plays for what national team?'\n",
      "ERROR CASE 'When was Leeds no longer called Elmet?'\n",
      "ERROR CASE 'What was the name of the team that represented an Arizona university in the conference that covers a broad expanse of the western United States, including Arizona, California, and New Mexico?'\n",
      "ERROR CASE 'With whom was a notable partner of Elena Krykanova a two-time Olympic champion with?'\n",
      "ERROR CASE 'What was the address of the building on U.S. Route 3 that was the tallest building in New Hampshire when completed in 1972?'\n",
      "ERROR CASE 'Which documentary is the oldest, The Private Life of Plants or Marx Reloaded?'\n",
      "ERROR CASE 'What is the title of the 1979 film adaptation of William Shakespeare\\'s play in which the English poet, actor, political activist and dramatist who wrote wrote a number of book-length polemical poems such as \"Autogeddon\", \"Falling for a Dolphin\" and \"Whale Nation\" played a main character?'\n",
      "ERROR CASE 'Dance and Laugh Amongst the Rotten is a studio Album by a band from which country ?'\n",
      "ERROR CASE 'Tommy Swerdlow co-wrote the screenplay of what film directed by Jon Turteltaub?'\n",
      "ERROR CASE 'Who died more recently, Ferdinand Anton Ernst Porsche or Ferdinand Porsche'\n",
      "ERROR CASE 'The Declaration of Montreal was the founding document of which world event, lasting from July 26-August 5, 2006?'\n",
      "ERROR CASE 'The third solo album by David Gates of Bread shares a name with a 1977 film directed by who?'\n",
      "ERROR CASE 'What third film in a franchise did Camile Delamarre edit?'\n",
      "ERROR CASE 'Yau Ma Tei North is a district of a city with how many citizens?'\n",
      "ERROR CASE 'How many episodes were made for the science fiction series with Gus Birney?'\n",
      "ERROR CASE 'What is the name of the daughter of the Irish entertainer in the girl band Maxi, Dick and Twink?'\n",
      "ERROR CASE 'What car did the German rally driver, who won victories for Fiat, Opel, Lancia, and Audi drive?'\n",
      "ERROR CASE 'Sian Gibson co-wrote which British sitcom, set around a supermarket and car share scheme?'\n",
      "ERROR CASE \"Fiske O'Hara was born in what city Knox County, Maine, that had a population of 2,297 as of the 2010 census?\"\n",
      "ERROR CASE 'When was the British economic historian who established \"The Economic History Review\" born?'\n",
      "ERROR CASE 'Which breed, Chinese Chongqing Dog or Kanni, is used for hunting?'\n",
      "ERROR CASE 'H Pistorius & Co is part of the reason for the wealth of the family that includes which South African sprinter?'\n",
      "ERROR CASE 'Which city in Missouri is the Route 66 State Park closest to travel from, St.Louis or Eureka?'\n",
      "ERROR CASE 'Bill Bryson grew up in a city that is the seat of which county ?'\n",
      "ERROR CASE 'James Conlon directed the oldest outdoor Music Festival that is located and what state?'\n",
      "ERROR CASE \"Which countries forces fought in The Battle of Hürtgen Forest which was covered in the shooter video game Darkest Hour: Europe '44-'45?\"\n",
      "ERROR CASE 'How many beer brands are in the portfolio of the company that hired Leonardus (Leo) Petrus Beukeboom to decorate cafes?'\n",
      "ERROR CASE 'What group of languages is the surname Gref, meaning \"Grave,\" taken from?'\n",
      "ERROR CASE 'Nguyễn Văn Trỗi tried to assassinate a future ambassador from which US state ?'\n",
      "ERROR CASE 'When was the duo formed who\\'s English language song is the \"Freaky Like Me\"?'\n",
      "ERROR CASE 'Who owns the broadcasting platform where Games Done Quick is broadcast?'\n",
      "ERROR CASE 'The star of \"The Inkwell\" also starred in what 1993 movie as O-Dog?'\n",
      "ERROR CASE 'Who composed music for this 1941 American animated film with the main character of Jumbo Jr.?'\n",
      "ERROR CASE 'Robert Earl Holding owned an oil company that was originally founded by who?'\n",
      "ERROR CASE 'Northland Mall was the first directionally-named shopping center in Columbus, 5 years before which shopping center at the intersection of US-40 and I-270?'\n",
      "ERROR CASE 'WFMT FM radio transmits from the second tallest building in the United States, which is located where?'\n",
      "ERROR CASE 'Where is the  city and \"comune\" in Emilia-Romagna in which talian Renaissance painter ;Ludovico Mazzolino located'\n",
      "ERROR CASE 'Is Bob Hewitt a citizen of a different country than Ray Ruffels?'\n",
      "ERROR CASE 'In the Library with the Lead Pipe, an academic journal on topics about libraries, is abstracted and indexed by this third largest private company in Birmingham, Alabama?'\n",
      "ERROR CASE 'Where will the student which pass the exam  for which Le Rêve de Rico has to pass progress to?'\n",
      "ERROR CASE 'Are both Yixing and Shaoshan county-level cities in China?'\n",
      "ERROR CASE 'Are Buried Country and South of the Border both films turned into stage performances?'\n",
      "ERROR CASE 'Which university is further North,  University of New Hampshire or Stony Brook University?'\n",
      "ERROR CASE 'When did an IndyCar race driver drive a Formula 1 car designed by Peter McCool?'\n",
      "ERROR CASE 'Cagliostro-Walzer op.370 was composed by a man born in what year?'\n",
      "ERROR CASE 'Which movie was filmed first \"The Guest\" or \"You\\'re Next\"?'\n",
      "ERROR CASE 'Which shore does the castle, which Sir James Montgomery, 4th Baronet is the tenth laird of, stand?'\n",
      "ERROR CASE \"Who was the great grandfather of Franklin Seaver Pratt's wife?\"\n",
      "ERROR CASE 'Which director was also a writer, Noel M. Smith or Reza Parsa?'\n",
      "ERROR CASE 'Who gave the mother of Alberic II of Spoleto the title \"patricia\" of Rome?'\n",
      "ERROR CASE 'What did an English former footballer purchase in march 2009?'\n",
      "ERROR CASE 'Ross Pople worked with this French dominant figure of the post-war classical music world.'\n",
      "ERROR CASE 'What line featured characters from a DC Comic creator by Bob Kane and Bill Finger?'\n",
      "ERROR CASE 'Why is Serena Williams more accomplished than Mariaan de Swardt in her tennis career?'\n",
      "ERROR CASE 'Who was the eldest brother of the Mexican drug trafficker born 12 March 1952?'\n",
      "ERROR CASE 'Which US Supreme court case involved a waiver of right to counsel Planned Parenthood v. Casey or Montejo v. Louisiana?'\n",
      "ERROR CASE 'Jennifer Jones captained the gold medalists for Canada at the Sochi Winter Olympics in which event?'\n",
      "ERROR CASE 'Who directed the film in which Catherine Ann \"Kate\" Bosworth made her debut?'\n",
      "ERROR CASE 'In which year did Baek Bong-ki appear in the South Korean drama film set in a high school?'\n",
      "ERROR CASE 'Where was the company, of which David DeVoe is Chief Financial Officer, ranked in the world, in 2014, in terms of revenue, against similar types of company ?'\n",
      "ERROR CASE 'What profession does H. L. Mencken and Albert Camus have in common?'\n",
      "ERROR CASE 'This work of literature _______ , known by its Greek title Oedipus Tyrannus was argued by Sigmund Freud to be one of the greatest works of world literature in his 1928 article.'\n",
      "ERROR CASE 'What year did the CEO of Tata Consultancy Services takeover as Chairman?'\n",
      "ERROR CASE 'What plant has about 40 species native to Asia, Manglietia or Abronia?'\n",
      "ERROR CASE 'Substorm was described in qualitative terms by a scientist nominated for what seven times?'\n",
      "ERROR CASE 'Which Australian city founded in 1838 contains a boarding school opened by a Prime Minister of Australia and named after a school in London of the same name.'\n",
      "ERROR CASE 'Van Andel Institute was founded in part by what American businessman, who was best known as co-founder of the Amway Corporation?'\n",
      "ERROR CASE 'Which Air Force member was behind enemy lines for 11 1/2 days and had the largest,longest and most complex rescue mission?'\n",
      "ERROR CASE \"Yakuza Kiwami is a remake of the first video game in what video game series that is an open world action-adventure beat 'em up video game franchise?\"\n",
      "ERROR CASE 'The scunthorpe telegraph and the Grimsby Telegraph used to service Scunthorpe which is in what country?'\n",
      "ERROR CASE 'John Constantine Williams, Sr was cofounder of a Florida city located in what county?'\n",
      "ERROR CASE 'Which actor in The Lieutenant Wears Skirts is named Samuel?'\n",
      "ERROR CASE 'When was the magazine Sam Duckworth got his name Get Cape. Wear Cape. Fly from launched?'\n",
      "ERROR CASE 'What color clothing do people of the Netherlands wear during Oranjegekte or to celebrate the national holiday Koningsdag?'\n",
      "ERROR CASE 'What type of building does Jim Bartels and ʻIolani Palace have in common?'\n",
      "ERROR CASE 'Were both Life magazine and Strictly Slots magazine published monthly in 1998?'\n",
      "ERROR CASE 'What is the focus of the movie in which Nolan North played the role of Superboy?'\n",
      "ERROR CASE 'Sony/Philips Digital Interface Format can transmit over what Toshiba optical fiber connector system?'\n",
      "ERROR CASE 'The brewing company known for making Genny Light, a beer with only 100 calories per 12 ounce portion, and located along the Genesee River, was formerly known by what brewery name?'\n",
      "ERROR CASE 'In which city is the parent company of Sterlite Industries headquartered?'\n",
      "ERROR CASE 'Edwyn Collins and Ian Gillan both have which profession in common?'\n",
      "ERROR CASE 'Which Outer Banks landmark and premiere BBQ restaurant has been featured in the magazine Southern Living?'\n",
      "ERROR CASE 'Who portrays Rachel Zane on the American legal comedy-drama that airs on USA Network?'\n",
      "ERROR CASE 'Ellie Parker is a 2005 American drama-comedy film whose title character is played by an English actress who made her screen debut in what Australian drama film?'\n",
      "ERROR CASE 'Between Parsifal and Saul og David which opera has more acts?'\n",
      "ERROR CASE 'A Talk is an EP by which South Korean singer and dancer?'\n",
      "ERROR CASE 'What is the name of the American author, songwriter, educator, lawyer, diplomat, civil rights activist and husband to Grace Nail Johnson who was the first African American executive secretary of the National Association for the Advancement of Colored People (NAACP)?'\n",
      "ERROR CASE 'Which is the Oil Capital of China, Chaoyang District, Shantou, or Daqing?'\n",
      "ERROR CASE 'Over what time period was the motion picture studio which produced Marvel One-Shots known as \"Marvel Films\"?'\n",
      "ERROR CASE 'What Nickelodeon movie stars the actress and YouTuber who appeared alongside Jon Voight in the 2016 film American Wrestler:The Wizard?'\n",
      "ERROR CASE 'At which level of French football does the football team named after the manager of France national team play?'\n",
      "ERROR CASE 'Kristine Moore Gebbie is a professor at a university founded in what year?'\n",
      "ERROR CASE 'A vehicle that uses hydrogen as its onboard fuel for motive power is cosidered which, Flex-fuel or Bi-fuel?'\n",
      "ERROR CASE 'The Ronkonkama railroad station and the town of Islip, New York are near?'\n",
      "ERROR CASE 'What career led Brandon James Routh to move to the city where Brian Ralston lives?'\n",
      "ERROR CASE \"Which of Damon Stoudamire's cousins once played college basketball for the University of Kentucky?\"\n",
      "ERROR CASE 'Where was the founder of the Trussed Concrete Steel Company raised?'\n",
      "ERROR CASE 'Which star of Zork was also the voice of Pac-Man?'\n",
      "ERROR CASE 'What country of origin does Jerry Barrett and Florence Nightingale have in common?'\n",
      "ERROR CASE 'Which composer, who was a crucial figure in the transition between the Classical and Romantic eras in Western art music, wrote Piano Sonata No. 16 ?'\n",
      "ERROR CASE 'Which dog breed has more derivative breeds from the original, German Spitz or Norfolk Spaniel?'\n",
      "ERROR CASE 'Who created the NBC sitcom that Johnny Pemberton appears in as the character Bo Thompson?'\n",
      "ERROR CASE 'Which band My Darkest Days or Human Drama had only one constant member?'\n",
      "ERROR CASE 'Which Kentucky Writers Hall of Fame author has had works published by Dim Gray Bar Press?'\n",
      "ERROR CASE 'Which  Australian singer-songwriter wrote  Cold Hard Bitch'\n",
      "ERROR CASE 'What singer who sang in church during her childhood did Stacy Barthe pen album tracks for?'\n",
      "ERROR CASE 'What band formed in 1995 and came out with an album called \"Welcome Interstate Managers\\'?'\n",
      "ERROR CASE 'Sinch when has the rank held by Sir Charles Comyn Egertong been the highest in the British Army?'\n",
      "ERROR CASE 'Hamilton Evans \"Tony\" James is the COO and director of the largest alternative investment firm in what?'\n",
      "ERROR CASE 'Which space mission did the man, in which the Onizuka Prop Wash Award is named after, perish?'\n",
      "ERROR CASE 'The pilot and author of Highest Duty: My Search for What Really Matters was hired by which news station in 2011?'\n",
      "ERROR CASE 'the first woman to be the chef de mission of an Australian Olympic team won gold medal in which winter Olympics ?'\n",
      "ERROR CASE 'What award did the actor in Tales from the Crypt win?'\n",
      "ERROR CASE 'What russian Marxist revolutionary born in 1875 was part of the Vpered organization?'\n",
      "ERROR CASE 'Are Villa Paletti and Betrayal at House on the Hill both board games?'\n",
      "ERROR CASE 'Which client of Lindka Cierach played Queen Elizabeth II in \"The Queen\"?'\n",
      "ERROR CASE 'Back Up n da Chevy was an album by the rap group from what city?'\n",
      "ERROR CASE 'Who was born first, Susan Oliver or W. S. Van Dyke?'\n",
      "ERROR CASE 'Were Enrique Carreras and Lionel Ngakane both filmakers during the 20th century?'\n",
      "ERROR CASE 'Who has a wider scope of profession, Hrag Vartanian or Hovsep Pushman?'\n",
      "ERROR CASE 'Were Halldór Laxness and Timothy Leary from the same country?'\n",
      "ERROR CASE 'What netflix series, produced by Joe Swanberg, had an actress  best known for her role as Vanessa on \"Atlanta\"?'\n",
      "ERROR CASE 'Brad Budde played professionally for a team in the NFL that was founded in 1960 as the Dallas Texans by who?'\n",
      "ERROR CASE 'Were Daniel Mann and Todd Solondz both directors?'\n",
      "ERROR CASE 'What was the arena, in which the 2017 Brit Awards were held, called during the 2012 Olympics ?'\n",
      "ERROR CASE 'Were Chad Gray and Dickie Peterson both singers?'\n",
      "ERROR CASE 'Which of the steering committee was an American broadcast journalist, best known as anchorman for the \"CBS Evening News\" for 19 years?'\n",
      "ERROR CASE 'When did the 2005 Ladbrokes.com World Darts Championship begin?'\n",
      "ERROR CASE 'In which county does the United States Navy air base located in which  Attack Squadron 174 (VA-174) was based on?'\n",
      "ERROR CASE 'In recent decades American schools have included much more on ncient times tens of thousands of years ago with the settlement of the Americas by who?'\n",
      "ERROR CASE 'Jimmy Garcia lost by unanimous decision to a professional boxer that challenged for what title in 1995?'\n",
      "ERROR CASE 'What religion was the martyr to whom the Lady of the Valey statue is dedicated?'\n",
      "ERROR CASE 'How many days did it take the Best New Artist of 2009 to sell 2 million copies of an album in the UK and break a twenty year old record?'\n",
      "ERROR CASE 'Consider the band formed in 2015 by JYP Entertainment through the reality show \"Sixteen\". How many tracks are on the reissue of their third album?'\n",
      "ERROR CASE '\"Let\\'s Get Ready to Rhumble\" is a 1994 song by a music duo from where?'\n",
      "ERROR CASE 'The founder of the Ali Akbar College of Music was known for his virtuosity in what musical instrument?'\n",
      "ERROR CASE 'The Lang Labor Party was the group that aligned with the policies of the government that followed what system?'\n",
      "ERROR CASE 'What is the shared country of ancestry between Art Laboe and Scout Tufankjian?'\n",
      "ERROR CASE 'What British made dance competition television series franchise did Claudia Albertario appear on?'\n",
      "ERROR CASE 'Are both Viken Babikian and Don Manoukian American ?'\n",
      "ERROR CASE 'The host of PokerFace is from where?'\n",
      "ERROR CASE 'The Prussian General Carl von Clausewitz is associated with what type of realism?'\n",
      "ERROR CASE 'As former head of Orange County Ironworks, what has his hit TLC show called?'\n",
      "ERROR CASE 'On which station did the 2014 South Korean television series, starring the main rapper of boyband SS501, air?'\n",
      "ERROR CASE 'when was the retired Jamaican sprinter which Richard Thompson is, 0.99 seconds slower than born ?'\n",
      "ERROR CASE 'The Shōgitai were an elite corps of which shogunate?'\n",
      "ERROR CASE 'In what century did this Native warrior and chief, whose brother Tenskwatawa led the Tippecanoe order of battle, become the primary leader of a large, multi tribal confederacy?'\n",
      "ERROR CASE 'Which band had more members, Semisonic or Cake?'\n",
      "ERROR CASE 'Which Russian professional ice hockey player, known as the Magic Man, was the final recipient of the NHL Plus-Minus Award?'\n",
      "ERROR CASE 'Which terrorist group was the cause of the battle in which Mark E. Michell won an award for his actions?'\n",
      "ERROR CASE 'What ended the career of the German composer of Bunte Blatter?'\n",
      "ERROR CASE 'The magazine that nominated George Rainsford for their Best Actor award in 2017 comes out every week on what day of the week?'\n",
      "ERROR CASE 'In what New York town did Glenn Martin Hughes attend high school?'\n",
      "ERROR CASE 'Who created and mostly wrote the show that Idris Akuna Elba played Stringer Bell in?'\n",
      "ERROR CASE 'What British novelist born in November 1898 wrote Surprised by Joy: The Shape of My Early Life?'\n",
      "ERROR CASE 'What is the population of the city in which the first edition of the South American Youth Olympic Games were held?'\n",
      "ERROR CASE 'What number president was Annie Caputo nominated by to become a member of the Nuclear Regulatory Commission?'\n",
      "ERROR CASE 'What was the job of the character Jack Nicholson played in a 1992 French-American biographical crime film directed by Danny DeVito?'\n",
      "ERROR CASE 'The Hindmarsh Stadium is sponsored by a brewery that sold how many liters of beer in 2013 ?'\n",
      "ERROR CASE 'Which was secretary to President Richard Nixon: Rose Mary Woods or H. R. Haldeman?'\n",
      "ERROR CASE \"Which  American chain of bakery-café fast casual restaurants sponsored Bill Steers Men's 4-Miler\"\n",
      "ERROR CASE 'In what year was the Sayrevill, New Jersey rock band that Frankie LaRocka played drums for formed?'\n",
      "ERROR CASE 'What is the nationality of the actor who was a leading man of Michèle Mercier and born on November 3, 1921?'\n",
      "ERROR CASE 'What is the birthdate of this Uruguayan former footballer, who management team consists of Charlie Oatway?'\n",
      "ERROR CASE 'About how many people are employed by the company founded by Denise Coates?'\n",
      "ERROR CASE 'Which team featured in both the 2012 and 2011 Cops del Rey Finals ?'\n",
      "ERROR CASE 'What is the organized crime syndicate founded and led by Carlos Alberto Rosales Mendoza who is friends with Osiel Cárdenas Guillén?'\n",
      "ERROR CASE 'The 2017–18 Wigan Athletic F.C. season will be a year in which the team competes in the league cup known as what for sponsorship reasons?'\n",
      "ERROR CASE \"Selena Quintanilla-Pérez's assistant and head of her fan club will be eligible for parole on what date?\"\n",
      "ERROR CASE 'Driven To Perform has a sponsor that includes the electronics store chain from what country?'\n",
      "ERROR CASE 'Live Wire Radio will possibly be considered as a replacement for a variety show created in what year?'\n",
      "ERROR CASE 'What year was the early consumer co-operative, in which a 2012 British biographical feature film tells the story of, formed?'\n",
      "ERROR CASE \"In which University is Richard Williams' former assistant a member of the Athletics Hall of Fame?\"\n",
      "ERROR CASE 'What is the English translation of the name of the novel series which the Four III is the final installment of?'\n",
      "ERROR CASE 'What American corporation owns Claim Jumper?'\n",
      "ERROR CASE 'Is Xingcheng or Ulan Hot located in the Inner Mongolia region of China?'\n",
      "ERROR CASE 'Spring Waltz starred the American actor who is known for what 2007 film?'\n",
      "ERROR CASE 'On what date will the comedy film directed by Kevin Tent and starring the Bulgarian-Canadian actress known for portraying the role of Mia Jones be released on video on demand services?'\n",
      "ERROR CASE 'Was Steve Sekely and Willian King Baggot known by multiple names or nicknames?'\n",
      "ERROR CASE 'Which aired first, Life After People or Werner Herzog Eats His Shoe?'\n",
      "ERROR CASE 'What professional do both Marc Bolan and Ian MacKaye share?'\n",
      "ERROR CASE 'Which bi-weekly publication ranked Schreiber Foods as number 81 in 2016.'\n",
      "ERROR CASE 'Which member of the research project conducted by the Creation Research Society and the Institute for Creation Research between 1997 and 2005 was Kevin R. Henke most critical of?'\n",
      "ERROR CASE 'What location under Charing Cross railway station did G-A-Y move to?'\n",
      "ERROR CASE 'What county is Ron Teachworth from?'\n",
      "ERROR CASE 'What actor from Northern Ireland born in 1983 starred in Whole Lotta Sole?'\n",
      "ERROR CASE 'What were the nations after 1722 that composed a culture that was extensively studied by William N. Fenton?'\n",
      "ERROR CASE 'Both Alexander Hall and Pierre Morel are involved in which profession?'\n",
      "ERROR CASE 'Piers Bizony has written articles for which magazine based in Bristol, UK?'\n",
      "ERROR CASE 'Are Ranger Rick and Tennis both sports magazines?'\n",
      "ERROR CASE 'Which satellite suburb of Melbourne is partially included in the Electoral district of Bass?'\n",
      "ERROR CASE 'Were Dee Dee Ramone and Ben Weasel ever in the same band?'\n",
      "ERROR CASE 'Who starred in the 1991 American action comedy film The Hard Way and was featured on the roster of Rawkus Records?'\n",
      "ERROR CASE \"Brad Elterman is a professional photographer who addressed the rock 'n' roll lifestyle of a band that became noted for what?\"\n",
      "ERROR CASE 'A Big Daddy is a fictional character in a series that has sold more than how many copies?'\n",
      "ERROR CASE 'J.B. Scotts located on this 11 mile stretch in Albany New York and is also known by this name in Schenectady County?'\n",
      "ERROR CASE \"Which bay in the Irish Sea is located Wales's first offshore wind farm?\"\n",
      "ERROR CASE 'Who does the minister at The First Church of Springfield help make teaching evolution illegal?'\n",
      "ERROR CASE 'The actress who played Laurie Keller in the episode \"Pilot\" of the show Cougartown won what award in 2011?'\n",
      "ERROR CASE 'Are both Yangzhou and Jiangyan District considered coastal cities?'\n",
      "ERROR CASE 'What was held in 2011 at the same stadium where the seventeenth edition of the IAAF World Championships is scheduled to be held in 2019?'\n",
      "ERROR CASE \"Where is the author of Killing Pablo: The Hunt for the World's Greatest Outlaw (2001) born?\"\n",
      "ERROR CASE 'What Cantonese slang term can mean both \"ghost man\" and to refer to Westerners?'\n",
      "ERROR CASE 'TMNT is a single-player action-adventure multi-platform action game based on a film which was the final film role for who?'\n",
      "ERROR CASE 'Which university offers more campuses in the Philippines, Fairleigh Dickinson University or the Western Institute of Technology?'\n",
      "ERROR CASE 'Michael Lent is best known as the co-writer of the memoirs of Hugh Rowland, a star on a reality television series that premiered on what date?'\n",
      "ERROR CASE 'What Happens in Vegas, an American comedy film starring Lake Bell, was released in what year?'\n",
      "ERROR CASE \"Do both Adventist World and Girls' Life have a headquarter or editor based in Maryland?\"\n",
      "ERROR CASE 'Which musician who first became famous in the late 1960s and early 1970s is Inner Secrets  the ninth studio album by'\n",
      "ERROR CASE \"Who was the head of the Imperial Family that was making an broadcast announcement of Japan's surrender in 1945?\"\n",
      "ERROR CASE 'Which Lithuanian-Canadian anthropologist, primatologist, conservationist, ethologist, and author was chosen by  Louis Leakey, along with Jane Goodall, Dian Fossey to study hominids in their natural environments?'\n",
      "ERROR CASE 'The Government Digital Service is overseen by the Chief Secretary to the Treasury, who is from which party?'\n",
      "ERROR CASE \"Which documentary was filmed first, Almost Sunrise or Hail! Hail! Rock 'n' Roll?\"\n",
      "ERROR CASE \"Which battle took place first out of the Battle of the Ch'ongch'on River and the Battle of Tarawa?\"\n",
      "ERROR CASE \"Back Home is a children's historical novel adapted into a TV drama starring what English actress born in 1946?\"\n",
      "ERROR CASE '\"I Will Not Say Goodbye\" is a song written in part by a music artist who first gained national attention as a winner of what talent competition?'\n",
      "ERROR CASE 'In between Thomas Anders and Micky Dolenz, who was the a vocalist of the Monkees?'\n",
      "ERROR CASE 'Which is a university in Pennsylvania, University of New Haven or Carnegie Mellon University?'\n",
      "ERROR CASE 'Matt Doheny lost his primary race to what current youngest woman ever elected to Congress?'\n",
      "ERROR CASE 'Which composer created Night Ferry first performed in 2012 at Symphony Center in Chicago?'\n",
      "ERROR CASE 'What are a Uruguayan professional footballer and Luz Pfannenstiel are best known as?'\n",
      "ERROR CASE 'What shallow water table aquifer is located near the county seat of Keith County, Nebraska?'\n",
      "ERROR CASE 'What award won by only twelve people has a man who Ted Kooshian has performed with won?'\n",
      "ERROR CASE 'Which legal, autonomous North American tribal government signed its constitution in Oklahoma on September 6, 1839?'\n",
      "ERROR CASE 'Who was the winner of the season of The Rap Game where a contestant named Lady Leshurr as one of her influences?'\n",
      "ERROR CASE 'What was the birth name of the start of Hwarang: The Poet Warrior Youth?'\n",
      "ERROR CASE 'The tap dancing soloist in My Feet Keep Dancing also starred in what 1935 MGM musical?'\n",
      "ERROR CASE 'What was the capacity of the stadium that Colección Privada that was filmed on October 10, 2000?'\n",
      "ERROR CASE 'What year did the musical premiere that was based on the 2007 Irish romantic musical film of the same name?'\n",
      "ERROR CASE 'The Nike Hoop Summit has had many current NBA players as former participants, including what German player from the Dallas Mavericks?'\n",
      "ERROR CASE 'What lawyers were featured in The State of Marriage, with the lawyer nominated by Governor Peter Shumlin?'\n",
      "ERROR CASE 'What building is opposite the ceremonial meeting place of the Accession Council in the United Kingdom?'\n",
      "ERROR CASE 'Gerd Neggo trained under the founder of which type of dance analysis?'\n",
      "ERROR CASE 'Do both Icehouse pieces and El Grande come from the same game?'\n",
      "ERROR CASE 'Falling Stars is a role-playing game published by the company based out of what country?'\n",
      "ERROR CASE 'What country of origin does Shawnee Trail and Great Indian Warpath have in common?'\n",
      "ERROR CASE 'When was the designer of the Disneyland attraction with variants in California, France, Hong Kong, Tokyo, and the Tomorrowland Speedway born?'\n",
      "ERROR CASE 'Why does the City of Boston get their christmas tree from Ainslee Glen Nova Scotia?'\n",
      "ERROR CASE 'Which refers to more breeds, Stabyhoun or Griffon Bruxellois?'\n",
      "ERROR CASE 'Marvel Classics Comics specialized in adaptations of literary classics, such as a novel by American writer Herman Melville, that was published in what year?'\n",
      "ERROR CASE 'In what year was the novel that Lourenço Mutarelli based \"Nina\" on based first published?'\n",
      "ERROR CASE 'Robert Jan van Pelt testified for the defense in this \"Churchill\\'s War\" author\\'s civil libel suit?'\n",
      "ERROR CASE 'Which is founded by a president, University of Washington or University of Virginia?'\n",
      "ERROR CASE 'Who co-starred in an episode of The ABC Comedy Hour with the man who played Duke Slater in \"Gomer Pyle, U.S.M.C.\"?'\n",
      "ERROR CASE 'What Nobel Laureate teaches at  Chapman University?'\n",
      "ERROR CASE 'Are Floor Jansen and John McCrea from the same band?'\n",
      "ERROR CASE 'How far from Buenos Aires is the birthplace of Ezequiel Lazaro?'\n",
      "ERROR CASE 'Many right wing WNP were  connected to a clandestine operation ran by a \"stay-behind\"  operation ran by what organization?'\n",
      "ERROR CASE '\"Ew!\" is a song by a television host born where?'\n",
      "ERROR CASE \"Snoop Dogg's Doggystyle and Snoop Dogg's Hustlaz: Diary of a Pimp are hip-hop music videos that feature what film genre?\"\n",
      "ERROR CASE 'In what city did the 23rd overall pick of the 2015 NHL Entry Draft helped the United States national junior team win a bronze medal?'\n",
      "ERROR CASE 'What movie was the actor born on May 4, 1946 involved in in 1972?'\n",
      "ERROR CASE 'Party of Syrian Unity was established in the wake of a public statement that announced what ?'\n",
      "ERROR CASE 'Bobby Arora is the trading director of a retail chain that was formed in what year?'\n",
      "ERROR CASE 'What public radio network in New York has allowed Eric Plakun to dis his psychiatric work?'\n",
      "ERROR CASE 'Ckm wz. 25 Hotchkiss was a Polish derivative of what machine gun that became the standard machine gun of the French Army during World War I?'\n",
      "1\n",
      "question The 53rd National Hockey League All-Star Game took place at the indoor arena that was completed in what year?\n",
      "question type bridge\n",
      "answer 1998.\n",
      "gold 1998\n",
      "------------------------------\n",
      "all\n",
      "1\n",
      "{'em': 1.0, 'f1': 1.0, 'prec': 1.0, 'recall': 1.0, 'N': 1.0}\n",
      "bridge\n",
      "1\n",
      "{'em': 1.0, 'f1': 1.0, 'prec': 1.0, 'recall': 1.0, 'N': 1.0}\n",
      "comparison\n",
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics[q_type][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m metrics[q_type]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 51\u001b[0m         \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metrics[q_type])\n\u001b[1;32m     55\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(q2a, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq2a.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "from evaluate import update_answer\n",
    "import math\n",
    "# import re\n",
    "\n",
    "q2a = {}\n",
    "raw_data = [json.loads(line.strip()) for line in open('../../released_data/hotpotqa__v2_test_random_500.jsonl')]\n",
    "q2dq = json.load(open(\"./question_decompositions.json\"))\n",
    "q2gold = {}\n",
    "for item in raw_data:\n",
    "    try:\n",
    "        question = item['question_text'].strip()\n",
    "        question = list(q2dq[question].keys())[0]\n",
    "        # should add it later but run prompts again \n",
    "        # question = re.sub(r'\\s+', ' ', question)\n",
    "        gold = item['answers_objects'][0]['spans'][0]\n",
    "        q_type = item[\"type\"]\n",
    "        q2gold[question] = (gold, q_type)\n",
    "    except Exception as e:\n",
    "        # If question not found in question_decompositions, this means something went wrong in the proccess maybe in json parsing in prev steps of tree generation\n",
    "        print(\"ERROR CASE\", e)\n",
    "\n",
    "trees = json.load(open(\"results/test.json\", \"r\"))\n",
    "metrics = {}\n",
    "for q_type in [\"all\", \"bridge\", \"comparison\"]:\n",
    "    metrics[q_type] = {'em': 0, 'f1': 0, 'prec': 0, 'recall': 0, 'N': 0}\n",
    "\n",
    "print(len(trees))\n",
    "for i, tree in enumerate(trees):\n",
    "    node = tree[-1]\n",
    "    question, answer = node[\"question\"], node[\"answer\"][0]\n",
    "    gold, q_type = q2gold[question]\n",
    "    print(\"question\", question)\n",
    "    print(\"question type\", q_type)\n",
    "    print(\"answer\", answer)\n",
    "    print(\"gold\", gold)\n",
    "    print(\"------------------------------\")\n",
    "    q2a[question] = (i, answer, gold)\n",
    "    em, f1, prec, recall = update_answer(metrics[\"all\"], answer, gold)\n",
    "    update_answer(metrics[q_type], answer, gold)\n",
    "\n",
    "for q_type in [\"all\", \"bridge\", \"comparison\"]:\n",
    "    print(q_type)\n",
    "    print(metrics[q_type]['N'])\n",
    "\n",
    "    for k in metrics[q_type].keys():\n",
    "        metrics[q_type][k] /= metrics[q_type]['N']\n",
    "    print(metrics[q_type])\n",
    "\n",
    "\n",
    "json.dump(q2a, open(\"q2a.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_answering import bm25_search\n",
    "import re\n",
    "\n",
    "class ExternalKnowledgeInjectionAction(Action):\n",
    "    def __init__(self, external_knowledge_query_function=bm25_search):\n",
    "        self.external_knowledge_query_function = external_knowledge_query_function\n",
    "        self.k = 5 # Number of external knowledge sources to retrieve\n",
    "\n",
    "    # TODO:: what if we have <1> in the question ?? we should replace it with the answer of the child. but what if its not answered yet ??\n",
    "    def execute(self, node):\n",
    "        \"\"\"Inject external knowledge into the node.\"\"\"\n",
    "        \n",
    "        # # Check if the node contains <1>, <2>, etc. placeholders, which indicate dependencies on other nodes\n",
    "        # placeholders = re.findall(r\"<(\\d+)>\", node.question)\n",
    "        # # If placeholders are present, assert that the node still have dependencies and return an error message\n",
    "        # assert not placeholders, f\"Node '{node.question}' contains placeholders that are not yet resolved.\"\n",
    "        \n",
    "        external_knowledge = self.external_knowledge_query_function(node.question, self.k)\n",
    "        # we have output looking like for hotpotqa es: [{title: \"title\", text: \"text\"}]\n",
    "        node.external_knowledge = external_knowledge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
